{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b 8 times 4 radii\n",
      "\n",
      "(22000, 192)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_detectors = 6\n",
    "number_of_features = n_detectors*4*8\n",
    "input_data = []\n",
    "with open('data/PD_three_rings_with_particle_time_xe9_accuracy_1e-11.dat', 'r') as inpf: \n",
    "    l = inpf.readline()\n",
    "    print(l)\n",
    "    for line in inpf:\n",
    "        features = []\n",
    "        s = line.strip().split()\n",
    "        b = float(s[0])\n",
    "        # for i in range(6):\n",
    "            # for digit in s[i + 1]:\n",
    "                # features.append(float(digit))\n",
    "        for digit in s[1:]:\n",
    "            features.append(float(digit))\n",
    "        input_data.append([b, features])\n",
    "    # print(len(input_data))\n",
    "    \n",
    "    np.random.shuffle(input_data)\n",
    "    input_sorted = sorted(input_data, key=lambda x: (x[0]))\n",
    "    # print(input_data)\n",
    "    \n",
    "    features = np.zeros((len(input_data), number_of_features))\n",
    "    labels = np.zeros((len(input_data), 1))\n",
    "    incr = 0\n",
    "    for elem in input_data:\n",
    "        labels[incr] = np.array(elem[0])\n",
    "        features[incr] = np.array(elem[1])\n",
    "        incr += 1\n",
    "    \n",
    "    # print(input_sorted[:5])\n",
    "    # print(input_data[:5])\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.612]\n",
      " [11.706]\n",
      " [ 8.547]\n",
      " [11.588]\n",
      " [ 6.798]\n",
      " [ 7.727]\n",
      " [11.213]\n",
      " [10.573]\n",
      " [ 8.268]\n",
      " [11.53 ]]\n",
      "Length of segment: 5500\n",
      "Encoded into intervals: [(0, 6.974), (6.974, 9.814), (9.814, 12.043), (12.043, 16.347)]\n",
      "[[1]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [2]]\n",
      "Set shape: (22000, 192)\n",
      "Train features shape: torch.Size([17600, 192])\n",
      "Train labels shape: torch.Size([17600])\n",
      "Test features shape: torch.Size([4400, 192])\n",
      "Test labels shape: torch.Size([4400])\n"
     ]
    }
   ],
   "source": [
    "# Encode labels into segments with equal length\n",
    "def encode_equi_segment(b: float, maximum: float, groups: int) -> int:\n",
    "    if b == maximum:\n",
    "        return groups - 1\n",
    "    else:\n",
    "        length_of_segment = maximum / groups\n",
    "        return int( b // length_of_segment )\n",
    "\n",
    "    \n",
    "# Encode labels into segments with equal size\n",
    "def encode_equi_size(labels_arr: np.ndarray, groups: int ) -> np.ndarray:\n",
    "    lb_sorted = np.sort(labels_arr, axis=0)\n",
    "    segment = lb_sorted.shape[0]//groups\n",
    "    print(\"Length of segment: {}\".format(segment))\n",
    "    borders = []\n",
    "    for i in range(groups):   # define borders of segments\n",
    "        if i != (groups - 1) and i != 0:\n",
    "            borders.append((lb_sorted[(i)*segment].item(), lb_sorted[(i+1)*segment].item()))\n",
    "        elif i == 0:\n",
    "            borders.append((0, lb_sorted[(i+1)*segment].item()))\n",
    "        else: \n",
    "            borders.append((lb_sorted[(i)*segment].item(), lb_sorted[labels.shape[0] - 1].item()))\n",
    "    print(\"Encoded into intervals: {}\" .format(borders))\n",
    "    lb_enc = np.zeros_like(labels, dtype=np.int)\n",
    "    incr = 0\n",
    "    for elem in labels:   # iterate over all (not sorted) labels and encode them\n",
    "        gr = 0\n",
    "        for seg in borders:\n",
    "            if seg[0] < elem <= seg[1]:\n",
    "                lb_enc[incr] = gr\n",
    "                break\n",
    "            gr += 1\n",
    "        incr += 1\n",
    "    return lb_enc\n",
    "\n",
    "\n",
    "number_of_groups = 4\n",
    "\n",
    "\n",
    "# labels_encoded_list = []\n",
    "# maximum_b = np.max(labels)\n",
    "# for label in labels:\n",
    "#     labels_encoded_list.append(encode_equi_segment(label[0], maximum_b, number_of_groups))\n",
    "# labels_encoded = np.array(labels_encoded_list)\n",
    "# train_labels = torch.flatten(torch.tensor(labels_encoded[:size_of_training_set]))\n",
    "# test_labels = torch.flatten(torch.tensor(labels_encoded[size_of_training_set:]))\n",
    "\n",
    "\n",
    "# Divide into test and training sets\n",
    "size_of_training_set = int(features.shape[0] * 0.8)\n",
    "size_of_test_set = features.shape[0] - size_of_training_set\n",
    "\n",
    "train_features = torch.tensor(features[:size_of_training_set], dtype=torch.float32)\n",
    "test_features = torch.tensor(features[size_of_training_set:], dtype=torch.float32)\n",
    "\n",
    "print(labels[:10])\n",
    "labels_encoded_equisized = encode_equi_size(labels, number_of_groups)\n",
    "print(labels_encoded_equisized[:10])\n",
    "train_labels = torch.flatten(torch.tensor(labels_encoded_equisized[:size_of_training_set]))\n",
    "test_labels = torch.flatten(torch.tensor(labels_encoded_equisized[size_of_training_set:]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Set shape: ' + str(features.shape))\n",
    "print('Train features shape: ' + str(train_features.shape))\n",
    "print('Train labels shape: ' + str(train_labels.shape))\n",
    "print('Test features shape: ' + str(test_features.shape))\n",
    "print('Test labels shape: ' + str(test_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Fully connected network. \n",
    "# Convolutional - three blocks below\n",
    "\n",
    "def get_correct_predictions(preds: torch.Tensor, values: torch.Tensor) -> int:\n",
    "    return preds.argmax(dim=1).eq(values).sum().item()\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.lin1 = nn.Linear(in_features = n_detectors*32, out_features = 64)\n",
    "        nn.init.normal_(self.lin1.weight, mean=0.0, std=0.02)\n",
    "        \n",
    "        self.lin2 = nn.Linear(in_features = 64, out_features = 16)\n",
    "        nn.init.normal_(self.lin2.weight, mean=0.0, std=0.02)\n",
    "        \n",
    "        # self.lin3 = nn.Linear(in_features = 16, out_features = 30)\n",
    "        # nn.init.normal_(self.lin3.weight, mean=0.0, std=0.02)\n",
    "        \n",
    "        # self.lin4 = nn.Linear(in_features = 30, out_features = 20)\n",
    "        # nn.init.normal_(self.lin4.weight, mean=0.0, std=0.02)\n",
    "        \n",
    "        # self.lin5 = nn.Linear(in_features = 20, out_features = 12)\n",
    "        # nn.init.normal_(self.lin5.weight, mean=0.0, std=0.02)\n",
    "        \n",
    "        # self.lin6 = nn.Linear(in_features = 12, out_features = 8)\n",
    "        # nn.init.normal_(self.lin6.weight, mean=0.0, std=0.02)\n",
    "        \n",
    "        self.out = nn.Linear(in_features = 16, out_features = number_of_groups)\n",
    "        nn.init.normal_(self.out.weight, mean=0.0, std=0.02)\n",
    "        # print(self.lin1.weight[:4, :8])\n",
    "        # print(self.lin2.weight[:4, :8])\n",
    "        # print(self.lin3.weight[:4, :8])\n",
    "        # print(self.out.weight)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        t = t\n",
    "        t = F.relu(self.lin1(t))\n",
    "        t = F.relu(self.lin2(t))\n",
    "        # t = F.relu(self.lin3(t))\n",
    "        # t = F.relu(self.lin4(t))\n",
    "        # t = F.relu(self.lin5(t))\n",
    "        # t = F.relu(self.lin6(t))\n",
    "        t = F.softmax(self.out(t), dim=1)\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0062, -0.0065,  0.0171,  0.0037, -0.0074,  0.0120,  0.0485, -0.0016,\n",
      "         -0.0262, -0.0098, -0.0133, -0.0244, -0.0243, -0.0097,  0.0219,  0.0259],\n",
      "        [-0.0296,  0.0387, -0.0205, -0.0087, -0.0216,  0.0002,  0.0136, -0.0018,\n",
      "         -0.0276,  0.0020,  0.0051, -0.0238, -0.0032, -0.0065,  0.0006,  0.0248],\n",
      "        [-0.0282, -0.0114, -0.0153, -0.0044, -0.0174, -0.0321,  0.0083,  0.0076,\n",
      "          0.0160,  0.0157, -0.0025,  0.0060, -0.0152, -0.0169, -0.0207, -0.0168],\n",
      "        [ 0.0106, -0.0081, -0.0089,  0.0427, -0.0222, -0.0259,  0.0001, -0.0061,\n",
      "         -0.0129,  0.0114,  0.0250,  0.0236, -0.0194, -0.0219, -0.0290,  0.0168]],\n",
      "       requires_grad=True)\n",
      "Epoch:    0 |---> loss is 1.3864766359, total correct predictions:  4406, its 25.034%\n",
      "Epoch:    1 |---> loss is 1.3829104900, total correct predictions:  7315, its 41.562%\n",
      "Epoch:    2 |---> loss is 1.3694903851, total correct predictions:  6381, its 36.256%\n",
      "Epoch:    3 |---> loss is 1.3458870649, total correct predictions:  6097, its 34.642%\n",
      "Epoch:    4 |---> loss is 1.3284367323, total correct predictions:  6022, its 34.216%\n",
      "Epoch:    5 |---> loss is 1.3341032267, total correct predictions:  5869, its 33.347%\n",
      "Epoch:    6 |---> loss is 1.3369197845, total correct predictions:  6012, its 34.159%\n",
      "Epoch:    7 |---> loss is 1.3348656893, total correct predictions:  6048, its 34.364%\n",
      "Epoch:    8 |---> loss is 1.3262109756, total correct predictions:  6243, its 35.472%\n",
      "Epoch:    9 |---> loss is 1.3181076050, total correct predictions:  6503, its 36.949%\n",
      "Epoch:   10 |---> loss is 1.3226623535, total correct predictions:  6955, its 39.517%\n",
      "Epoch:   11 |---> loss is 1.3170412779, total correct predictions:  6949, its 39.483%\n",
      "Epoch:   12 |---> loss is 1.3117668629, total correct predictions:  6853, its 38.938%\n",
      "Epoch:   13 |---> loss is 1.3096528053, total correct predictions:  6822, its 38.761%\n",
      "Epoch:   14 |---> loss is 1.3065093756, total correct predictions:  6886, its 39.125%\n",
      "Epoch:   15 |---> loss is 1.3036447763, total correct predictions:  7025, its 39.915%\n",
      "Epoch:   16 |---> loss is 1.2997031212, total correct predictions:  7279, its 41.358%\n",
      "Epoch:   17 |---> loss is 1.2948832512, total correct predictions:  7539, its 42.835%\n",
      "Epoch:   18 |---> loss is 1.2908411026, total correct predictions:  7682, its 43.648%\n",
      "Epoch:   19 |---> loss is 1.2854040861, total correct predictions:  7601, its 43.188%\n",
      "Epoch:   20 |---> loss is 1.2803621292, total correct predictions:  7533, its 42.801%\n",
      "Epoch:   21 |---> loss is 1.2739397287, total correct predictions:  7618, its 43.284%\n",
      "Epoch:   22 |---> loss is 1.2669849396, total correct predictions:  7763, its 44.108%\n",
      "Epoch:   23 |---> loss is 1.2606072426, total correct predictions:  8250, its 46.875%\n",
      "Epoch:   24 |---> loss is 1.2532159090, total correct predictions:  8666, its 49.239%\n",
      "Epoch:   25 |---> loss is 1.2442393303, total correct predictions:  8746, its 49.693%\n",
      "Epoch:   26 |---> loss is 1.2346546650, total correct predictions:  8776, its 49.864%\n",
      "Epoch:   27 |---> loss is 1.2258019447, total correct predictions:  8888, its 50.500%\n",
      "Epoch:   28 |---> loss is 1.2155132294, total correct predictions:  9166, its 52.080%\n",
      "Epoch:   29 |---> loss is 1.2053035498, total correct predictions:  9409, its 53.460%\n",
      "Epoch:   30 |---> loss is 1.1961878538, total correct predictions:  9654, its 54.852%\n",
      "Epoch:   31 |---> loss is 1.1860895157, total correct predictions:  9882, its 56.148%\n",
      "Epoch:   32 |---> loss is 1.1769545078, total correct predictions: 10103, its 57.403%\n",
      "Epoch:   33 |---> loss is 1.1672801971, total correct predictions: 10352, its 58.818%\n",
      "Epoch:   34 |---> loss is 1.1582080126, total correct predictions: 10565, its 60.028%\n",
      "Epoch:   35 |---> loss is 1.1497402191, total correct predictions: 10659, its 60.562%\n",
      "Epoch:   36 |---> loss is 1.1417858601, total correct predictions: 10787, its 61.290%\n",
      "Epoch:   37 |---> loss is 1.1349982023, total correct predictions: 10855, its 61.676%\n",
      "Epoch:   38 |---> loss is 1.1288487911, total correct predictions: 10902, its 61.943%\n",
      "Epoch:   39 |---> loss is 1.1244723797, total correct predictions: 10902, its 61.943%\n",
      "Epoch:   40 |---> loss is 1.1172810793, total correct predictions: 11103, its 63.085%\n",
      "Epoch:   41 |---> loss is 1.1122746468, total correct predictions: 11177, its 63.506%\n",
      "Epoch:   42 |---> loss is 1.1089076996, total correct predictions: 11176, its 63.500%\n",
      "Epoch:   43 |---> loss is 1.1051371098, total correct predictions: 11282, its 64.102%\n",
      "Epoch:   44 |---> loss is 1.1027437449, total correct predictions: 11252, its 63.932%\n",
      "Epoch:   45 |---> loss is 1.0985928774, total correct predictions: 11367, its 64.585%\n",
      "Epoch:   46 |---> loss is 1.0954729319, total correct predictions: 11418, its 64.875%\n",
      "Epoch:   47 |---> loss is 1.0908839703, total correct predictions: 11508, its 65.386%\n",
      "Epoch:   48 |---> loss is 1.0874024630, total correct predictions: 11581, its 65.801%\n",
      "Epoch:   49 |---> loss is 1.0847359896, total correct predictions: 11616, its 66.000%\n",
      "Epoch:   50 |---> loss is 1.0822329521, total correct predictions: 11641, its 66.142%\n",
      "Epoch:   51 |---> loss is 1.0826176405, total correct predictions: 11636, its 66.114%\n",
      "Epoch:   52 |---> loss is 1.0835303068, total correct predictions: 11599, its 65.903%\n",
      "Epoch:   53 |---> loss is 1.0805883408, total correct predictions: 11662, its 66.261%\n",
      "Epoch:   54 |---> loss is 1.0718790293, total correct predictions: 11874, its 67.466%\n",
      "Epoch:   55 |---> loss is 1.0782148838, total correct predictions: 11693, its 66.438%\n",
      "Epoch:   56 |---> loss is 1.0761508942, total correct predictions: 11748, its 66.750%\n",
      "Epoch:   57 |---> loss is 1.0697944164, total correct predictions: 11910, its 67.670%\n",
      "Epoch:   58 |---> loss is 1.0735862255, total correct predictions: 11789, its 66.983%\n",
      "Epoch:   59 |---> loss is 1.0638968945, total correct predictions: 12040, its 68.409%\n",
      "Epoch:   60 |---> loss is 1.0669165850, total correct predictions: 11958, its 67.943%\n",
      "Epoch:   61 |---> loss is 1.0623943806, total correct predictions: 12050, its 68.466%\n",
      "Epoch:   62 |---> loss is 1.0616880655, total correct predictions: 12041, its 68.415%\n",
      "Epoch:   63 |---> loss is 1.0599572659, total correct predictions: 12096, its 68.727%\n",
      "Epoch:   64 |---> loss is 1.0568708181, total correct predictions: 12187, its 69.244%\n",
      "Epoch:   65 |---> loss is 1.0578527451, total correct predictions: 12131, its 68.926%\n",
      "Epoch:   66 |---> loss is 1.0533879995, total correct predictions: 12216, its 69.409%\n",
      "Epoch:   67 |---> loss is 1.0544134378, total correct predictions: 12196, its 69.295%\n",
      "Epoch:   68 |---> loss is 1.0503097773, total correct predictions: 12318, its 69.989%\n",
      "Epoch:   69 |---> loss is 1.0508136749, total correct predictions: 12296, its 69.864%\n",
      "Epoch:   70 |---> loss is 1.0487821102, total correct predictions: 12316, its 69.977%\n",
      "Epoch:   71 |---> loss is 1.0471150875, total correct predictions: 12361, its 70.233%\n",
      "Epoch:   72 |---> loss is 1.0464129448, total correct predictions: 12389, its 70.392%\n",
      "Epoch:   73 |---> loss is 1.0445220470, total correct predictions: 12429, its 70.619%\n",
      "Epoch:   74 |---> loss is 1.0435560942, total correct predictions: 12419, its 70.562%\n",
      "Epoch:   75 |---> loss is 1.0417711735, total correct predictions: 12479, its 70.903%\n",
      "Epoch:   76 |---> loss is 1.0418089628, total correct predictions: 12480, its 70.909%\n",
      "Epoch:   77 |---> loss is 1.0391141176, total correct predictions: 12535, its 71.222%\n",
      "Epoch:   78 |---> loss is 1.0394572020, total correct predictions: 12511, its 71.085%\n",
      "Epoch:   79 |---> loss is 1.0382385254, total correct predictions: 12538, its 71.239%\n",
      "Epoch:   80 |---> loss is 1.0369820595, total correct predictions: 12547, its 71.290%\n",
      "Epoch:   81 |---> loss is 1.0362631083, total correct predictions: 12556, its 71.341%\n",
      "Epoch:   82 |---> loss is 1.0339670181, total correct predictions: 12606, its 71.625%\n",
      "Epoch:   83 |---> loss is 1.0346772671, total correct predictions: 12603, its 71.608%\n",
      "Epoch:   84 |---> loss is 1.0333940983, total correct predictions: 12628, its 71.750%\n",
      "Epoch:   85 |---> loss is 1.0326889753, total correct predictions: 12627, its 71.744%\n",
      "Epoch:   86 |---> loss is 1.0325353146, total correct predictions: 12633, its 71.778%\n",
      "Epoch:   87 |---> loss is 1.0296086073, total correct predictions: 12709, its 72.210%\n",
      "Epoch:   88 |---> loss is 1.0299928188, total correct predictions: 12694, its 72.125%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   89 |---> loss is 1.0282402039, total correct predictions: 12735, its 72.358%\n",
      "Epoch:   90 |---> loss is 1.0280467272, total correct predictions: 12737, its 72.369%\n",
      "Epoch:   91 |---> loss is 1.0294108391, total correct predictions: 12682, its 72.057%\n",
      "Epoch:   92 |---> loss is 1.0273411274, total correct predictions: 12754, its 72.466%\n",
      "Epoch:   93 |---> loss is 1.0290910006, total correct predictions: 12707, its 72.199%\n",
      "Epoch:   94 |---> loss is 1.0246659517, total correct predictions: 12804, its 72.750%\n",
      "Epoch:   95 |---> loss is 1.0246541500, total correct predictions: 12779, its 72.608%\n",
      "Epoch:   96 |---> loss is 1.0224558115, total correct predictions: 12851, its 73.017%\n",
      "Epoch:   97 |---> loss is 1.0221916437, total correct predictions: 12865, its 73.097%\n",
      "Epoch:   98 |---> loss is 1.0241658688, total correct predictions: 12787, its 72.653%\n",
      "Epoch:   99 |---> loss is 1.0219533443, total correct predictions: 12868, its 73.114%\n",
      "Epoch:  100 |---> loss is 1.0243617296, total correct predictions: 12788, its 72.659%\n",
      "Epoch:  101 |---> loss is 1.0195406675, total correct predictions: 12925, its 73.438%\n",
      "Epoch:  102 |---> loss is 1.0195333958, total correct predictions: 12873, its 73.142%\n",
      "Epoch:  103 |---> loss is 1.0175046921, total correct predictions: 12969, its 73.688%\n",
      "Epoch:  104 |---> loss is 1.0168119669, total correct predictions: 12982, its 73.761%\n",
      "Epoch:  105 |---> loss is 1.0188581944, total correct predictions: 12887, its 73.222%\n",
      "Epoch:  106 |---> loss is 1.0169991255, total correct predictions: 12983, its 73.767%\n",
      "Epoch:  107 |---> loss is 1.0187090635, total correct predictions: 12918, its 73.398%\n",
      "Epoch:  108 |---> loss is 1.0158927441, total correct predictions: 12999, its 73.858%\n",
      "Epoch:  109 |---> loss is 1.0150426626, total correct predictions: 12989, its 73.801%\n",
      "Epoch:  110 |---> loss is 1.0140076876, total correct predictions: 13039, its 74.085%\n",
      "Epoch:  111 |---> loss is 1.0125914812, total correct predictions: 13048, its 74.136%\n",
      "Epoch:  112 |---> loss is 1.0115388632, total correct predictions: 13092, its 74.386%\n",
      "Epoch:  113 |---> loss is 1.0111488104, total correct predictions: 13096, its 74.409%\n",
      "Epoch:  114 |---> loss is 1.0100119114, total correct predictions: 13124, its 74.568%\n",
      "Epoch:  115 |---> loss is 1.0092918873, total correct predictions: 13133, its 74.619%\n",
      "Epoch:  116 |---> loss is 1.0090057850, total correct predictions: 13150, its 74.716%\n",
      "Epoch:  117 |---> loss is 1.0084190369, total correct predictions: 13145, its 74.688%\n",
      "Epoch:  118 |---> loss is 1.0076131821, total correct predictions: 13171, its 74.835%\n",
      "Epoch:  119 |---> loss is 1.0071049929, total correct predictions: 13179, its 74.881%\n",
      "Epoch:  120 |---> loss is 1.0071531534, total correct predictions: 13186, its 74.920%\n",
      "Epoch:  121 |---> loss is 1.0089664459, total correct predictions: 13111, its 74.494%\n",
      "Epoch:  122 |---> loss is 1.0160572529, total correct predictions: 12875, its 73.153%\n",
      "Epoch:  123 |---> loss is 1.0308237076, total correct predictions: 12509, its 71.074%\n",
      "Epoch:  124 |---> loss is 1.0057442188, total correct predictions: 13187, its 74.926%\n",
      "Epoch:  125 |---> loss is 1.0151072741, total correct predictions: 12908, its 73.341%\n",
      "Epoch:  126 |---> loss is 1.0303893089, total correct predictions: 12533, its 71.210%\n",
      "Epoch:  127 |---> loss is 1.0062627792, total correct predictions: 13121, its 74.551%\n",
      "Epoch:  128 |---> loss is 1.0402760506, total correct predictions: 12278, its 69.761%\n",
      "Epoch:  129 |---> loss is 1.0074055195, total correct predictions: 13106, its 74.466%\n",
      "Epoch:  130 |---> loss is 1.0325049162, total correct predictions: 12491, its 70.972%\n",
      "Epoch:  131 |---> loss is 1.0096580982, total correct predictions: 12989, its 73.801%\n",
      "Epoch:  132 |---> loss is 1.0302267075, total correct predictions: 12526, its 71.170%\n",
      "Epoch:  133 |---> loss is 1.0114977360, total correct predictions: 12976, its 73.727%\n",
      "Epoch:  134 |---> loss is 1.0245584249, total correct predictions: 12676, its 72.023%\n",
      "Epoch:  135 |---> loss is 1.0190708637, total correct predictions: 12785, its 72.642%\n",
      "Epoch:  136 |---> loss is 1.0102812052, total correct predictions: 12984, its 73.773%\n",
      "Epoch:  137 |---> loss is 1.0193943977, total correct predictions: 12774, its 72.580%\n",
      "Epoch:  138 |---> loss is 1.0064169168, total correct predictions: 13077, its 74.301%\n",
      "Epoch:  139 |---> loss is 1.0128382444, total correct predictions: 12907, its 73.335%\n",
      "Epoch:  140 |---> loss is 1.0092535019, total correct predictions: 12967, its 73.676%\n",
      "Epoch:  141 |---> loss is 1.0055522919, total correct predictions: 13093, its 74.392%\n",
      "Epoch:  142 |---> loss is 1.0096635818, total correct predictions: 13011, its 73.926%\n",
      "Epoch:  143 |---> loss is 1.0017482042, total correct predictions: 13157, its 74.756%\n",
      "Epoch:  144 |---> loss is 1.0084677935, total correct predictions: 13003, its 73.881%\n",
      "Epoch:  145 |---> loss is 1.0007525682, total correct predictions: 13173, its 74.847%\n",
      "Epoch:  146 |---> loss is 1.0050212145, total correct predictions: 13126, its 74.580%\n",
      "Epoch:  147 |---> loss is 1.0008133650, total correct predictions: 13201, its 75.006%\n",
      "Epoch:  148 |---> loss is 1.0017299652, total correct predictions: 13163, its 74.790%\n",
      "Epoch:  149 |---> loss is 1.0009996891, total correct predictions: 13186, its 74.920%\n",
      "Epoch:  150 |---> loss is 0.9989447594, total correct predictions: 13248, its 75.273%\n",
      "Epoch:  151 |---> loss is 1.0003960133, total correct predictions: 13223, its 75.131%\n",
      "Epoch:  152 |---> loss is 0.9973410964, total correct predictions: 13267, its 75.381%\n",
      "Epoch:  153 |---> loss is 0.9991410971, total correct predictions: 13234, its 75.193%\n",
      "Epoch:  154 |---> loss is 0.9962221384, total correct predictions: 13298, its 75.557%\n",
      "Epoch:  155 |---> loss is 0.9976881146, total correct predictions: 13277, its 75.438%\n",
      "Epoch:  156 |---> loss is 0.9955557585, total correct predictions: 13319, its 75.676%\n",
      "Epoch:  157 |---> loss is 0.9963286519, total correct predictions: 13294, its 75.534%\n",
      "Epoch:  158 |---> loss is 0.9947593808, total correct predictions: 13347, its 75.835%\n",
      "Epoch:  159 |---> loss is 0.9948070049, total correct predictions: 13355, its 75.881%\n",
      "Epoch:  160 |---> loss is 0.9943390489, total correct predictions: 13337, its 75.778%\n",
      "Epoch:  161 |---> loss is 0.9933427572, total correct predictions: 13350, its 75.852%\n",
      "Epoch:  162 |---> loss is 0.9939083457, total correct predictions: 13366, its 75.943%\n",
      "Epoch:  163 |---> loss is 0.9921694398, total correct predictions: 13393, its 76.097%\n",
      "Epoch:  164 |---> loss is 0.9931841493, total correct predictions: 13357, its 75.892%\n",
      "Epoch:  165 |---> loss is 0.9915911555, total correct predictions: 13401, its 76.142%\n",
      "Epoch:  166 |---> loss is 0.9919350147, total correct predictions: 13398, its 76.125%\n",
      "Epoch:  167 |---> loss is 0.9914587140, total correct predictions: 13394, its 76.102%\n",
      "Epoch:  168 |---> loss is 0.9905767441, total correct predictions: 13410, its 76.193%\n",
      "Epoch:  169 |---> loss is 0.9910988808, total correct predictions: 13418, its 76.239%\n",
      "Epoch:  170 |---> loss is 0.9899186492, total correct predictions: 13430, its 76.307%\n",
      "Epoch:  171 |---> loss is 0.9899247885, total correct predictions: 13424, its 76.273%\n",
      "Epoch:  172 |---> loss is 0.9897025824, total correct predictions: 13436, its 76.341%\n",
      "Epoch:  173 |---> loss is 0.9887652993, total correct predictions: 13461, its 76.483%\n",
      "Epoch:  174 |---> loss is 0.9890987873, total correct predictions: 13449, its 76.415%\n",
      "Epoch:  175 |---> loss is 0.9886450171, total correct predictions: 13455, its 76.449%\n",
      "Epoch:  176 |---> loss is 0.9879161716, total correct predictions: 13474, its 76.557%\n",
      "Epoch:  177 |---> loss is 0.9881018996, total correct predictions: 13466, its 76.511%\n",
      "Epoch:  178 |---> loss is 0.9874383211, total correct predictions: 13477, its 76.574%\n",
      "Epoch:  179 |---> loss is 0.9869509339, total correct predictions: 13483, its 76.608%\n",
      "Epoch:  180 |---> loss is 0.9871413112, total correct predictions: 13483, its 76.608%\n",
      "Epoch:  181 |---> loss is 0.9866566062, total correct predictions: 13495, its 76.676%\n",
      "Epoch:  182 |---> loss is 0.9861444831, total correct predictions: 13505, its 76.733%\n",
      "Epoch:  183 |---> loss is 0.9861238003, total correct predictions: 13501, its 76.710%\n",
      "Epoch:  184 |---> loss is 0.9858598113, total correct predictions: 13511, its 76.767%\n",
      "Epoch:  185 |---> loss is 0.9852186441, total correct predictions: 13521, its 76.824%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  186 |---> loss is 0.9850841165, total correct predictions: 13518, its 76.807%\n",
      "Epoch:  187 |---> loss is 0.9849482775, total correct predictions: 13526, its 76.852%\n",
      "Epoch:  188 |---> loss is 0.9844520092, total correct predictions: 13535, its 76.903%\n",
      "Epoch:  189 |---> loss is 0.9841352701, total correct predictions: 13534, its 76.898%\n",
      "Epoch:  190 |---> loss is 0.9841053486, total correct predictions: 13539, its 76.926%\n",
      "Epoch:  191 |---> loss is 0.9838744998, total correct predictions: 13538, its 76.920%\n",
      "Epoch:  192 |---> loss is 0.9837078452, total correct predictions: 13549, its 76.983%\n",
      "Epoch:  193 |---> loss is 0.9839897156, total correct predictions: 13538, its 76.920%\n",
      "Epoch:  194 |---> loss is 0.9850209951, total correct predictions: 13512, its 76.773%\n",
      "Epoch:  195 |---> loss is 0.9865650535, total correct predictions: 13478, its 76.580%\n",
      "Epoch:  196 |---> loss is 0.9893251657, total correct predictions: 13424, its 76.273%\n",
      "Epoch:  197 |---> loss is 0.9902807474, total correct predictions: 13391, its 76.085%\n",
      "Epoch:  198 |---> loss is 0.9905282259, total correct predictions: 13390, its 76.080%\n",
      "Epoch:  199 |---> loss is 0.9836728573, total correct predictions: 13532, its 76.886%\n",
      "Epoch:  200 |---> loss is 0.9836128354, total correct predictions: 13528, its 76.864%\n",
      "Epoch:  201 |---> loss is 0.9864339828, total correct predictions: 13475, its 76.562%\n",
      "Epoch:  202 |---> loss is 0.9848616123, total correct predictions: 13490, its 76.648%\n",
      "Epoch:  203 |---> loss is 0.9857535362, total correct predictions: 13481, its 76.597%\n",
      "Epoch:  204 |---> loss is 0.9829739928, total correct predictions: 13539, its 76.926%\n",
      "Epoch:  205 |---> loss is 0.9848096967, total correct predictions: 13493, its 76.665%\n",
      "Epoch:  206 |---> loss is 0.9859392643, total correct predictions: 13461, its 76.483%\n",
      "Epoch:  207 |---> loss is 0.9802587628, total correct predictions: 13576, its 77.136%\n",
      "Epoch:  208 |---> loss is 0.9839054942, total correct predictions: 13509, its 76.756%\n",
      "Epoch:  209 |---> loss is 0.9829565287, total correct predictions: 13513, its 76.778%\n",
      "Epoch:  210 |---> loss is 0.9813041687, total correct predictions: 13550, its 76.989%\n",
      "Epoch:  211 |---> loss is 0.9828104973, total correct predictions: 13534, its 76.898%\n",
      "Epoch:  212 |---> loss is 0.9795590043, total correct predictions: 13586, its 77.193%\n",
      "Epoch:  213 |---> loss is 0.9829084873, total correct predictions: 13520, its 76.818%\n",
      "Epoch:  214 |---> loss is 0.9836602211, total correct predictions: 13513, its 76.778%\n",
      "Epoch:  215 |---> loss is 0.9794579148, total correct predictions: 13579, its 77.153%\n",
      "Epoch:  216 |---> loss is 0.9832938910, total correct predictions: 13514, its 76.784%\n",
      "Epoch:  217 |---> loss is 0.9805941582, total correct predictions: 13577, its 77.142%\n",
      "Epoch:  218 |---> loss is 0.9823989272, total correct predictions: 13523, its 76.835%\n",
      "Epoch:  219 |---> loss is 0.9815456271, total correct predictions: 13540, its 76.932%\n",
      "Epoch:  220 |---> loss is 0.9786275029, total correct predictions: 13595, its 77.244%\n",
      "Epoch:  221 |---> loss is 0.9803671241, total correct predictions: 13568, its 77.091%\n",
      "Epoch:  222 |---> loss is 0.9788376689, total correct predictions: 13599, its 77.267%\n",
      "Epoch:  223 |---> loss is 0.9808806777, total correct predictions: 13548, its 76.977%\n",
      "Epoch:  224 |---> loss is 0.9782016873, total correct predictions: 13605, its 77.301%\n",
      "Epoch:  225 |---> loss is 0.9782502651, total correct predictions: 13601, its 77.278%\n",
      "Epoch:  226 |---> loss is 0.9778593183, total correct predictions: 13607, its 77.312%\n",
      "Epoch:  227 |---> loss is 0.9775917530, total correct predictions: 13609, its 77.324%\n",
      "Epoch:  228 |---> loss is 0.9778730869, total correct predictions: 13611, its 77.335%\n",
      "Epoch:  229 |---> loss is 0.9763595462, total correct predictions: 13626, its 77.420%\n",
      "Epoch:  230 |---> loss is 0.9769683480, total correct predictions: 13620, its 77.386%\n",
      "Epoch:  231 |---> loss is 0.9758429527, total correct predictions: 13629, its 77.438%\n",
      "Epoch:  232 |---> loss is 0.9766559601, total correct predictions: 13629, its 77.438%\n",
      "Epoch:  233 |---> loss is 0.9759193063, total correct predictions: 13630, its 77.443%\n",
      "Epoch:  234 |---> loss is 0.9755080342, total correct predictions: 13640, its 77.500%\n",
      "Epoch:  235 |---> loss is 0.9755031466, total correct predictions: 13643, its 77.517%\n",
      "Epoch:  236 |---> loss is 0.9748876691, total correct predictions: 13645, its 77.528%\n",
      "Epoch:  237 |---> loss is 0.9754825234, total correct predictions: 13646, its 77.534%\n",
      "Epoch:  238 |---> loss is 0.9747973680, total correct predictions: 13647, its 77.540%\n",
      "Epoch:  239 |---> loss is 0.9745628834, total correct predictions: 13653, its 77.574%\n",
      "Epoch:  240 |---> loss is 0.9745738506, total correct predictions: 13654, its 77.580%\n",
      "Epoch:  241 |---> loss is 0.9739527702, total correct predictions: 13657, its 77.597%\n",
      "Epoch:  242 |---> loss is 0.9740550518, total correct predictions: 13657, its 77.597%\n",
      "Epoch:  243 |---> loss is 0.9739190340, total correct predictions: 13661, its 77.619%\n",
      "Epoch:  244 |---> loss is 0.9735442400, total correct predictions: 13664, its 77.636%\n",
      "Epoch:  245 |---> loss is 0.9736046195, total correct predictions: 13665, its 77.642%\n",
      "Epoch:  246 |---> loss is 0.9733436108, total correct predictions: 13667, its 77.653%\n",
      "Epoch:  247 |---> loss is 0.9730518460, total correct predictions: 13668, its 77.659%\n",
      "Epoch:  248 |---> loss is 0.9730424285, total correct predictions: 13670, its 77.670%\n",
      "Epoch:  249 |---> loss is 0.9727445841, total correct predictions: 13671, its 77.676%\n",
      "Epoch:  250 |---> loss is 0.9725552797, total correct predictions: 13676, its 77.705%\n",
      "Epoch:  251 |---> loss is 0.9725276232, total correct predictions: 13678, its 77.716%\n",
      "Epoch:  252 |---> loss is 0.9723057747, total correct predictions: 13677, its 77.710%\n",
      "Epoch:  253 |---> loss is 0.9721580744, total correct predictions: 13680, its 77.727%\n",
      "Epoch:  254 |---> loss is 0.9721169472, total correct predictions: 13681, its 77.733%\n",
      "Epoch:  255 |---> loss is 0.9719543457, total correct predictions: 13681, its 77.733%\n",
      "Epoch:  256 |---> loss is 0.9718385935, total correct predictions: 13681, its 77.733%\n",
      "Epoch:  257 |---> loss is 0.9718548059, total correct predictions: 13684, its 77.750%\n",
      "Epoch:  258 |---> loss is 0.9717981815, total correct predictions: 13683, its 77.744%\n",
      "Epoch:  259 |---> loss is 0.9718379378, total correct predictions: 13684, its 77.750%\n",
      "Epoch:  260 |---> loss is 0.9720712900, total correct predictions: 13688, its 77.773%\n",
      "Epoch:  261 |---> loss is 0.9726942182, total correct predictions: 13682, its 77.739%\n",
      "Epoch:  262 |---> loss is 0.9739544392, total correct predictions: 13670, its 77.670%\n",
      "Epoch:  263 |---> loss is 0.9776785374, total correct predictions: 13605, its 77.301%\n",
      "Epoch:  264 |---> loss is 0.9863560796, total correct predictions: 13397, its 76.119%\n",
      "Epoch:  265 |---> loss is 1.0001180172, total correct predictions: 13078, its 74.307%\n",
      "Epoch:  266 |---> loss is 0.9753881693, total correct predictions: 13627, its 77.426%\n",
      "Epoch:  267 |---> loss is 0.9797520041, total correct predictions: 13543, its 76.949%\n",
      "Epoch:  268 |---> loss is 0.9966576099, total correct predictions: 13176, its 74.864%\n",
      "Epoch:  269 |---> loss is 0.9831793904, total correct predictions: 13473, its 76.551%\n",
      "Epoch:  270 |---> loss is 0.9839186668, total correct predictions: 13444, its 76.386%\n",
      "Epoch:  271 |---> loss is 0.9845453501, total correct predictions: 13422, its 76.261%\n",
      "Epoch:  272 |---> loss is 0.9776059985, total correct predictions: 13580, its 77.159%\n",
      "Epoch:  273 |---> loss is 0.9793330431, total correct predictions: 13552, its 77.000%\n",
      "Epoch:  274 |---> loss is 0.9856551886, total correct predictions: 13398, its 76.125%\n",
      "Epoch:  275 |---> loss is 0.9740656018, total correct predictions: 13621, its 77.392%\n",
      "Epoch:  276 |---> loss is 0.9856567383, total correct predictions: 13398, its 76.125%\n",
      "Epoch:  277 |---> loss is 0.9740789533, total correct predictions: 13633, its 77.460%\n",
      "Epoch:  278 |---> loss is 0.9789912701, total correct predictions: 13524, its 76.841%\n",
      "Epoch:  279 |---> loss is 0.9752396941, total correct predictions: 13610, its 77.330%\n",
      "Epoch:  280 |---> loss is 0.9756674170, total correct predictions: 13612, its 77.341%\n",
      "Epoch:  281 |---> loss is 0.9750529528, total correct predictions: 13627, its 77.426%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  282 |---> loss is 0.9748252034, total correct predictions: 13612, its 77.341%\n",
      "Epoch:  283 |---> loss is 0.9720340371, total correct predictions: 13658, its 77.602%\n",
      "Epoch:  284 |---> loss is 0.9732340574, total correct predictions: 13656, its 77.591%\n",
      "Epoch:  285 |---> loss is 0.9709203243, total correct predictions: 13680, its 77.727%\n",
      "Epoch:  286 |---> loss is 0.9721229076, total correct predictions: 13663, its 77.631%\n",
      "Epoch:  287 |---> loss is 0.9698191285, total correct predictions: 13697, its 77.824%\n",
      "Epoch:  288 |---> loss is 0.9710634351, total correct predictions: 13694, its 77.807%\n",
      "Epoch:  289 |---> loss is 0.9693557024, total correct predictions: 13706, its 77.875%\n",
      "Epoch:  290 |---> loss is 0.9703494310, total correct predictions: 13695, its 77.812%\n",
      "Epoch:  291 |---> loss is 0.9690509439, total correct predictions: 13716, its 77.932%\n",
      "Epoch:  292 |---> loss is 0.9695032835, total correct predictions: 13716, its 77.932%\n",
      "Epoch:  293 |---> loss is 0.9686213732, total correct predictions: 13723, its 77.972%\n",
      "Epoch:  294 |---> loss is 0.9692226052, total correct predictions: 13717, its 77.938%\n",
      "Epoch:  295 |---> loss is 0.9682082534, total correct predictions: 13728, its 78.000%\n",
      "Epoch:  296 |---> loss is 0.9688132405, total correct predictions: 13723, its 77.972%\n",
      "Epoch:  297 |---> loss is 0.9680680633, total correct predictions: 13729, its 78.006%\n",
      "Epoch:  298 |---> loss is 0.9682193398, total correct predictions: 13727, its 77.994%\n",
      "Epoch:  299 |---> loss is 0.9679727554, total correct predictions: 13734, its 78.034%\n",
      "Epoch:  300 |---> loss is 0.9677670002, total correct predictions: 13735, its 78.040%\n",
      "Epoch:  301 |---> loss is 0.9677474499, total correct predictions: 13730, its 78.011%\n",
      "Epoch:  302 |---> loss is 0.9673511982, total correct predictions: 13735, its 78.040%\n",
      "Epoch:  303 |---> loss is 0.9675407410, total correct predictions: 13736, its 78.045%\n",
      "Epoch:  304 |---> loss is 0.9670675397, total correct predictions: 13737, its 78.051%\n",
      "Epoch:  305 |---> loss is 0.9673120975, total correct predictions: 13735, its 78.040%\n",
      "Epoch:  306 |---> loss is 0.9669414759, total correct predictions: 13738, its 78.057%\n",
      "Epoch:  307 |---> loss is 0.9669489264, total correct predictions: 13740, its 78.068%\n",
      "Epoch:  308 |---> loss is 0.9668062925, total correct predictions: 13740, its 78.068%\n",
      "Epoch:  309 |---> loss is 0.9666566253, total correct predictions: 13741, its 78.074%\n",
      "Epoch:  310 |---> loss is 0.9666413069, total correct predictions: 13743, its 78.085%\n",
      "Epoch:  311 |---> loss is 0.9663870335, total correct predictions: 13742, its 78.080%\n",
      "Epoch:  312 |---> loss is 0.9664593935, total correct predictions: 13743, its 78.085%\n",
      "Epoch:  313 |---> loss is 0.9662144780, total correct predictions: 13743, its 78.085%\n",
      "Epoch:  314 |---> loss is 0.9661916494, total correct predictions: 13744, its 78.091%\n",
      "Epoch:  315 |---> loss is 0.9660812020, total correct predictions: 13745, its 78.097%\n",
      "Epoch:  316 |---> loss is 0.9659238458, total correct predictions: 13749, its 78.119%\n",
      "Epoch:  317 |---> loss is 0.9659057856, total correct predictions: 13751, its 78.131%\n",
      "Epoch:  318 |---> loss is 0.9657239914, total correct predictions: 13752, its 78.136%\n",
      "Epoch:  319 |---> loss is 0.9656986594, total correct predictions: 13752, its 78.136%\n",
      "Epoch:  320 |---> loss is 0.9655903578, total correct predictions: 13752, its 78.136%\n",
      "Epoch:  321 |---> loss is 0.9654679894, total correct predictions: 13753, its 78.142%\n",
      "Epoch:  322 |---> loss is 0.9654533267, total correct predictions: 13754, its 78.148%\n",
      "Epoch:  323 |---> loss is 0.9653140306, total correct predictions: 13754, its 78.148%\n",
      "Epoch:  324 |---> loss is 0.9652519226, total correct predictions: 13755, its 78.153%\n",
      "Epoch:  325 |---> loss is 0.9651890993, total correct predictions: 13756, its 78.159%\n",
      "Epoch:  326 |---> loss is 0.9650764465, total correct predictions: 13757, its 78.165%\n",
      "Epoch:  327 |---> loss is 0.9650248289, total correct predictions: 13758, its 78.170%\n",
      "Epoch:  328 |---> loss is 0.9649205208, total correct predictions: 13759, its 78.176%\n",
      "Epoch:  329 |---> loss is 0.9648370743, total correct predictions: 13760, its 78.182%\n",
      "Epoch:  330 |---> loss is 0.9647775888, total correct predictions: 13761, its 78.188%\n",
      "Epoch:  331 |---> loss is 0.9646722674, total correct predictions: 13762, its 78.193%\n",
      "Epoch:  332 |---> loss is 0.9645984769, total correct predictions: 13763, its 78.199%\n",
      "Epoch:  333 |---> loss is 0.9645236135, total correct predictions: 13764, its 78.205%\n",
      "Epoch:  334 |---> loss is 0.9644151926, total correct predictions: 13764, its 78.205%\n",
      "Epoch:  335 |---> loss is 0.9643331766, total correct predictions: 13766, its 78.216%\n",
      "Epoch:  336 |---> loss is 0.9642627835, total correct predictions: 13767, its 78.222%\n",
      "Epoch:  337 |---> loss is 0.9641816020, total correct predictions: 13769, its 78.233%\n",
      "Epoch:  338 |---> loss is 0.9641245604, total correct predictions: 13769, its 78.233%\n",
      "Epoch:  339 |---> loss is 0.9640458822, total correct predictions: 13771, its 78.244%\n",
      "Epoch:  340 |---> loss is 0.9639686346, total correct predictions: 13771, its 78.244%\n",
      "Epoch:  341 |---> loss is 0.9639113545, total correct predictions: 13773, its 78.256%\n",
      "Epoch:  342 |---> loss is 0.9638400078, total correct predictions: 13773, its 78.256%\n",
      "Epoch:  343 |---> loss is 0.9637731910, total correct predictions: 13773, its 78.256%\n",
      "Epoch:  344 |---> loss is 0.9637178183, total correct predictions: 13773, its 78.256%\n",
      "Epoch:  345 |---> loss is 0.9636555910, total correct predictions: 13773, its 78.256%\n",
      "Epoch:  346 |---> loss is 0.9635930657, total correct predictions: 13773, its 78.256%\n",
      "Epoch:  347 |---> loss is 0.9635410309, total correct predictions: 13774, its 78.261%\n",
      "Epoch:  348 |---> loss is 0.9634835720, total correct predictions: 13774, its 78.261%\n",
      "Epoch:  349 |---> loss is 0.9634230733, total correct predictions: 13774, its 78.261%\n",
      "Epoch:  350 |---> loss is 0.9633617997, total correct predictions: 13774, its 78.261%\n",
      "Epoch:  351 |---> loss is 0.9632854462, total correct predictions: 13775, its 78.267%\n",
      "Epoch:  352 |---> loss is 0.9632136822, total correct predictions: 13776, its 78.273%\n",
      "Epoch:  353 |---> loss is 0.9631691575, total correct predictions: 13777, its 78.278%\n",
      "Epoch:  354 |---> loss is 0.9631147981, total correct predictions: 13778, its 78.284%\n",
      "Epoch:  355 |---> loss is 0.9630630612, total correct predictions: 13778, its 78.284%\n",
      "Epoch:  356 |---> loss is 0.9630123377, total correct predictions: 13779, its 78.290%\n",
      "Epoch:  357 |---> loss is 0.9629570842, total correct predictions: 13779, its 78.290%\n",
      "Epoch:  358 |---> loss is 0.9629088044, total correct predictions: 13779, its 78.290%\n",
      "Epoch:  359 |---> loss is 0.9628645182, total correct predictions: 13779, its 78.290%\n",
      "Epoch:  360 |---> loss is 0.9628149271, total correct predictions: 13780, its 78.295%\n",
      "Epoch:  361 |---> loss is 0.9627694488, total correct predictions: 13780, its 78.295%\n",
      "Epoch:  362 |---> loss is 0.9627258182, total correct predictions: 13780, its 78.295%\n",
      "Epoch:  363 |---> loss is 0.9626777768, total correct predictions: 13780, its 78.295%\n",
      "Epoch:  364 |---> loss is 0.9626328349, total correct predictions: 13780, its 78.295%\n",
      "Epoch:  365 |---> loss is 0.9625885487, total correct predictions: 13780, its 78.295%\n",
      "Epoch:  366 |---> loss is 0.9625425935, total correct predictions: 13780, its 78.295%\n",
      "Epoch:  367 |---> loss is 0.9624991417, total correct predictions: 13780, its 78.295%\n",
      "Epoch:  368 |---> loss is 0.9624567032, total correct predictions: 13782, its 78.307%\n",
      "Epoch:  369 |---> loss is 0.9624121189, total correct predictions: 13782, its 78.307%\n",
      "Epoch:  370 |---> loss is 0.9623700380, total correct predictions: 13782, its 78.307%\n",
      "Epoch:  371 |---> loss is 0.9623285532, total correct predictions: 13782, its 78.307%\n",
      "Epoch:  372 |---> loss is 0.9622872472, total correct predictions: 13783, its 78.312%\n",
      "Epoch:  373 |---> loss is 0.9622475505, total correct predictions: 13783, its 78.312%\n",
      "Epoch:  374 |---> loss is 0.9622098207, total correct predictions: 13783, its 78.312%\n",
      "Epoch:  375 |---> loss is 0.9621697664, total correct predictions: 13783, its 78.312%\n",
      "Epoch:  376 |---> loss is 0.9621331096, total correct predictions: 13783, its 78.312%\n",
      "Epoch:  377 |---> loss is 0.9620940685, total correct predictions: 13783, its 78.312%\n",
      "Epoch:  378 |---> loss is 0.9620535374, total correct predictions: 13783, its 78.312%\n",
      "Epoch:  379 |---> loss is 0.9620133638, total correct predictions: 13784, its 78.318%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  380 |---> loss is 0.9619716406, total correct predictions: 13784, its 78.318%\n",
      "Epoch:  381 |---> loss is 0.9619345665, total correct predictions: 13784, its 78.318%\n",
      "Epoch:  382 |---> loss is 0.9619004130, total correct predictions: 13785, its 78.324%\n",
      "Epoch:  383 |---> loss is 0.9618647695, total correct predictions: 13785, its 78.324%\n",
      "Epoch:  384 |---> loss is 0.9618297219, total correct predictions: 13785, its 78.324%\n",
      "Epoch:  385 |---> loss is 0.9617935419, total correct predictions: 13785, its 78.324%\n",
      "Epoch:  386 |---> loss is 0.9617527127, total correct predictions: 13786, its 78.330%\n",
      "Epoch:  387 |---> loss is 0.9617159963, total correct predictions: 13786, its 78.330%\n",
      "Epoch:  388 |---> loss is 0.9616731405, total correct predictions: 13786, its 78.330%\n",
      "Epoch:  389 |---> loss is 0.9616134167, total correct predictions: 13788, its 78.341%\n",
      "Epoch:  390 |---> loss is 0.9615710378, total correct predictions: 13788, its 78.341%\n",
      "Epoch:  391 |---> loss is 0.9615406394, total correct predictions: 13788, its 78.341%\n",
      "Epoch:  392 |---> loss is 0.9615049958, total correct predictions: 13788, its 78.341%\n",
      "Epoch:  393 |---> loss is 0.9614585042, total correct predictions: 13787, its 78.335%\n",
      "Epoch:  394 |---> loss is 0.9614157081, total correct predictions: 13788, its 78.341%\n",
      "Epoch:  395 |---> loss is 0.9613835216, total correct predictions: 13788, its 78.341%\n",
      "Epoch:  396 |---> loss is 0.9613499641, total correct predictions: 13789, its 78.347%\n",
      "Epoch:  397 |---> loss is 0.9613146782, total correct predictions: 13789, its 78.347%\n",
      "Epoch:  398 |---> loss is 0.9612799883, total correct predictions: 13789, its 78.347%\n",
      "Epoch:  399 |---> loss is 0.9612441063, total correct predictions: 13789, its 78.347%\n",
      "Epoch:  400 |---> loss is 0.9612100720, total correct predictions: 13790, its 78.352%\n",
      "Epoch:  401 |---> loss is 0.9611765146, total correct predictions: 13789, its 78.347%\n",
      "Epoch:  402 |---> loss is 0.9611421227, total correct predictions: 13790, its 78.352%\n",
      "Epoch:  403 |---> loss is 0.9611057639, total correct predictions: 13790, its 78.352%\n",
      "Epoch:  404 |---> loss is 0.9610716701, total correct predictions: 13791, its 78.358%\n",
      "Epoch:  405 |---> loss is 0.9610349536, total correct predictions: 13792, its 78.364%\n",
      "Epoch:  406 |---> loss is 0.9609985352, total correct predictions: 13792, its 78.364%\n",
      "Epoch:  407 |---> loss is 0.9609632492, total correct predictions: 13792, its 78.364%\n",
      "Epoch:  408 |---> loss is 0.9609249830, total correct predictions: 13792, its 78.364%\n",
      "Epoch:  409 |---> loss is 0.9608849883, total correct predictions: 13794, its 78.375%\n",
      "Epoch:  410 |---> loss is 0.9608469605, total correct predictions: 13794, its 78.375%\n",
      "Epoch:  411 |---> loss is 0.9608089924, total correct predictions: 13794, its 78.375%\n",
      "Epoch:  412 |---> loss is 0.9607659578, total correct predictions: 13794, its 78.375%\n",
      "Epoch:  413 |---> loss is 0.9607225657, total correct predictions: 13796, its 78.386%\n",
      "Epoch:  414 |---> loss is 0.9606759548, total correct predictions: 13797, its 78.392%\n",
      "Epoch:  415 |---> loss is 0.9606389999, total correct predictions: 13797, its 78.392%\n",
      "Epoch:  416 |---> loss is 0.9606086612, total correct predictions: 13797, its 78.392%\n",
      "Epoch:  417 |---> loss is 0.9605787396, total correct predictions: 13797, its 78.392%\n",
      "Epoch:  418 |---> loss is 0.9605469704, total correct predictions: 13797, its 78.392%\n",
      "Epoch:  419 |---> loss is 0.9605161548, total correct predictions: 13797, its 78.392%\n",
      "Epoch:  420 |---> loss is 0.9604827166, total correct predictions: 13798, its 78.398%\n",
      "Epoch:  421 |---> loss is 0.9604520798, total correct predictions: 13798, its 78.398%\n",
      "Epoch:  422 |---> loss is 0.9604252577, total correct predictions: 13798, its 78.398%\n",
      "Epoch:  423 |---> loss is 0.9603945017, total correct predictions: 13798, its 78.398%\n",
      "Epoch:  424 |---> loss is 0.9603627920, total correct predictions: 13798, its 78.398%\n",
      "Epoch:  425 |---> loss is 0.9603269100, total correct predictions: 13799, its 78.403%\n",
      "Epoch:  426 |---> loss is 0.9602923989, total correct predictions: 13799, its 78.403%\n",
      "Epoch:  427 |---> loss is 0.9602595568, total correct predictions: 13799, its 78.403%\n",
      "Epoch:  428 |---> loss is 0.9602311850, total correct predictions: 13800, its 78.409%\n",
      "Epoch:  429 |---> loss is 0.9602019787, total correct predictions: 13800, its 78.409%\n",
      "Epoch:  430 |---> loss is 0.9601766467, total correct predictions: 13800, its 78.409%\n",
      "Epoch:  431 |---> loss is 0.9601484537, total correct predictions: 13800, its 78.409%\n",
      "Epoch:  432 |---> loss is 0.9601237178, total correct predictions: 13801, its 78.415%\n",
      "Epoch:  433 |---> loss is 0.9600994587, total correct predictions: 13801, its 78.415%\n",
      "Epoch:  434 |---> loss is 0.9600787759, total correct predictions: 13801, its 78.415%\n",
      "Epoch:  435 |---> loss is 0.9600585699, total correct predictions: 13801, its 78.415%\n",
      "Epoch:  436 |---> loss is 0.9600361586, total correct predictions: 13801, its 78.415%\n",
      "Epoch:  437 |---> loss is 0.9600182176, total correct predictions: 13801, its 78.415%\n",
      "Epoch:  438 |---> loss is 0.9599996805, total correct predictions: 13801, its 78.415%\n",
      "Epoch:  439 |---> loss is 0.9599802494, total correct predictions: 13801, its 78.415%\n",
      "Epoch:  440 |---> loss is 0.9599615932, total correct predictions: 13801, its 78.415%\n",
      "Epoch:  441 |---> loss is 0.9599394202, total correct predictions: 13802, its 78.420%\n",
      "Epoch:  442 |---> loss is 0.9599171281, total correct predictions: 13802, its 78.420%\n",
      "Epoch:  443 |---> loss is 0.9598906040, total correct predictions: 13802, its 78.420%\n",
      "Epoch:  444 |---> loss is 0.9598659277, total correct predictions: 13802, its 78.420%\n",
      "Epoch:  445 |---> loss is 0.9598428607, total correct predictions: 13802, its 78.420%\n",
      "Epoch:  446 |---> loss is 0.9598175883, total correct predictions: 13802, its 78.420%\n",
      "Epoch:  447 |---> loss is 0.9597991109, total correct predictions: 13802, its 78.420%\n",
      "Epoch:  448 |---> loss is 0.9597769380, total correct predictions: 13802, its 78.420%\n",
      "Epoch:  449 |---> loss is 0.9597606063, total correct predictions: 13802, its 78.420%\n",
      "Epoch:  450 |---> loss is 0.9597396851, total correct predictions: 13802, its 78.420%\n",
      "Epoch:  451 |---> loss is 0.9597218037, total correct predictions: 13802, its 78.420%\n",
      "Epoch:  452 |---> loss is 0.9597050548, total correct predictions: 13802, its 78.420%\n",
      "Epoch:  453 |---> loss is 0.9597014785, total correct predictions: 13803, its 78.426%\n",
      "Epoch:  454 |---> loss is 0.9597048163, total correct predictions: 13803, its 78.426%\n",
      "Epoch:  455 |---> loss is 0.9597200155, total correct predictions: 13803, its 78.426%\n",
      "Epoch:  456 |---> loss is 0.9597075582, total correct predictions: 13803, its 78.426%\n",
      "Epoch:  457 |---> loss is 0.9596835971, total correct predictions: 13803, its 78.426%\n",
      "Epoch:  458 |---> loss is 0.9596303701, total correct predictions: 13803, its 78.426%\n",
      "Epoch:  459 |---> loss is 0.9595818520, total correct predictions: 13803, its 78.426%\n",
      "Epoch:  460 |---> loss is 0.9595398903, total correct predictions: 13804, its 78.432%\n",
      "Epoch:  461 |---> loss is 0.9595065117, total correct predictions: 13804, its 78.432%\n",
      "Epoch:  462 |---> loss is 0.9594819546, total correct predictions: 13804, its 78.432%\n",
      "Epoch:  463 |---> loss is 0.9594624639, total correct predictions: 13804, its 78.432%\n",
      "Epoch:  464 |---> loss is 0.9594454765, total correct predictions: 13804, its 78.432%\n",
      "Epoch:  465 |---> loss is 0.9594292641, total correct predictions: 13804, its 78.432%\n",
      "Epoch:  466 |---> loss is 0.9594161510, total correct predictions: 13804, its 78.432%\n",
      "Epoch:  467 |---> loss is 0.9594005346, total correct predictions: 13804, its 78.432%\n",
      "Epoch:  468 |---> loss is 0.9593868852, total correct predictions: 13804, its 78.432%\n",
      "Epoch:  469 |---> loss is 0.9593752027, total correct predictions: 13804, its 78.432%\n",
      "Epoch:  470 |---> loss is 0.9593663216, total correct predictions: 13804, its 78.432%\n",
      "Epoch:  471 |---> loss is 0.9593652487, total correct predictions: 13804, its 78.432%\n",
      "Epoch:  472 |---> loss is 0.9593806863, total correct predictions: 13804, its 78.432%\n",
      "Epoch:  473 |---> loss is 0.9594264627, total correct predictions: 13804, its 78.432%\n",
      "Epoch:  474 |---> loss is 0.9594705701, total correct predictions: 13804, its 78.432%\n",
      "Epoch:  475 |---> loss is 0.9595105052, total correct predictions: 13804, its 78.432%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  476 |---> loss is 0.9594227076, total correct predictions: 13804, its 78.432%\n",
      "Epoch:  477 |---> loss is 0.9593481421, total correct predictions: 13804, its 78.432%\n",
      "Epoch:  478 |---> loss is 0.9592836499, total correct predictions: 13804, its 78.432%\n",
      "Epoch:  479 |---> loss is 0.9592491388, total correct predictions: 13804, its 78.432%\n",
      "Epoch:  480 |---> loss is 0.9592339396, total correct predictions: 13804, its 78.432%\n",
      "Epoch:  481 |---> loss is 0.9592299461, total correct predictions: 13804, its 78.432%\n",
      "Epoch:  482 |---> loss is 0.9592390656, total correct predictions: 13804, its 78.432%\n",
      "Epoch:  483 |---> loss is 0.9592721462, total correct predictions: 13804, its 78.432%\n",
      "Epoch:  484 |---> loss is 0.9593443871, total correct predictions: 13804, its 78.432%\n",
      "Epoch:  485 |---> loss is 0.9593650103, total correct predictions: 13804, its 78.432%\n",
      "Epoch:  486 |---> loss is 0.9593605995, total correct predictions: 13804, its 78.432%\n",
      "Epoch:  487 |---> loss is 0.9592446089, total correct predictions: 13804, its 78.432%\n",
      "Epoch:  488 |---> loss is 0.9591654539, total correct predictions: 13804, its 78.432%\n",
      "Epoch:  489 |---> loss is 0.9591126442, total correct predictions: 13805, its 78.438%\n",
      "Epoch:  490 |---> loss is 0.9590927958, total correct predictions: 13805, its 78.438%\n",
      "Epoch:  491 |---> loss is 0.9591003656, total correct predictions: 13805, its 78.438%\n",
      "Epoch:  492 |---> loss is 0.9591302872, total correct predictions: 13805, its 78.438%\n",
      "Epoch:  493 |---> loss is 0.9592000842, total correct predictions: 13805, its 78.438%\n",
      "Epoch:  494 |---> loss is 0.9592546821, total correct predictions: 13805, its 78.438%\n",
      "Epoch:  495 |---> loss is 0.9592609406, total correct predictions: 13805, its 78.438%\n",
      "Epoch:  496 |---> loss is 0.9591462016, total correct predictions: 13805, its 78.438%\n",
      "Epoch:  497 |---> loss is 0.9590585232, total correct predictions: 13805, its 78.438%\n",
      "Epoch:  498 |---> loss is 0.9590104818, total correct predictions: 13805, its 78.438%\n",
      "Epoch:  499 |---> loss is 0.9589956999, total correct predictions: 13805, its 78.438%\n"
     ]
    }
   ],
   "source": [
    "net = Network()\n",
    "print(net.out.weight)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "number_of_epoches = 500\n",
    "loss_weights = torch.tensor([1.,1.,1.,1.])\n",
    "\n",
    "\n",
    "total_loss = []\n",
    "total_accuracy = []\n",
    "total_val_loss = []\n",
    "total_val_accuracy = []\n",
    "for epoch in range(number_of_epoches):\n",
    "    predicted = net(train_features)\n",
    "    loss = F.cross_entropy(predicted, train_labels, loss_weights)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    total_correct = get_correct_predictions(predicted, train_labels)\n",
    "    print(\"Epoch: {:4d} |---> loss is {:4.10f}, total correct predictions: {:5d}, its {:.3f}%\"\n",
    "      .format(epoch, loss.item(), total_correct, total_correct*100/train_features.shape[0]))\n",
    "    \n",
    "    with torch.no_grad():  # record loss and accuracy info for plots\n",
    "        total_loss.append(loss.item())\n",
    "        total_accuracy.append(total_correct*100/train_features.shape[0])\n",
    "        \n",
    "        test_preds = net(test_features)\n",
    "        total_val_loss.append(F.cross_entropy(test_preds, test_labels, loss_weights).item())\n",
    "        total_val_accuracy.append(get_correct_predictions(test_preds, test_labels)*100/test_features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 61.93%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graphs and evaluation\n",
    "with torch.no_grad():\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(total_accuracy, label='accuracy')\n",
    "    plt.plot(total_val_accuracy, label = 'val_accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([0, 100])\n",
    "    plt.legend(loc='upper left')\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(total_loss, label='loss')\n",
    "    plt.plot(total_val_loss, label = 'val_loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    \n",
    "    \n",
    "    test_predictions = net(test_features)\n",
    "    test_correct_predictions = get_correct_predictions(test_predictions, test_labels)\n",
    "    print(\"Test accuracy is {:2.2f}%\" .format(test_correct_predictions * 100 /test_features.shape[0]))\n",
    "    \n",
    "    stacked = torch.stack((test_labels, test_predictions.argmax(dim=1)), dim=1)\n",
    "    confusion_matrix = torch.zeros((number_of_groups,number_of_groups), dtype=torch.int32)      # horizontal axis - predicted, vertical - true\n",
    "    for row in stacked:\n",
    "       confusion_matrix[row[0].item()][row[1].item()] += 1     # row is target, column - predicted\n",
    "    # print(confusion_matrix)\n",
    "    # print(400 - torch.count_nonzero(test_labels_tensor).item())\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(confusion_matrix, cmap='winter')\n",
    "    \n",
    "    ax.set_xticks(np.arange(confusion_matrix.shape[0]))\n",
    "    ax.set_yticks(np.arange(confusion_matrix.shape[1]))\n",
    "    x_labels = []\n",
    "    y_labels = []\n",
    "    for i in range(confusion_matrix.shape[0]):\n",
    "        x_labels.append('Predicted: '+ str(i + 1))\n",
    "        y_labels.append('Real: ' + str(i + 1))\n",
    "    ax.set_xticklabels(x_labels)\n",
    "    ax.set_yticklabels(y_labels)\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "    \n",
    "    for i in range(confusion_matrix.shape[0]):\n",
    "        for j in range(confusion_matrix.shape[1]):\n",
    "            text = ax.text(j, i, str(round(confusion_matrix[i][j].item()*100/test_features.shape[0], 2)) + '%', ha=\"center\", va=\"center\", size=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.612]\n",
      " [11.706]\n",
      " [ 8.547]]\n",
      "[[1]\n",
      " [2]\n",
      " [1]]\n",
      "tensor([[3.3800, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [3.3700, 0.0000, 3.3700, 0.0000],\n",
      "        [0.0000, 3.4000, 0.0000, 3.4700],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 3.3800, 0.0000],\n",
      "        [6.7400, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 3.4100, 3.4000]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convolutional NN\n",
    "features_reshaped = np.reshape(features, (features.shape[0], n_detectors, 8, 4))\n",
    "\n",
    "train_features_c = torch.tensor(features_reshaped[:size_of_training_set], dtype=torch.float32)\n",
    "test_features_c = torch.tensor(features_reshaped[size_of_training_set:], dtype=torch.float32)\n",
    "\n",
    "\n",
    "print(labels[:3])\n",
    "print(labels_encoded_equisized[:3])\n",
    "\n",
    "# Equisized\n",
    "train_labels_c = torch.flatten(torch.tensor(labels_encoded_equisized[:size_of_training_set]))\n",
    "test_labels_c = torch.flatten(torch.tensor(labels_encoded_equisized[size_of_training_set:]))\n",
    "\n",
    "# print(train_features_conv.shape)\n",
    "print(train_features_c[0][0])\n",
    "plt.imshow(train_features_c[0][0])\n",
    "plt.show()\n",
    "# print(train_features_c[0][1])\n",
    "# plt.imshow(train_features_c[0][1])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional NN\n",
    "class NetworkConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetworkConv, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=n_detectors, out_channels=n_detectors*2, kernel_size=(4, 2))\n",
    "        nn.init.normal_(self.conv1.weight, mean=0.0, std=0.02)\n",
    "        # print(self.conv1.weight)\n",
    "        # self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=2)\n",
    "        \n",
    "        self.lin1 = nn.Linear(in_features=n_detectors*2*5*3, out_features=60)\n",
    "        nn.init.normal_(self.lin1.weight, mean=0.0, std=0.02)\n",
    "        \n",
    "        self.lin2 = nn.Linear(in_features=60, out_features=16)\n",
    "        nn.init.normal_(self.lin2.weight, mean=0.0, std=0.02)\n",
    "\n",
    "        # self.lin3 = nn.Linear(in_features=30, out_features=12)\n",
    "        # nn.init.normal_(self.lin3.weight, mean=0.0, std=0.02)\n",
    "        \n",
    "        # self.lin4 = nn.Linear(in_features=30, out_features=16)\n",
    "        # nn.init.normal_(self.lin4.weight, mean=0.0, std=0.02) \n",
    "        \n",
    "        self.out = nn.Linear(in_features=16, out_features=number_of_groups)\n",
    "        nn.init.normal_(self.out.weight, mean=0.0, std=0.02)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        t = t\n",
    "        t = F.relu(self.conv1(t))\n",
    "        # t = F.relu(self.conv2(t))\n",
    "        # t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        t = F.relu(self.lin1(t.reshape(-1, n_detectors*2*5*3)))\n",
    "        t = F.relu(self.lin2(t))\n",
    "        # t = F.relu(self.lin3(t))\n",
    "        # t = F.relu(self.lin4(t))\n",
    "        \n",
    "        t = F.softmax(self.out(t), dim=1)\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 1.0471e-02, -1.0377e-02],\n",
      "          [ 2.8475e-02, -3.9719e-03],\n",
      "          [ 1.6322e-02,  2.0941e-02],\n",
      "          [-6.8795e-05,  1.8703e-02]],\n",
      "\n",
      "         [[ 2.4026e-02,  6.7573e-03],\n",
      "          [ 1.8176e-02,  1.5251e-02],\n",
      "          [-3.3451e-03, -1.4057e-02],\n",
      "          [ 1.3354e-02,  2.2560e-02]],\n",
      "\n",
      "         [[ 5.4009e-02, -3.4461e-03],\n",
      "          [-3.9473e-02, -9.1835e-03],\n",
      "          [-1.9593e-02,  4.9147e-03],\n",
      "          [ 6.5960e-03,  5.0465e-03]],\n",
      "\n",
      "         [[-2.2537e-02,  1.8220e-02],\n",
      "          [-2.9908e-02, -1.9082e-02],\n",
      "          [-2.6833e-02,  4.8387e-03],\n",
      "          [-1.0307e-02,  9.0943e-03]],\n",
      "\n",
      "         [[-6.6958e-03,  2.1404e-02],\n",
      "          [ 2.9654e-02,  1.5977e-02],\n",
      "          [-4.1099e-02,  3.0748e-02],\n",
      "          [-3.3664e-02,  2.8667e-02]],\n",
      "\n",
      "         [[ 1.7540e-02,  2.7797e-03],\n",
      "          [-4.0291e-02,  5.5808e-03],\n",
      "          [-2.6618e-02, -2.7916e-02],\n",
      "          [ 1.9060e-02, -1.8054e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.8291e-02,  7.0446e-03],\n",
      "          [ 7.6514e-03, -1.2059e-02],\n",
      "          [-4.8498e-03, -1.7347e-02],\n",
      "          [ 1.3196e-02,  1.2638e-03]],\n",
      "\n",
      "         [[-3.6684e-02,  2.2044e-02],\n",
      "          [ 1.1071e-02, -3.4422e-02],\n",
      "          [-2.6555e-03,  5.6360e-02],\n",
      "          [-3.7497e-03,  2.0583e-02]],\n",
      "\n",
      "         [[ 7.5170e-03, -6.2139e-04],\n",
      "          [ 3.8450e-03,  4.2412e-02],\n",
      "          [ 1.3551e-02,  7.8489e-03],\n",
      "          [-5.4536e-02, -1.0351e-02]],\n",
      "\n",
      "         [[ 6.1290e-03, -1.6202e-02],\n",
      "          [-6.5988e-03, -9.4254e-03],\n",
      "          [-9.9478e-03,  6.8550e-03],\n",
      "          [ 1.0912e-02, -2.2731e-02]],\n",
      "\n",
      "         [[-6.1906e-03,  3.8516e-03],\n",
      "          [-2.6352e-02,  1.6102e-02],\n",
      "          [-3.0923e-03, -1.4781e-02],\n",
      "          [ 4.0562e-02, -7.1309e-03]],\n",
      "\n",
      "         [[ 1.5199e-02,  1.4089e-02],\n",
      "          [-5.4369e-02,  4.2059e-02],\n",
      "          [-1.8924e-02,  4.1923e-02],\n",
      "          [-3.6217e-02,  2.3650e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.2092e-02,  1.9202e-02],\n",
      "          [-2.1002e-02,  2.6924e-03],\n",
      "          [-5.8271e-03, -6.4090e-04],\n",
      "          [-1.6607e-02, -3.8490e-04]],\n",
      "\n",
      "         [[ 4.1347e-02, -1.3553e-02],\n",
      "          [-9.8964e-03,  2.4618e-02],\n",
      "          [-2.4104e-02,  1.6333e-03],\n",
      "          [ 1.9587e-03,  2.5932e-02]],\n",
      "\n",
      "         [[-2.4059e-02, -2.6405e-03],\n",
      "          [ 1.2930e-02,  2.3668e-02],\n",
      "          [ 2.6860e-02,  4.7340e-02],\n",
      "          [-1.3626e-02,  6.7368e-03]],\n",
      "\n",
      "         [[ 6.1653e-03, -3.9759e-02],\n",
      "          [-6.2813e-03,  6.0453e-03],\n",
      "          [-4.0443e-02, -6.8890e-03],\n",
      "          [-6.9824e-03, -2.8139e-02]],\n",
      "\n",
      "         [[ 4.0006e-02, -7.7807e-03],\n",
      "          [ 1.9120e-02, -2.4128e-02],\n",
      "          [-2.6794e-03,  4.6729e-03],\n",
      "          [ 1.0826e-02, -1.9918e-03]],\n",
      "\n",
      "         [[-4.1330e-02, -5.4175e-03],\n",
      "          [-2.2295e-03,  2.0893e-02],\n",
      "          [-4.0894e-02,  4.9614e-03],\n",
      "          [ 1.5412e-02, -9.9163e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7806e-02,  2.2420e-03],\n",
      "          [ 1.4268e-02, -2.6159e-02],\n",
      "          [-8.8803e-03, -6.8271e-03],\n",
      "          [-1.0699e-02,  9.9507e-03]],\n",
      "\n",
      "         [[-7.0719e-03, -2.0607e-03],\n",
      "          [-7.0096e-03,  2.1599e-02],\n",
      "          [ 3.6260e-02, -2.1140e-02],\n",
      "          [-1.7305e-02, -2.5241e-02]],\n",
      "\n",
      "         [[ 1.9064e-02, -1.4867e-02],\n",
      "          [ 6.1748e-03, -1.7953e-02],\n",
      "          [-8.8118e-03,  5.6413e-02],\n",
      "          [-1.2555e-03,  1.5660e-02]],\n",
      "\n",
      "         [[ 4.7797e-03, -2.4552e-03],\n",
      "          [ 2.7846e-03,  1.6615e-02],\n",
      "          [-2.4449e-02, -3.9737e-02],\n",
      "          [ 2.8482e-03, -1.3780e-02]],\n",
      "\n",
      "         [[ 3.8938e-02, -2.2363e-02],\n",
      "          [-2.5915e-02,  3.6485e-03],\n",
      "          [ 6.5817e-03, -2.9304e-02],\n",
      "          [ 1.4024e-02, -8.9188e-03]],\n",
      "\n",
      "         [[-4.2454e-02, -6.2183e-03],\n",
      "          [ 6.0846e-03, -1.2208e-02],\n",
      "          [ 5.7806e-03,  2.8177e-02],\n",
      "          [ 1.2522e-02, -7.3701e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4322e-03,  1.5700e-02],\n",
      "          [ 3.3456e-02,  2.2436e-02],\n",
      "          [ 1.1436e-02,  4.9013e-03],\n",
      "          [-1.4590e-02,  5.1394e-03]],\n",
      "\n",
      "         [[-6.8540e-03, -5.3991e-03],\n",
      "          [-1.4114e-02,  1.1209e-05],\n",
      "          [-2.8189e-02, -4.9818e-02],\n",
      "          [-1.2122e-02,  2.4389e-03]],\n",
      "\n",
      "         [[-2.7950e-02, -2.3344e-02],\n",
      "          [ 1.0945e-02,  2.1917e-02],\n",
      "          [-1.7920e-03,  2.6828e-02],\n",
      "          [ 1.4963e-02,  7.1586e-04]],\n",
      "\n",
      "         [[ 7.7113e-03,  1.3463e-03],\n",
      "          [-2.8358e-02, -6.4966e-03],\n",
      "          [ 1.8487e-02,  2.7166e-03],\n",
      "          [ 2.9850e-02,  9.5144e-03]],\n",
      "\n",
      "         [[ 2.9655e-02,  6.7981e-03],\n",
      "          [ 1.5894e-03,  1.9981e-03],\n",
      "          [-5.1656e-02, -2.2889e-02],\n",
      "          [ 1.0095e-03, -2.3685e-02]],\n",
      "\n",
      "         [[ 1.0764e-02,  1.3850e-02],\n",
      "          [-3.1381e-03,  1.2626e-02],\n",
      "          [ 5.2978e-03, -1.0817e-02],\n",
      "          [ 8.7455e-04, -5.5319e-04]]],\n",
      "\n",
      "\n",
      "        [[[-3.7655e-02, -1.0080e-02],\n",
      "          [ 1.1716e-02, -4.5833e-02],\n",
      "          [-1.5775e-02, -7.5893e-03],\n",
      "          [-1.6131e-02, -2.2306e-02]],\n",
      "\n",
      "         [[-4.2261e-03, -2.1909e-02],\n",
      "          [ 1.5766e-02,  3.0648e-03],\n",
      "          [ 2.1214e-02, -3.0317e-02],\n",
      "          [ 1.0401e-02,  3.7237e-02]],\n",
      "\n",
      "         [[ 2.4341e-02,  1.9852e-02],\n",
      "          [ 5.3615e-03,  1.3235e-02],\n",
      "          [-9.1787e-03,  4.1772e-03],\n",
      "          [-5.8406e-03, -8.4473e-03]],\n",
      "\n",
      "         [[-5.8975e-03, -5.5974e-03],\n",
      "          [-3.7740e-02,  2.3709e-02],\n",
      "          [-1.2401e-02,  3.2839e-02],\n",
      "          [-1.7847e-02,  2.8384e-02]],\n",
      "\n",
      "         [[-4.3549e-03,  2.2907e-02],\n",
      "          [ 6.2938e-03, -3.0472e-03],\n",
      "          [-6.9762e-03, -2.9808e-02],\n",
      "          [-7.8223e-04, -3.0098e-02]],\n",
      "\n",
      "         [[-4.9556e-03, -7.2289e-03],\n",
      "          [-2.8153e-02, -1.4118e-02],\n",
      "          [-2.6100e-02, -6.7532e-03],\n",
      "          [ 1.5593e-02,  8.7681e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2052e-02,  3.6188e-03],\n",
      "          [-5.3846e-03,  1.2700e-02],\n",
      "          [-4.6764e-03,  7.9782e-03],\n",
      "          [ 2.7612e-02,  5.8617e-03]],\n",
      "\n",
      "         [[-2.5889e-02,  1.9573e-02],\n",
      "          [-2.2837e-02,  2.5600e-02],\n",
      "          [-1.3505e-02, -4.1318e-02],\n",
      "          [-3.5222e-02,  3.3936e-02]],\n",
      "\n",
      "         [[-2.6258e-02,  2.4091e-02],\n",
      "          [-9.6755e-03, -1.8519e-02],\n",
      "          [-1.7639e-02,  2.8300e-02],\n",
      "          [ 1.2782e-02, -4.8806e-03]],\n",
      "\n",
      "         [[ 1.6058e-02, -2.1849e-02],\n",
      "          [ 5.5755e-03, -1.6300e-02],\n",
      "          [-3.8655e-03,  2.2818e-02],\n",
      "          [-2.0852e-02, -1.3863e-02]],\n",
      "\n",
      "         [[ 4.8844e-03, -3.3115e-02],\n",
      "          [-1.0809e-02, -8.9765e-03],\n",
      "          [-2.2852e-02,  6.4044e-03],\n",
      "          [-1.6600e-02, -2.3352e-02]],\n",
      "\n",
      "         [[ 3.8026e-04, -3.0513e-02],\n",
      "          [-3.1039e-02,  5.4105e-03],\n",
      "          [-8.7586e-04,  9.3273e-03],\n",
      "          [-1.1937e-02,  2.3317e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.7429e-03, -9.8012e-03],\n",
      "          [ 1.4861e-02,  1.7776e-02],\n",
      "          [-9.2814e-03,  9.1435e-03],\n",
      "          [ 3.3040e-02,  1.7136e-02]],\n",
      "\n",
      "         [[ 2.4029e-02,  8.3977e-03],\n",
      "          [ 1.9938e-02,  4.2566e-02],\n",
      "          [-7.9332e-03, -1.7157e-04],\n",
      "          [ 9.1944e-03,  1.1810e-02]],\n",
      "\n",
      "         [[-1.6392e-02,  3.9553e-03],\n",
      "          [ 1.5848e-03, -2.4590e-02],\n",
      "          [-1.5166e-02,  2.9803e-02],\n",
      "          [-4.3232e-03,  2.4447e-03]],\n",
      "\n",
      "         [[-1.0883e-02,  2.9151e-02],\n",
      "          [-3.8947e-02,  1.3929e-02],\n",
      "          [-1.9548e-03,  1.9884e-02],\n",
      "          [ 2.5170e-02,  1.1635e-02]],\n",
      "\n",
      "         [[-2.4701e-02, -2.3089e-03],\n",
      "          [-1.9386e-02,  1.1458e-02],\n",
      "          [-6.2000e-03,  9.2870e-03],\n",
      "          [-2.4448e-02,  2.6725e-02]],\n",
      "\n",
      "         [[-5.5802e-03, -9.1422e-03],\n",
      "          [ 1.0469e-02, -5.2858e-02],\n",
      "          [ 1.1966e-04, -1.3086e-02],\n",
      "          [-1.0916e-02,  1.9147e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0878e-02, -3.0355e-02],\n",
      "          [ 3.9416e-03,  1.1400e-02],\n",
      "          [ 2.7220e-02, -5.1064e-03],\n",
      "          [-2.8312e-02,  3.6711e-03]],\n",
      "\n",
      "         [[ 2.0484e-02,  1.3207e-02],\n",
      "          [-1.0488e-02,  2.4876e-02],\n",
      "          [ 3.7636e-02,  3.6177e-02],\n",
      "          [-1.1911e-03, -2.8228e-02]],\n",
      "\n",
      "         [[-2.2051e-02,  1.6446e-02],\n",
      "          [ 4.6278e-02,  5.0675e-03],\n",
      "          [-4.6385e-03, -6.7719e-03],\n",
      "          [-2.9331e-02,  4.6842e-03]],\n",
      "\n",
      "         [[-1.5064e-02, -1.0237e-02],\n",
      "          [ 3.1115e-03, -1.0112e-02],\n",
      "          [-1.6992e-02, -1.0822e-02],\n",
      "          [ 2.8659e-02, -6.3386e-02]],\n",
      "\n",
      "         [[ 2.9112e-02, -1.1218e-02],\n",
      "          [-1.3215e-02, -4.4235e-03],\n",
      "          [ 1.3761e-02, -2.6518e-02],\n",
      "          [ 1.3374e-02,  2.8730e-02]],\n",
      "\n",
      "         [[-2.1986e-02,  3.7148e-02],\n",
      "          [ 6.0418e-03, -1.6044e-03],\n",
      "          [ 1.2676e-02, -1.2453e-02],\n",
      "          [-9.5143e-03, -5.0097e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.2897e-02, -3.4787e-02],\n",
      "          [ 2.0691e-02, -1.1344e-02],\n",
      "          [-7.3200e-03,  1.4593e-02],\n",
      "          [ 1.8279e-02, -3.6613e-02]],\n",
      "\n",
      "         [[-2.1807e-02, -7.1681e-03],\n",
      "          [-1.5128e-02, -1.1303e-02],\n",
      "          [ 4.2664e-02,  1.2321e-02],\n",
      "          [ 1.8770e-02, -7.7630e-03]],\n",
      "\n",
      "         [[ 5.2704e-03,  1.0779e-03],\n",
      "          [ 2.2889e-02, -6.0665e-03],\n",
      "          [-2.5896e-03, -1.2500e-02],\n",
      "          [-1.7336e-02, -7.3818e-03]],\n",
      "\n",
      "         [[ 1.9424e-02, -5.8739e-03],\n",
      "          [-2.5228e-02,  2.1039e-02],\n",
      "          [-8.4916e-03, -6.9747e-03],\n",
      "          [ 3.4220e-03,  3.7455e-05]],\n",
      "\n",
      "         [[ 1.3384e-02, -1.7798e-02],\n",
      "          [ 5.4955e-04, -2.5843e-02],\n",
      "          [ 4.6135e-02, -2.4133e-02],\n",
      "          [-1.1440e-02, -6.8892e-03]],\n",
      "\n",
      "         [[ 1.9334e-02,  1.0046e-03],\n",
      "          [ 1.0921e-02, -1.4105e-02],\n",
      "          [-2.0665e-02,  5.4896e-03],\n",
      "          [-1.3959e-02, -1.7647e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1584e-02,  1.4215e-02],\n",
      "          [ 2.9796e-03,  1.9698e-03],\n",
      "          [-1.2638e-02,  2.0624e-02],\n",
      "          [-1.5326e-02,  1.3250e-02]],\n",
      "\n",
      "         [[ 4.0038e-03, -2.1087e-02],\n",
      "          [ 8.3869e-04, -1.8046e-02],\n",
      "          [-1.4445e-02, -1.6149e-02],\n",
      "          [-2.4612e-02,  3.3658e-02]],\n",
      "\n",
      "         [[-7.5319e-03, -4.6301e-02],\n",
      "          [-3.5166e-02,  1.7232e-02],\n",
      "          [-1.4744e-02, -1.7522e-02],\n",
      "          [ 1.3772e-02,  7.8196e-03]],\n",
      "\n",
      "         [[ 1.5982e-02, -7.8749e-03],\n",
      "          [ 1.8433e-02,  2.8036e-04],\n",
      "          [ 1.5418e-02,  1.3023e-02],\n",
      "          [-1.4146e-02,  4.2216e-02]],\n",
      "\n",
      "         [[-3.8279e-02,  9.6479e-04],\n",
      "          [-8.0344e-03,  2.0533e-02],\n",
      "          [-1.8634e-02, -4.0513e-03],\n",
      "          [ 3.5374e-03, -2.6351e-02]],\n",
      "\n",
      "         [[ 2.2458e-02,  2.7332e-03],\n",
      "          [-1.8013e-02, -3.9358e-04],\n",
      "          [-6.4469e-03, -2.4275e-03],\n",
      "          [-2.3106e-03, -2.6441e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.4131e-02, -2.2582e-02],\n",
      "          [ 2.0584e-03, -3.5131e-03],\n",
      "          [ 1.6820e-02, -2.8699e-03],\n",
      "          [ 2.8369e-02, -1.4141e-02]],\n",
      "\n",
      "         [[-1.0281e-02, -9.7728e-03],\n",
      "          [-1.3458e-02, -2.7286e-02],\n",
      "          [-6.3404e-03,  2.8215e-03],\n",
      "          [ 9.6154e-04,  1.2441e-02]],\n",
      "\n",
      "         [[-1.2255e-02,  3.8395e-02],\n",
      "          [ 2.9342e-02, -2.4142e-02],\n",
      "          [ 1.9292e-02,  6.1880e-03],\n",
      "          [ 7.0944e-03, -4.4401e-04]],\n",
      "\n",
      "         [[-2.4456e-02,  2.4652e-02],\n",
      "          [-2.5078e-02,  2.1335e-02],\n",
      "          [ 2.5617e-02,  2.0676e-02],\n",
      "          [ 2.0822e-03,  1.0435e-02]],\n",
      "\n",
      "         [[ 1.6952e-02,  1.2866e-02],\n",
      "          [ 3.2691e-02,  1.6344e-02],\n",
      "          [-2.4087e-03,  2.7493e-02],\n",
      "          [-4.1634e-02, -1.7845e-02]],\n",
      "\n",
      "         [[-3.5297e-03,  1.1486e-02],\n",
      "          [ 5.5370e-04, -1.8118e-02],\n",
      "          [-1.3641e-02,  3.2294e-02],\n",
      "          [-2.5812e-03,  1.5212e-02]]]], requires_grad=True)\n",
      "Epoch:    0 |---> loss is 1.3874708414, total correct predictions:  4385, its 24.915%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    1 |---> loss is 1.3866521120, total correct predictions:  4385, its 24.915%\n",
      "Epoch:    2 |---> loss is 1.3852952719, total correct predictions:  4385, its 24.915%\n",
      "Epoch:    3 |---> loss is 1.3811023235, total correct predictions:  3523, its 20.017%\n",
      "Epoch:    4 |---> loss is 1.3717522621, total correct predictions:  3968, its 22.545%\n",
      "Epoch:    5 |---> loss is 1.3551307917, total correct predictions:  4223, its 23.994%\n",
      "Epoch:    6 |---> loss is 1.3437691927, total correct predictions:  4295, its 24.403%\n",
      "Epoch:    7 |---> loss is 1.3337380886, total correct predictions:  4836, its 27.477%\n",
      "Epoch:    8 |---> loss is 1.3216263056, total correct predictions:  6667, its 37.881%\n",
      "Epoch:    9 |---> loss is 1.3256151676, total correct predictions:  8572, its 48.705%\n",
      "Epoch:   10 |---> loss is 1.3159121275, total correct predictions:  7271, its 41.312%\n",
      "Epoch:   11 |---> loss is 1.3137392998, total correct predictions:  7315, its 41.562%\n",
      "Epoch:   12 |---> loss is 1.2916516066, total correct predictions:  7877, its 44.756%\n",
      "Epoch:   13 |---> loss is 1.2826317549, total correct predictions:  8220, its 46.705%\n",
      "Epoch:   14 |---> loss is 1.2700843811, total correct predictions:  8266, its 46.966%\n",
      "Epoch:   15 |---> loss is 1.2536020279, total correct predictions:  8360, its 47.500%\n",
      "Epoch:   16 |---> loss is 1.2461876869, total correct predictions:  8332, its 47.341%\n",
      "Epoch:   17 |---> loss is 1.2357389927, total correct predictions:  8413, its 47.801%\n",
      "Epoch:   18 |---> loss is 1.2235383987, total correct predictions:  8552, its 48.591%\n",
      "Epoch:   19 |---> loss is 1.2160333395, total correct predictions:  8707, its 49.472%\n",
      "Epoch:   20 |---> loss is 1.2089449167, total correct predictions:  8756, its 49.750%\n",
      "Epoch:   21 |---> loss is 1.1972421408, total correct predictions:  9048, its 51.409%\n",
      "Epoch:   22 |---> loss is 1.1882759333, total correct predictions:  9340, its 53.068%\n",
      "Epoch:   23 |---> loss is 1.1745624542, total correct predictions:  9769, its 55.506%\n",
      "Epoch:   24 |---> loss is 1.1685863733, total correct predictions:  9929, its 56.415%\n",
      "Epoch:   25 |---> loss is 1.1581920385, total correct predictions: 10185, its 57.869%\n",
      "Epoch:   26 |---> loss is 1.1549838781, total correct predictions: 10222, its 58.080%\n",
      "Epoch:   27 |---> loss is 1.1472638845, total correct predictions: 10342, its 58.761%\n",
      "Epoch:   28 |---> loss is 1.1430678368, total correct predictions: 10196, its 57.932%\n",
      "Epoch:   29 |---> loss is 1.1406884193, total correct predictions: 10218, its 58.057%\n",
      "Epoch:   30 |---> loss is 1.1364061832, total correct predictions: 10392, its 59.045%\n",
      "Epoch:   31 |---> loss is 1.1373933554, total correct predictions: 10343, its 58.767%\n",
      "Epoch:   32 |---> loss is 1.1350635290, total correct predictions: 10442, its 59.330%\n",
      "Epoch:   33 |---> loss is 1.1419485807, total correct predictions: 10257, its 58.278%\n",
      "Epoch:   34 |---> loss is 1.1427752972, total correct predictions: 10263, its 58.312%\n",
      "Epoch:   35 |---> loss is 1.1410784721, total correct predictions: 10219, its 58.062%\n",
      "Epoch:   36 |---> loss is 1.1567435265, total correct predictions:  9585, its 54.460%\n",
      "Epoch:   37 |---> loss is 1.1456804276, total correct predictions: 10177, its 57.824%\n",
      "Epoch:   38 |---> loss is 1.1372486353, total correct predictions: 10353, its 58.824%\n",
      "Epoch:   39 |---> loss is 1.1633460522, total correct predictions:  9868, its 56.068%\n",
      "Epoch:   40 |---> loss is 1.1448760033, total correct predictions: 10269, its 58.347%\n",
      "Epoch:   41 |---> loss is 1.1578443050, total correct predictions: 10038, its 57.034%\n",
      "Epoch:   42 |---> loss is 1.1439268589, total correct predictions: 10257, its 58.278%\n",
      "Epoch:   43 |---> loss is 1.1409369707, total correct predictions: 10313, its 58.597%\n",
      "Epoch:   44 |---> loss is 1.1359479427, total correct predictions: 10430, its 59.261%\n",
      "Epoch:   45 |---> loss is 1.1348565817, total correct predictions: 10447, its 59.358%\n",
      "Epoch:   46 |---> loss is 1.1393049955, total correct predictions: 10363, its 58.881%\n",
      "Epoch:   47 |---> loss is 1.1327855587, total correct predictions: 10486, its 59.580%\n",
      "Epoch:   48 |---> loss is 1.1338505745, total correct predictions: 10486, its 59.580%\n",
      "Epoch:   49 |---> loss is 1.1351629496, total correct predictions: 10432, its 59.273%\n",
      "Epoch:   50 |---> loss is 1.1284742355, total correct predictions: 10567, its 60.040%\n",
      "Epoch:   51 |---> loss is 1.1317179203, total correct predictions: 10461, its 59.438%\n",
      "Epoch:   52 |---> loss is 1.1319904327, total correct predictions: 10501, its 59.665%\n",
      "Epoch:   53 |---> loss is 1.1298234463, total correct predictions: 10531, its 59.835%\n",
      "Epoch:   54 |---> loss is 1.1301585436, total correct predictions: 10533, its 59.847%\n",
      "Epoch:   55 |---> loss is 1.1275304556, total correct predictions: 10594, its 60.193%\n",
      "Epoch:   56 |---> loss is 1.1276267767, total correct predictions: 10546, its 59.920%\n",
      "Epoch:   57 |---> loss is 1.1284011602, total correct predictions: 10548, its 59.932%\n",
      "Epoch:   58 |---> loss is 1.1265556812, total correct predictions: 10589, its 60.165%\n",
      "Epoch:   59 |---> loss is 1.1257836819, total correct predictions: 10619, its 60.335%\n",
      "Epoch:   60 |---> loss is 1.1250188351, total correct predictions: 10612, its 60.295%\n",
      "Epoch:   61 |---> loss is 1.1237934828, total correct predictions: 10640, its 60.455%\n",
      "Epoch:   62 |---> loss is 1.1244552135, total correct predictions: 10622, its 60.352%\n",
      "Epoch:   63 |---> loss is 1.1231131554, total correct predictions: 10663, its 60.585%\n",
      "Epoch:   64 |---> loss is 1.1223196983, total correct predictions: 10658, its 60.557%\n",
      "Epoch:   65 |---> loss is 1.1206960678, total correct predictions: 10727, its 60.949%\n",
      "Epoch:   66 |---> loss is 1.1202480793, total correct predictions: 10746, its 61.057%\n",
      "Epoch:   67 |---> loss is 1.1196242571, total correct predictions: 10753, its 61.097%\n",
      "Epoch:   68 |---> loss is 1.1179440022, total correct predictions: 10784, its 61.273%\n",
      "Epoch:   69 |---> loss is 1.1168112755, total correct predictions: 10795, its 61.335%\n",
      "Epoch:   70 |---> loss is 1.1156415939, total correct predictions: 10792, its 61.318%\n",
      "Epoch:   71 |---> loss is 1.1148918867, total correct predictions: 10842, its 61.602%\n",
      "Epoch:   72 |---> loss is 1.1132771969, total correct predictions: 10870, its 61.761%\n",
      "Epoch:   73 |---> loss is 1.1126213074, total correct predictions: 10892, its 61.886%\n",
      "Epoch:   74 |---> loss is 1.1114842892, total correct predictions: 10941, its 62.165%\n",
      "Epoch:   75 |---> loss is 1.1107506752, total correct predictions: 10957, its 62.256%\n",
      "Epoch:   76 |---> loss is 1.1100450754, total correct predictions: 10953, its 62.233%\n",
      "Epoch:   77 |---> loss is 1.1091158390, total correct predictions: 10982, its 62.398%\n",
      "Epoch:   78 |---> loss is 1.1085103750, total correct predictions: 10999, its 62.494%\n",
      "Epoch:   79 |---> loss is 1.1078972816, total correct predictions: 11028, its 62.659%\n",
      "Epoch:   80 |---> loss is 1.1067783833, total correct predictions: 11045, its 62.756%\n",
      "Epoch:   81 |---> loss is 1.1060600281, total correct predictions: 11033, its 62.688%\n",
      "Epoch:   82 |---> loss is 1.1049063206, total correct predictions: 11067, its 62.881%\n",
      "Epoch:   83 |---> loss is 1.1041514874, total correct predictions: 11107, its 63.108%\n",
      "Epoch:   84 |---> loss is 1.1029500961, total correct predictions: 11133, its 63.256%\n",
      "Epoch:   85 |---> loss is 1.1022715569, total correct predictions: 11143, its 63.312%\n",
      "Epoch:   86 |---> loss is 1.1014541388, total correct predictions: 11169, its 63.460%\n",
      "Epoch:   87 |---> loss is 1.1005202532, total correct predictions: 11179, its 63.517%\n",
      "Epoch:   88 |---> loss is 1.0995650291, total correct predictions: 11215, its 63.722%\n",
      "Epoch:   89 |---> loss is 1.0987780094, total correct predictions: 11225, its 63.778%\n",
      "Epoch:   90 |---> loss is 1.0979942083, total correct predictions: 11232, its 63.818%\n",
      "Epoch:   91 |---> loss is 1.0975883007, total correct predictions: 11251, its 63.926%\n",
      "Epoch:   92 |---> loss is 1.0971592665, total correct predictions: 11267, its 64.017%\n",
      "Epoch:   93 |---> loss is 1.0969960690, total correct predictions: 11289, its 64.142%\n",
      "Epoch:   94 |---> loss is 1.0962908268, total correct predictions: 11286, its 64.125%\n",
      "Epoch:   95 |---> loss is 1.0951700211, total correct predictions: 11351, its 64.494%\n",
      "Epoch:   96 |---> loss is 1.0940321684, total correct predictions: 11354, its 64.511%\n",
      "Epoch:   97 |---> loss is 1.0931677818, total correct predictions: 11377, its 64.642%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   98 |---> loss is 1.0928142071, total correct predictions: 11388, its 64.705%\n",
      "Epoch:   99 |---> loss is 1.0929024220, total correct predictions: 11358, its 64.534%\n",
      "Epoch:  100 |---> loss is 1.0938491821, total correct predictions: 11345, its 64.460%\n",
      "Epoch:  101 |---> loss is 1.0935356617, total correct predictions: 11308, its 64.250%\n",
      "Epoch:  102 |---> loss is 1.0931237936, total correct predictions: 11345, its 64.460%\n",
      "Epoch:  103 |---> loss is 1.0902929306, total correct predictions: 11425, its 64.915%\n",
      "Epoch:  104 |---> loss is 1.0888136625, total correct predictions: 11455, its 65.085%\n",
      "Epoch:  105 |---> loss is 1.0881966352, total correct predictions: 11462, its 65.125%\n",
      "Epoch:  106 |---> loss is 1.0882488489, total correct predictions: 11469, its 65.165%\n",
      "Epoch:  107 |---> loss is 1.0890178680, total correct predictions: 11438, its 64.989%\n",
      "Epoch:  108 |---> loss is 1.0886869431, total correct predictions: 11436, its 64.977%\n",
      "Epoch:  109 |---> loss is 1.0890359879, total correct predictions: 11428, its 64.932%\n",
      "Epoch:  110 |---> loss is 1.0869003534, total correct predictions: 11482, its 65.239%\n",
      "Epoch:  111 |---> loss is 1.0852990150, total correct predictions: 11534, its 65.534%\n",
      "Epoch:  112 |---> loss is 1.0841522217, total correct predictions: 11537, its 65.551%\n",
      "Epoch:  113 |---> loss is 1.0837908983, total correct predictions: 11576, its 65.773%\n",
      "Epoch:  114 |---> loss is 1.0841654539, total correct predictions: 11546, its 65.602%\n",
      "Epoch:  115 |---> loss is 1.0844830275, total correct predictions: 11539, its 65.562%\n",
      "Epoch:  116 |---> loss is 1.0864518881, total correct predictions: 11494, its 65.307%\n",
      "Epoch:  117 |---> loss is 1.0855201483, total correct predictions: 11515, its 65.426%\n",
      "Epoch:  118 |---> loss is 1.0859218836, total correct predictions: 11501, its 65.347%\n",
      "Epoch:  119 |---> loss is 1.0820538998, total correct predictions: 11613, its 65.983%\n",
      "Epoch:  120 |---> loss is 1.0806204081, total correct predictions: 11608, its 65.955%\n",
      "Epoch:  121 |---> loss is 1.0801458359, total correct predictions: 11635, its 66.108%\n",
      "Epoch:  122 |---> loss is 1.0804276466, total correct predictions: 11656, its 66.227%\n",
      "Epoch:  123 |---> loss is 1.0822119713, total correct predictions: 11567, its 65.722%\n",
      "Epoch:  124 |---> loss is 1.0829784870, total correct predictions: 11563, its 65.699%\n",
      "Epoch:  125 |---> loss is 1.0872821808, total correct predictions: 11479, its 65.222%\n",
      "Epoch:  126 |---> loss is 1.0810465813, total correct predictions: 11624, its 66.045%\n",
      "Epoch:  127 |---> loss is 1.0782945156, total correct predictions: 11665, its 66.278%\n",
      "Epoch:  128 |---> loss is 1.0771672726, total correct predictions: 11715, its 66.562%\n",
      "Epoch:  129 |---> loss is 1.0776208639, total correct predictions: 11698, its 66.466%\n",
      "Epoch:  130 |---> loss is 1.0788750648, total correct predictions: 11642, its 66.148%\n",
      "Epoch:  131 |---> loss is 1.0783743858, total correct predictions: 11686, its 66.398%\n",
      "Epoch:  132 |---> loss is 1.0801035166, total correct predictions: 11631, its 66.085%\n",
      "Epoch:  133 |---> loss is 1.0804771185, total correct predictions: 11614, its 65.989%\n",
      "Epoch:  134 |---> loss is 1.0836615562, total correct predictions: 11524, its 65.477%\n",
      "Epoch:  135 |---> loss is 1.0746009350, total correct predictions: 11767, its 66.858%\n",
      "Epoch:  136 |---> loss is 1.0796836615, total correct predictions: 11648, its 66.182%\n",
      "Epoch:  137 |---> loss is 1.0861871243, total correct predictions: 11489, its 65.278%\n",
      "Epoch:  138 |---> loss is 1.0801641941, total correct predictions: 11604, its 65.932%\n",
      "Epoch:  139 |---> loss is 1.0867816210, total correct predictions: 11442, its 65.011%\n",
      "Epoch:  140 |---> loss is 1.0800082684, total correct predictions: 11637, its 66.119%\n",
      "Epoch:  141 |---> loss is 1.0884301662, total correct predictions: 11398, its 64.761%\n",
      "Epoch:  142 |---> loss is 1.0753978491, total correct predictions: 11707, its 66.517%\n",
      "Epoch:  143 |---> loss is 1.0841352940, total correct predictions: 11523, its 65.472%\n",
      "Epoch:  144 |---> loss is 1.0784740448, total correct predictions: 11636, its 66.114%\n",
      "Epoch:  145 |---> loss is 1.0786510706, total correct predictions: 11614, its 65.989%\n",
      "Epoch:  146 |---> loss is 1.0796334743, total correct predictions: 11615, its 65.994%\n",
      "Epoch:  147 |---> loss is 1.0755413771, total correct predictions: 11703, its 66.494%\n",
      "Epoch:  148 |---> loss is 1.0763634443, total correct predictions: 11740, its 66.705%\n",
      "Epoch:  149 |---> loss is 1.0745216608, total correct predictions: 11734, its 66.670%\n",
      "Epoch:  150 |---> loss is 1.0745508671, total correct predictions: 11753, its 66.778%\n",
      "Epoch:  151 |---> loss is 1.0759137869, total correct predictions: 11662, its 66.261%\n",
      "Epoch:  152 |---> loss is 1.0734685659, total correct predictions: 11776, its 66.909%\n",
      "Epoch:  153 |---> loss is 1.0729007721, total correct predictions: 11784, its 66.955%\n",
      "Epoch:  154 |---> loss is 1.0720374584, total correct predictions: 11799, its 67.040%\n",
      "Epoch:  155 |---> loss is 1.0707641840, total correct predictions: 11849, its 67.324%\n",
      "Epoch:  156 |---> loss is 1.0721786022, total correct predictions: 11822, its 67.170%\n",
      "Epoch:  157 |---> loss is 1.0702488422, total correct predictions: 11848, its 67.318%\n",
      "Epoch:  158 |---> loss is 1.0749584436, total correct predictions: 11711, its 66.540%\n",
      "Epoch:  159 |---> loss is 1.0732666254, total correct predictions: 11759, its 66.812%\n",
      "Epoch:  160 |---> loss is 1.0776050091, total correct predictions: 11663, its 66.267%\n",
      "Epoch:  161 |---> loss is 1.0773868561, total correct predictions: 11637, its 66.119%\n",
      "Epoch:  162 |---> loss is 1.0726823807, total correct predictions: 11758, its 66.807%\n",
      "Epoch:  163 |---> loss is 1.0707535744, total correct predictions: 11858, its 67.375%\n",
      "Epoch:  164 |---> loss is 1.0675830841, total correct predictions: 11933, its 67.801%\n",
      "Epoch:  165 |---> loss is 1.0695277452, total correct predictions: 11871, its 67.449%\n",
      "Epoch:  166 |---> loss is 1.0724136829, total correct predictions: 11784, its 66.955%\n",
      "Epoch:  167 |---> loss is 1.0747617483, total correct predictions: 11736, its 66.682%\n",
      "Epoch:  168 |---> loss is 1.0732096434, total correct predictions: 11744, its 66.727%\n",
      "Epoch:  169 |---> loss is 1.0685915947, total correct predictions: 11893, its 67.574%\n",
      "Epoch:  170 |---> loss is 1.0681537390, total correct predictions: 11888, its 67.545%\n",
      "Epoch:  171 |---> loss is 1.0657101870, total correct predictions: 11963, its 67.972%\n",
      "Epoch:  172 |---> loss is 1.0655051470, total correct predictions: 11955, its 67.926%\n",
      "Epoch:  173 |---> loss is 1.0651007891, total correct predictions: 11960, its 67.955%\n",
      "Epoch:  174 |---> loss is 1.0641249418, total correct predictions: 12023, its 68.312%\n",
      "Epoch:  175 |---> loss is 1.0645896196, total correct predictions: 11987, its 68.108%\n",
      "Epoch:  176 |---> loss is 1.0635542870, total correct predictions: 12025, its 68.324%\n",
      "Epoch:  177 |---> loss is 1.0656949282, total correct predictions: 11946, its 67.875%\n",
      "Epoch:  178 |---> loss is 1.0725171566, total correct predictions: 11770, its 66.875%\n",
      "Epoch:  179 |---> loss is 1.0823363066, total correct predictions: 11517, its 65.438%\n",
      "Epoch:  180 |---> loss is 1.0744739771, total correct predictions: 11696, its 66.455%\n",
      "Epoch:  181 |---> loss is 1.0636974573, total correct predictions: 11995, its 68.153%\n",
      "Epoch:  182 |---> loss is 1.0621346235, total correct predictions: 12057, its 68.506%\n",
      "Epoch:  183 |---> loss is 1.0625469685, total correct predictions: 12047, its 68.449%\n",
      "Epoch:  184 |---> loss is 1.0678207874, total correct predictions: 11885, its 67.528%\n",
      "Epoch:  185 |---> loss is 1.0754880905, total correct predictions: 11677, its 66.347%\n",
      "Epoch:  186 |---> loss is 1.0684677362, total correct predictions: 11854, its 67.352%\n",
      "Epoch:  187 |---> loss is 1.0628646612, total correct predictions: 12004, its 68.205%\n",
      "Epoch:  188 |---> loss is 1.0612354279, total correct predictions: 12027, its 68.335%\n",
      "Epoch:  189 |---> loss is 1.0599133968, total correct predictions: 12096, its 68.727%\n",
      "Epoch:  190 |---> loss is 1.0604343414, total correct predictions: 12090, its 68.693%\n",
      "Epoch:  191 |---> loss is 1.0599359274, total correct predictions: 12089, its 68.688%\n",
      "Epoch:  192 |---> loss is 1.0625934601, total correct predictions: 12033, its 68.369%\n",
      "Epoch:  193 |---> loss is 1.0695363283, total correct predictions: 11823, its 67.176%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  194 |---> loss is 1.0776222944, total correct predictions: 11638, its 66.125%\n",
      "Epoch:  195 |---> loss is 1.0611853600, total correct predictions: 12062, its 68.534%\n",
      "Epoch:  196 |---> loss is 1.0669478178, total correct predictions: 11873, its 67.460%\n",
      "Epoch:  197 |---> loss is 1.0791965723, total correct predictions: 11581, its 65.801%\n",
      "Epoch:  198 |---> loss is 1.0651272535, total correct predictions: 11935, its 67.812%\n",
      "Epoch:  199 |---> loss is 1.0703032017, total correct predictions: 11800, its 67.045%\n",
      "Epoch:  200 |---> loss is 1.0720010996, total correct predictions: 11763, its 66.835%\n",
      "Epoch:  201 |---> loss is 1.0672535896, total correct predictions: 11876, its 67.477%\n",
      "Epoch:  202 |---> loss is 1.0602197647, total correct predictions: 12044, its 68.432%\n",
      "Epoch:  203 |---> loss is 1.0749000311, total correct predictions: 11722, its 66.602%\n",
      "Epoch:  204 |---> loss is 1.0626188517, total correct predictions: 11987, its 68.108%\n",
      "Epoch:  205 |---> loss is 1.0692448616, total correct predictions: 11828, its 67.205%\n",
      "Epoch:  206 |---> loss is 1.0729087591, total correct predictions: 11726, its 66.625%\n",
      "Epoch:  207 |---> loss is 1.0646086931, total correct predictions: 11928, its 67.773%\n",
      "Epoch:  208 |---> loss is 1.0635036230, total correct predictions: 11955, its 67.926%\n",
      "Epoch:  209 |---> loss is 1.0724306107, total correct predictions: 11762, its 66.830%\n",
      "Epoch:  210 |---> loss is 1.0609568357, total correct predictions: 12029, its 68.347%\n",
      "Epoch:  211 |---> loss is 1.0826083422, total correct predictions: 11525, its 65.483%\n",
      "Epoch:  212 |---> loss is 1.0631338358, total correct predictions: 11957, its 67.938%\n",
      "Epoch:  213 |---> loss is 1.0752955675, total correct predictions: 11712, its 66.545%\n",
      "Epoch:  214 |---> loss is 1.0773994923, total correct predictions: 11611, its 65.972%\n",
      "Epoch:  215 |---> loss is 1.0639523268, total correct predictions: 11951, its 67.903%\n",
      "Epoch:  216 |---> loss is 1.0797662735, total correct predictions: 11586, its 65.830%\n",
      "Epoch:  217 |---> loss is 1.0755003691, total correct predictions: 11663, its 66.267%\n",
      "Epoch:  218 |---> loss is 1.0657809973, total correct predictions: 11877, its 67.483%\n",
      "Epoch:  219 |---> loss is 1.0664370060, total correct predictions: 11876, its 67.477%\n",
      "Epoch:  220 |---> loss is 1.0657645464, total correct predictions: 11890, its 67.557%\n",
      "Epoch:  221 |---> loss is 1.0650162697, total correct predictions: 11912, its 67.682%\n",
      "Epoch:  222 |---> loss is 1.0582456589, total correct predictions: 12077, its 68.619%\n",
      "Epoch:  223 |---> loss is 1.0664041042, total correct predictions: 11880, its 67.500%\n",
      "Epoch:  224 |---> loss is 1.0589421988, total correct predictions: 12072, its 68.591%\n",
      "Epoch:  225 |---> loss is 1.0666323900, total correct predictions: 11883, its 67.517%\n",
      "Epoch:  226 |---> loss is 1.0598682165, total correct predictions: 12025, its 68.324%\n",
      "Epoch:  227 |---> loss is 1.0586973429, total correct predictions: 12073, its 68.597%\n",
      "Epoch:  228 |---> loss is 1.0645517111, total correct predictions: 11906, its 67.648%\n",
      "Epoch:  229 |---> loss is 1.0548321009, total correct predictions: 12149, its 69.028%\n",
      "Epoch:  230 |---> loss is 1.0583384037, total correct predictions: 12058, its 68.511%\n",
      "Epoch:  231 |---> loss is 1.0557818413, total correct predictions: 12144, its 69.000%\n",
      "Epoch:  232 |---> loss is 1.0563892126, total correct predictions: 12121, its 68.869%\n",
      "Epoch:  233 |---> loss is 1.0527709723, total correct predictions: 12208, its 69.364%\n",
      "Epoch:  234 |---> loss is 1.0581351519, total correct predictions: 12060, its 68.523%\n",
      "Epoch:  235 |---> loss is 1.0551376343, total correct predictions: 12146, its 69.011%\n",
      "Epoch:  236 |---> loss is 1.0539408922, total correct predictions: 12166, its 69.125%\n",
      "Epoch:  237 |---> loss is 1.0514912605, total correct predictions: 12243, its 69.562%\n",
      "Epoch:  238 |---> loss is 1.0538640022, total correct predictions: 12176, its 69.182%\n",
      "Epoch:  239 |---> loss is 1.0542609692, total correct predictions: 12182, its 69.216%\n",
      "Epoch:  240 |---> loss is 1.0547152758, total correct predictions: 12151, its 69.040%\n",
      "Epoch:  241 |---> loss is 1.0527352095, total correct predictions: 12215, its 69.403%\n",
      "Epoch:  242 |---> loss is 1.0505677462, total correct predictions: 12256, its 69.636%\n",
      "Epoch:  243 |---> loss is 1.0498137474, total correct predictions: 12302, its 69.898%\n",
      "Epoch:  244 |---> loss is 1.0487868786, total correct predictions: 12303, its 69.903%\n",
      "Epoch:  245 |---> loss is 1.0483583212, total correct predictions: 12319, its 69.994%\n",
      "Epoch:  246 |---> loss is 1.0483683348, total correct predictions: 12307, its 69.926%\n",
      "Epoch:  247 |---> loss is 1.0478391647, total correct predictions: 12355, its 70.199%\n",
      "Epoch:  248 |---> loss is 1.0489988327, total correct predictions: 12297, its 69.869%\n",
      "Epoch:  249 |---> loss is 1.0538467169, total correct predictions: 12177, its 69.188%\n",
      "Epoch:  250 |---> loss is 1.0690647364, total correct predictions: 11813, its 67.119%\n",
      "Epoch:  251 |---> loss is 1.0497556925, total correct predictions: 12292, its 69.841%\n",
      "Epoch:  252 |---> loss is 1.0460593700, total correct predictions: 12393, its 70.415%\n",
      "Epoch:  253 |---> loss is 1.0520730019, total correct predictions: 12197, its 69.301%\n",
      "Epoch:  254 |---> loss is 1.0664577484, total correct predictions: 11849, its 67.324%\n",
      "Epoch:  255 |---> loss is 1.0688211918, total correct predictions: 11817, its 67.142%\n",
      "Epoch:  256 |---> loss is 1.0473086834, total correct predictions: 12322, its 70.011%\n",
      "Epoch:  257 |---> loss is 1.0866458416, total correct predictions: 11403, its 64.790%\n",
      "Epoch:  258 |---> loss is 1.0510454178, total correct predictions: 12234, its 69.511%\n",
      "Epoch:  259 |---> loss is 1.0762920380, total correct predictions: 11624, its 66.045%\n",
      "Epoch:  260 |---> loss is 1.0514650345, total correct predictions: 12223, its 69.449%\n",
      "Epoch:  261 |---> loss is 1.0607713461, total correct predictions: 11988, its 68.114%\n",
      "Epoch:  262 |---> loss is 1.0761691332, total correct predictions: 11648, its 66.182%\n",
      "Epoch:  263 |---> loss is 1.0548344851, total correct predictions: 12111, its 68.812%\n",
      "Epoch:  264 |---> loss is 1.0951595306, total correct predictions: 11289, its 64.142%\n",
      "Epoch:  265 |---> loss is 1.0786129236, total correct predictions: 11604, its 65.932%\n",
      "Epoch:  266 |---> loss is 1.0807517767, total correct predictions: 11573, its 65.756%\n",
      "Epoch:  267 |---> loss is 1.0826417208, total correct predictions: 11535, its 65.540%\n",
      "Epoch:  268 |---> loss is 1.0586533546, total correct predictions: 12023, its 68.312%\n",
      "Epoch:  269 |---> loss is 1.0731424093, total correct predictions: 11740, its 66.705%\n",
      "Epoch:  270 |---> loss is 1.0620790720, total correct predictions: 11958, its 67.943%\n",
      "Epoch:  271 |---> loss is 1.0747588873, total correct predictions: 11680, its 66.364%\n",
      "Epoch:  272 |---> loss is 1.0594425201, total correct predictions: 12014, its 68.261%\n",
      "Epoch:  273 |---> loss is 1.0725423098, total correct predictions: 11702, its 66.489%\n",
      "Epoch:  274 |---> loss is 1.0593508482, total correct predictions: 12028, its 68.341%\n",
      "Epoch:  275 |---> loss is 1.0690850019, total correct predictions: 11807, its 67.085%\n",
      "Epoch:  276 |---> loss is 1.0566444397, total correct predictions: 12051, its 68.472%\n",
      "Epoch:  277 |---> loss is 1.0673185587, total correct predictions: 11842, its 67.284%\n",
      "Epoch:  278 |---> loss is 1.0527952909, total correct predictions: 12165, its 69.119%\n",
      "Epoch:  279 |---> loss is 1.0629465580, total correct predictions: 11957, its 67.938%\n",
      "Epoch:  280 |---> loss is 1.0606805086, total correct predictions: 11989, its 68.119%\n",
      "Epoch:  281 |---> loss is 1.0516616106, total correct predictions: 12188, its 69.250%\n",
      "Epoch:  282 |---> loss is 1.0578092337, total correct predictions: 12065, its 68.551%\n",
      "Epoch:  283 |---> loss is 1.0532959700, total correct predictions: 12146, its 69.011%\n",
      "Epoch:  284 |---> loss is 1.0530426502, total correct predictions: 12152, its 69.045%\n",
      "Epoch:  285 |---> loss is 1.0545247793, total correct predictions: 12119, its 68.858%\n",
      "Epoch:  286 |---> loss is 1.0483070612, total correct predictions: 12268, its 69.705%\n",
      "Epoch:  287 |---> loss is 1.0520359278, total correct predictions: 12173, its 69.165%\n",
      "Epoch:  288 |---> loss is 1.0467698574, total correct predictions: 12286, its 69.807%\n",
      "Epoch:  289 |---> loss is 1.0494821072, total correct predictions: 12211, its 69.381%\n",
      "Epoch:  290 |---> loss is 1.0473967791, total correct predictions: 12266, its 69.693%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  291 |---> loss is 1.0460976362, total correct predictions: 12318, its 69.989%\n",
      "Epoch:  292 |---> loss is 1.0468335152, total correct predictions: 12284, its 69.795%\n",
      "Epoch:  293 |---> loss is 1.0441660881, total correct predictions: 12363, its 70.244%\n",
      "Epoch:  294 |---> loss is 1.0439171791, total correct predictions: 12364, its 70.250%\n",
      "Epoch:  295 |---> loss is 1.0453722477, total correct predictions: 12331, its 70.062%\n",
      "Epoch:  296 |---> loss is 1.0420129299, total correct predictions: 12407, its 70.494%\n",
      "Epoch:  297 |---> loss is 1.0425548553, total correct predictions: 12389, its 70.392%\n",
      "Epoch:  298 |---> loss is 1.0432034731, total correct predictions: 12400, its 70.455%\n",
      "Epoch:  299 |---> loss is 1.0423622131, total correct predictions: 12404, its 70.477%\n",
      "Epoch:  300 |---> loss is 1.0408382416, total correct predictions: 12438, its 70.670%\n",
      "Epoch:  301 |---> loss is 1.0402407646, total correct predictions: 12468, its 70.841%\n",
      "Epoch:  302 |---> loss is 1.0395041704, total correct predictions: 12474, its 70.875%\n",
      "Epoch:  303 |---> loss is 1.0408633947, total correct predictions: 12429, its 70.619%\n",
      "Epoch:  304 |---> loss is 1.0419430733, total correct predictions: 12414, its 70.534%\n",
      "Epoch:  305 |---> loss is 1.0425083637, total correct predictions: 12377, its 70.324%\n",
      "Epoch:  306 |---> loss is 1.0443077087, total correct predictions: 12356, its 70.205%\n",
      "Epoch:  307 |---> loss is 1.0426354408, total correct predictions: 12374, its 70.307%\n",
      "Epoch:  308 |---> loss is 1.0434330702, total correct predictions: 12357, its 70.210%\n",
      "Epoch:  309 |---> loss is 1.0394289494, total correct predictions: 12465, its 70.824%\n",
      "Epoch:  310 |---> loss is 1.0382108688, total correct predictions: 12506, its 71.057%\n",
      "Epoch:  311 |---> loss is 1.0378569365, total correct predictions: 12509, its 71.074%\n",
      "Epoch:  312 |---> loss is 1.0381629467, total correct predictions: 12503, its 71.040%\n",
      "Epoch:  313 |---> loss is 1.0393944979, total correct predictions: 12468, its 70.841%\n",
      "Epoch:  314 |---> loss is 1.0449966192, total correct predictions: 12324, its 70.023%\n",
      "Epoch:  315 |---> loss is 1.0430624485, total correct predictions: 12393, its 70.415%\n",
      "Epoch:  316 |---> loss is 1.0433236361, total correct predictions: 12365, its 70.256%\n",
      "Epoch:  317 |---> loss is 1.0387252569, total correct predictions: 12472, its 70.864%\n",
      "Epoch:  318 |---> loss is 1.0365570784, total correct predictions: 12540, its 71.250%\n",
      "Epoch:  319 |---> loss is 1.0354717970, total correct predictions: 12553, its 71.324%\n",
      "Epoch:  320 |---> loss is 1.0353590250, total correct predictions: 12555, its 71.335%\n",
      "Epoch:  321 |---> loss is 1.0353716612, total correct predictions: 12553, its 71.324%\n",
      "Epoch:  322 |---> loss is 1.0367755890, total correct predictions: 12513, its 71.097%\n",
      "Epoch:  323 |---> loss is 1.0403795242, total correct predictions: 12458, its 70.784%\n",
      "Epoch:  324 |---> loss is 1.0496896505, total correct predictions: 12208, its 69.364%\n",
      "Epoch:  325 |---> loss is 1.0393749475, total correct predictions: 12479, its 70.903%\n",
      "Epoch:  326 |---> loss is 1.0350173712, total correct predictions: 12562, its 71.375%\n",
      "Epoch:  327 |---> loss is 1.0328992605, total correct predictions: 12597, its 71.574%\n",
      "Epoch:  328 |---> loss is 1.0321151018, total correct predictions: 12620, its 71.705%\n",
      "Epoch:  329 |---> loss is 1.0320758820, total correct predictions: 12611, its 71.653%\n",
      "Epoch:  330 |---> loss is 1.0337581635, total correct predictions: 12592, its 71.545%\n",
      "Epoch:  331 |---> loss is 1.0409461260, total correct predictions: 12409, its 70.506%\n",
      "Epoch:  332 |---> loss is 1.0507210493, total correct predictions: 12164, its 69.114%\n",
      "Epoch:  333 |---> loss is 1.0504992008, total correct predictions: 12173, its 69.165%\n",
      "Epoch:  334 |---> loss is 1.0328893661, total correct predictions: 12607, its 71.631%\n",
      "Epoch:  335 |---> loss is 1.0335671902, total correct predictions: 12586, its 71.511%\n",
      "Epoch:  336 |---> loss is 1.0463958979, total correct predictions: 12291, its 69.835%\n",
      "Epoch:  337 |---> loss is 1.0410380363, total correct predictions: 12421, its 70.574%\n",
      "Epoch:  338 |---> loss is 1.0381628275, total correct predictions: 12464, its 70.818%\n",
      "Epoch:  339 |---> loss is 1.0314306021, total correct predictions: 12625, its 71.733%\n",
      "Epoch:  340 |---> loss is 1.0304865837, total correct predictions: 12645, its 71.847%\n",
      "Epoch:  341 |---> loss is 1.0338033438, total correct predictions: 12573, its 71.438%\n",
      "Epoch:  342 |---> loss is 1.0377610922, total correct predictions: 12510, its 71.080%\n",
      "Epoch:  343 |---> loss is 1.0454424620, total correct predictions: 12307, its 69.926%\n",
      "Epoch:  344 |---> loss is 1.0328801870, total correct predictions: 12610, its 71.648%\n",
      "Epoch:  345 |---> loss is 1.0294495821, total correct predictions: 12663, its 71.949%\n",
      "Epoch:  346 |---> loss is 1.0329103470, total correct predictions: 12574, its 71.443%\n",
      "Epoch:  347 |---> loss is 1.0360841751, total correct predictions: 12549, its 71.301%\n",
      "Epoch:  348 |---> loss is 1.0435807705, total correct predictions: 12349, its 70.165%\n",
      "Epoch:  349 |---> loss is 1.0335680246, total correct predictions: 12589, its 71.528%\n",
      "Epoch:  350 |---> loss is 1.0341602564, total correct predictions: 12541, its 71.256%\n",
      "Epoch:  351 |---> loss is 1.0350301266, total correct predictions: 12517, its 71.119%\n",
      "Epoch:  352 |---> loss is 1.0283821821, total correct predictions: 12674, its 72.011%\n",
      "Epoch:  353 |---> loss is 1.0296349525, total correct predictions: 12643, its 71.835%\n",
      "Epoch:  354 |---> loss is 1.0347183943, total correct predictions: 12526, its 71.170%\n",
      "Epoch:  355 |---> loss is 1.0311557055, total correct predictions: 12624, its 71.727%\n",
      "Epoch:  356 |---> loss is 1.0303469896, total correct predictions: 12657, its 71.915%\n",
      "Epoch:  357 |---> loss is 1.0416929722, total correct predictions: 12342, its 70.125%\n",
      "Epoch:  358 |---> loss is 1.0370016098, total correct predictions: 12512, its 71.091%\n",
      "Epoch:  359 |---> loss is 1.0463713408, total correct predictions: 12260, its 69.659%\n",
      "Epoch:  360 |---> loss is 1.0293699503, total correct predictions: 12643, its 71.835%\n",
      "Epoch:  361 |---> loss is 1.0279161930, total correct predictions: 12689, its 72.097%\n",
      "Epoch:  362 |---> loss is 1.0399830341, total correct predictions: 12395, its 70.426%\n",
      "Epoch:  363 |---> loss is 1.0342217684, total correct predictions: 12557, its 71.347%\n",
      "Epoch:  364 |---> loss is 1.0323646069, total correct predictions: 12572, its 71.432%\n",
      "Epoch:  365 |---> loss is 1.0284230709, total correct predictions: 12682, its 72.057%\n",
      "Epoch:  366 |---> loss is 1.0300264359, total correct predictions: 12634, its 71.784%\n",
      "Epoch:  367 |---> loss is 1.0264467001, total correct predictions: 12687, its 72.085%\n",
      "Epoch:  368 |---> loss is 1.0286428928, total correct predictions: 12674, its 72.011%\n",
      "Epoch:  369 |---> loss is 1.0375015736, total correct predictions: 12456, its 70.773%\n",
      "Epoch:  370 |---> loss is 1.0300338268, total correct predictions: 12642, its 71.830%\n",
      "Epoch:  371 |---> loss is 1.0380003452, total correct predictions: 12433, its 70.642%\n",
      "Epoch:  372 |---> loss is 1.0328111649, total correct predictions: 12568, its 71.409%\n",
      "Epoch:  373 |---> loss is 1.0265986919, total correct predictions: 12688, its 72.091%\n",
      "Epoch:  374 |---> loss is 1.0304814577, total correct predictions: 12591, its 71.540%\n",
      "Epoch:  375 |---> loss is 1.0348588228, total correct predictions: 12492, its 70.977%\n",
      "Epoch:  376 |---> loss is 1.0246242285, total correct predictions: 12750, its 72.443%\n",
      "Epoch:  377 |---> loss is 1.0389860868, total correct predictions: 12393, its 70.415%\n",
      "Epoch:  378 |---> loss is 1.0282285213, total correct predictions: 12663, its 71.949%\n",
      "Epoch:  379 |---> loss is 1.0275148153, total correct predictions: 12665, its 71.960%\n",
      "Epoch:  380 |---> loss is 1.0372668505, total correct predictions: 12465, its 70.824%\n",
      "Epoch:  381 |---> loss is 1.0420577526, total correct predictions: 12348, its 70.159%\n",
      "Epoch:  382 |---> loss is 1.0385239124, total correct predictions: 12407, its 70.494%\n",
      "Epoch:  383 |---> loss is 1.0305415392, total correct predictions: 12597, its 71.574%\n",
      "Epoch:  384 |---> loss is 1.0245342255, total correct predictions: 12731, its 72.335%\n",
      "Epoch:  385 |---> loss is 1.0281947851, total correct predictions: 12665, its 71.960%\n",
      "Epoch:  386 |---> loss is 1.0236639977, total correct predictions: 12744, its 72.409%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  387 |---> loss is 1.0309191942, total correct predictions: 12604, its 71.614%\n",
      "Epoch:  388 |---> loss is 1.0446072817, total correct predictions: 12288, its 69.818%\n",
      "Epoch:  389 |---> loss is 1.0374963284, total correct predictions: 12429, its 70.619%\n",
      "Epoch:  390 |---> loss is 1.0329985619, total correct predictions: 12545, its 71.278%\n",
      "Epoch:  391 |---> loss is 1.0224056244, total correct predictions: 12782, its 72.625%\n",
      "Epoch:  392 |---> loss is 1.0268055201, total correct predictions: 12682, its 72.057%\n",
      "Epoch:  393 |---> loss is 1.0369765759, total correct predictions: 12446, its 70.716%\n",
      "Epoch:  394 |---> loss is 1.0319526196, total correct predictions: 12583, its 71.494%\n",
      "Epoch:  395 |---> loss is 1.0355684757, total correct predictions: 12479, its 70.903%\n",
      "Epoch:  396 |---> loss is 1.0230515003, total correct predictions: 12756, its 72.477%\n",
      "Epoch:  397 |---> loss is 1.0299690962, total correct predictions: 12598, its 71.580%\n",
      "Epoch:  398 |---> loss is 1.0250027180, total correct predictions: 12716, its 72.250%\n",
      "Epoch:  399 |---> loss is 1.0313649178, total correct predictions: 12577, its 71.460%\n",
      "Epoch:  400 |---> loss is 1.0461401939, total correct predictions: 12249, its 69.597%\n",
      "Epoch:  401 |---> loss is 1.0240646601, total correct predictions: 12736, its 72.364%\n",
      "Epoch:  402 |---> loss is 1.0512163639, total correct predictions: 12145, its 69.006%\n",
      "Epoch:  403 |---> loss is 1.0311497450, total correct predictions: 12591, its 71.540%\n",
      "Epoch:  404 |---> loss is 1.0376714468, total correct predictions: 12414, its 70.534%\n",
      "Epoch:  405 |---> loss is 1.0223921537, total correct predictions: 12762, its 72.511%\n",
      "Epoch:  406 |---> loss is 1.0418082476, total correct predictions: 12326, its 70.034%\n",
      "Epoch:  407 |---> loss is 1.0277047157, total correct predictions: 12624, its 71.727%\n",
      "Epoch:  408 |---> loss is 1.0362601280, total correct predictions: 12447, its 70.722%\n",
      "Epoch:  409 |---> loss is 1.0208702087, total correct predictions: 12795, its 72.699%\n",
      "Epoch:  410 |---> loss is 1.0382955074, total correct predictions: 12405, its 70.483%\n",
      "Epoch:  411 |---> loss is 1.0293121338, total correct predictions: 12605, its 71.619%\n",
      "Epoch:  412 |---> loss is 1.0360193253, total correct predictions: 12452, its 70.750%\n",
      "Epoch:  413 |---> loss is 1.0228474140, total correct predictions: 12743, its 72.403%\n",
      "Epoch:  414 |---> loss is 1.0263003111, total correct predictions: 12673, its 72.006%\n",
      "Epoch:  415 |---> loss is 1.0225654840, total correct predictions: 12766, its 72.534%\n",
      "Epoch:  416 |---> loss is 1.0258735418, total correct predictions: 12687, its 72.085%\n",
      "Epoch:  417 |---> loss is 1.0270912647, total correct predictions: 12651, its 71.881%\n",
      "Epoch:  418 |---> loss is 1.0264437199, total correct predictions: 12675, its 72.017%\n",
      "Epoch:  419 |---> loss is 1.0267230272, total correct predictions: 12668, its 71.977%\n",
      "Epoch:  420 |---> loss is 1.0225350857, total correct predictions: 12758, its 72.489%\n",
      "Epoch:  421 |---> loss is 1.0223246813, total correct predictions: 12758, its 72.489%\n",
      "Epoch:  422 |---> loss is 1.0192102194, total correct predictions: 12808, its 72.773%\n",
      "Epoch:  423 |---> loss is 1.0193567276, total correct predictions: 12813, its 72.801%\n",
      "Epoch:  424 |---> loss is 1.0182198286, total correct predictions: 12836, its 72.932%\n",
      "Epoch:  425 |---> loss is 1.0180145502, total correct predictions: 12844, its 72.977%\n",
      "Epoch:  426 |---> loss is 1.0196957588, total correct predictions: 12804, its 72.750%\n",
      "Epoch:  427 |---> loss is 1.0197789669, total correct predictions: 12822, its 72.852%\n",
      "Epoch:  428 |---> loss is 1.0256515741, total correct predictions: 12692, its 72.114%\n",
      "Epoch:  429 |---> loss is 1.0328156948, total correct predictions: 12511, its 71.085%\n",
      "Epoch:  430 |---> loss is 1.0344351530, total correct predictions: 12475, its 70.881%\n",
      "Epoch:  431 |---> loss is 1.0310115814, total correct predictions: 12568, its 71.409%\n",
      "Epoch:  432 |---> loss is 1.0233244896, total correct predictions: 12730, its 72.330%\n",
      "Epoch:  433 |---> loss is 1.0203441381, total correct predictions: 12799, its 72.722%\n",
      "Epoch:  434 |---> loss is 1.0166811943, total correct predictions: 12853, its 73.028%\n",
      "Epoch:  435 |---> loss is 1.0161910057, total correct predictions: 12878, its 73.170%\n",
      "Epoch:  436 |---> loss is 1.0173485279, total correct predictions: 12848, its 73.000%\n",
      "Epoch:  437 |---> loss is 1.0179677010, total correct predictions: 12852, its 73.023%\n",
      "Epoch:  438 |---> loss is 1.0187671185, total correct predictions: 12835, its 72.926%\n",
      "Epoch:  439 |---> loss is 1.0178214312, total correct predictions: 12849, its 73.006%\n",
      "Epoch:  440 |---> loss is 1.0172311068, total correct predictions: 12866, its 73.102%\n",
      "Epoch:  441 |---> loss is 1.0164020061, total correct predictions: 12880, its 73.182%\n",
      "Epoch:  442 |---> loss is 1.0153038502, total correct predictions: 12893, its 73.256%\n",
      "Epoch:  443 |---> loss is 1.0145325661, total correct predictions: 12913, its 73.369%\n",
      "Epoch:  444 |---> loss is 1.0139489174, total correct predictions: 12919, its 73.403%\n",
      "Epoch:  445 |---> loss is 1.0134894848, total correct predictions: 12928, its 73.455%\n",
      "Epoch:  446 |---> loss is 1.0134526491, total correct predictions: 12931, its 73.472%\n",
      "Epoch:  447 |---> loss is 1.0141556263, total correct predictions: 12932, its 73.477%\n",
      "Epoch:  448 |---> loss is 1.0174701214, total correct predictions: 12861, its 73.074%\n",
      "Epoch:  449 |---> loss is 1.0345674753, total correct predictions: 12483, its 70.926%\n",
      "Epoch:  450 |---> loss is 1.0353914499, total correct predictions: 12442, its 70.693%\n",
      "Epoch:  451 |---> loss is 1.0319148302, total correct predictions: 12545, its 71.278%\n",
      "Epoch:  452 |---> loss is 1.0214053392, total correct predictions: 12777, its 72.597%\n",
      "Epoch:  453 |---> loss is 1.0194746256, total correct predictions: 12804, its 72.750%\n",
      "Epoch:  454 |---> loss is 1.0194506645, total correct predictions: 12806, its 72.761%\n",
      "Epoch:  455 |---> loss is 1.0246315002, total correct predictions: 12705, its 72.188%\n",
      "Epoch:  456 |---> loss is 1.0215685368, total correct predictions: 12774, its 72.580%\n",
      "Epoch:  457 |---> loss is 1.0214184523, total correct predictions: 12766, its 72.534%\n",
      "Epoch:  458 |---> loss is 1.0182377100, total correct predictions: 12830, its 72.898%\n",
      "Epoch:  459 |---> loss is 1.0154827833, total correct predictions: 12881, its 73.188%\n",
      "Epoch:  460 |---> loss is 1.0126228333, total correct predictions: 12930, its 73.466%\n",
      "Epoch:  461 |---> loss is 1.0132989883, total correct predictions: 12933, its 73.483%\n",
      "Epoch:  462 |---> loss is 1.0153167248, total correct predictions: 12893, its 73.256%\n",
      "Epoch:  463 |---> loss is 1.0154498816, total correct predictions: 12904, its 73.318%\n",
      "Epoch:  464 |---> loss is 1.0155624151, total correct predictions: 12872, its 73.136%\n",
      "Epoch:  465 |---> loss is 1.0161377192, total correct predictions: 12874, its 73.148%\n",
      "Epoch:  466 |---> loss is 1.0197451115, total correct predictions: 12799, its 72.722%\n",
      "Epoch:  467 |---> loss is 1.0192056894, total correct predictions: 12814, its 72.807%\n",
      "Epoch:  468 |---> loss is 1.0236443281, total correct predictions: 12714, its 72.239%\n",
      "Epoch:  469 |---> loss is 1.0257935524, total correct predictions: 12683, its 72.062%\n",
      "Epoch:  470 |---> loss is 1.0315667391, total correct predictions: 12530, its 71.193%\n",
      "Epoch:  471 |---> loss is 1.0181541443, total correct predictions: 12853, its 73.028%\n",
      "Epoch:  472 |---> loss is 1.0132195950, total correct predictions: 12913, its 73.369%\n",
      "Epoch:  473 |---> loss is 1.0141808987, total correct predictions: 12904, its 73.318%\n",
      "Epoch:  474 |---> loss is 1.0186145306, total correct predictions: 12836, its 72.932%\n",
      "Epoch:  475 |---> loss is 1.0229604244, total correct predictions: 12731, its 72.335%\n",
      "Epoch:  476 |---> loss is 1.0187672377, total correct predictions: 12823, its 72.858%\n",
      "Epoch:  477 |---> loss is 1.0144985914, total correct predictions: 12901, its 73.301%\n",
      "Epoch:  478 |---> loss is 1.0107165575, total correct predictions: 12957, its 73.619%\n",
      "Epoch:  479 |---> loss is 1.0165966749, total correct predictions: 12864, its 73.091%\n",
      "Epoch:  480 |---> loss is 1.0249657631, total correct predictions: 12695, its 72.131%\n",
      "Epoch:  481 |---> loss is 1.0170730352, total correct predictions: 12876, its 73.159%\n",
      "Epoch:  482 |---> loss is 1.0125197172, total correct predictions: 12936, its 73.500%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  483 |---> loss is 1.0127646923, total correct predictions: 12917, its 73.392%\n",
      "Epoch:  484 |---> loss is 1.0131270885, total correct predictions: 12939, its 73.517%\n",
      "Epoch:  485 |---> loss is 1.0108956099, total correct predictions: 12962, its 73.648%\n",
      "Epoch:  486 |---> loss is 1.0113023520, total correct predictions: 12944, its 73.545%\n",
      "Epoch:  487 |---> loss is 1.0124348402, total correct predictions: 12943, its 73.540%\n",
      "Epoch:  488 |---> loss is 1.0108947754, total correct predictions: 12956, its 73.614%\n",
      "Epoch:  489 |---> loss is 1.0097794533, total correct predictions: 12986, its 73.784%\n",
      "Epoch:  490 |---> loss is 1.0107636452, total correct predictions: 12978, its 73.739%\n",
      "Epoch:  491 |---> loss is 1.0105625391, total correct predictions: 12967, its 73.676%\n",
      "Epoch:  492 |---> loss is 1.0088548660, total correct predictions: 13004, its 73.886%\n",
      "Epoch:  493 |---> loss is 1.0100635290, total correct predictions: 12999, its 73.858%\n",
      "Epoch:  494 |---> loss is 1.0161423683, total correct predictions: 12871, its 73.131%\n",
      "Epoch:  495 |---> loss is 1.0330694914, total correct predictions: 12494, its 70.989%\n",
      "Epoch:  496 |---> loss is 1.0306286812, total correct predictions: 12548, its 71.295%\n",
      "Epoch:  497 |---> loss is 1.0254842043, total correct predictions: 12641, its 71.824%\n",
      "Epoch:  498 |---> loss is 1.0110684633, total correct predictions: 12965, its 73.665%\n",
      "Epoch:  499 |---> loss is 1.0074721575, total correct predictions: 13030, its 74.034%\n"
     ]
    }
   ],
   "source": [
    "net_c = NetworkConv()\n",
    "print(net_c.conv1.weight)\n",
    "optimizer_c = optim.Adam(net_c.parameters(), lr=0.01, weight_decay=0.0001)\n",
    "number_of_epoches_c = 500\n",
    "# Here define weights for loss contribution of segments\n",
    "loss_weights_c = torch.tensor([1.,1.,1.,1.])\n",
    "\n",
    "total_loss_c = []\n",
    "total_accuracy_c = []\n",
    "total_val_loss_c = []\n",
    "total_val_accuracy_c = []\n",
    "for epoch in range(number_of_epoches_c):\n",
    "    predicted_c = net_c(train_features_c)\n",
    "    loss_c = F.cross_entropy(predicted_c, train_labels_c, loss_weights_c)\n",
    "    optimizer_c.zero_grad()\n",
    "    loss_c.backward()\n",
    "    optimizer_c.step()\n",
    "    \n",
    "    total_correct_c = get_correct_predictions(predicted_c, train_labels_c)\n",
    "    print(\"Epoch: {:4d} |---> loss is {:4.10f}, total correct predictions: {:5d}, its {:.3f}%\"\n",
    "      .format(epoch, loss_c.item(), total_correct_c, total_correct_c*100/train_features_c.shape[0]))\n",
    "    \n",
    "    with torch.no_grad():  # record loss and accuracy info for plots\n",
    "        total_loss_c.append(loss_c.item())\n",
    "        total_accuracy_c.append(total_correct_c*100/train_features_c.shape[0])\n",
    "        \n",
    "        test_preds_c = net_c(test_features_c)\n",
    "        total_val_loss_c.append(F.cross_entropy(test_preds_c, test_labels_c, loss_weights_c).item())\n",
    "        total_val_accuracy_c.append(get_correct_predictions(test_preds_c, test_labels_c)*100/test_features_c.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 60.34%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graphs and evaluation\n",
    "with torch.no_grad():\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(total_accuracy_c, label='accuracy')\n",
    "    plt.plot(total_val_accuracy_c, label = 'val_accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([0, 100])\n",
    "    plt.legend(loc='upper left')\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(total_loss_c, label='loss')\n",
    "    plt.plot(total_val_loss_c, label = 'val_loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    \n",
    "    \n",
    "    test_predictions_c = net_c(test_features_c)\n",
    "    test_correct_predictions_c = get_correct_predictions(test_predictions_c, test_labels_c)\n",
    "    print(\"Test accuracy is {:2.2f}%\" .format(test_correct_predictions_c * 100 /test_features_c.shape[0]))\n",
    "    \n",
    "    stacked_c = torch.stack((test_labels_c, test_predictions_c.argmax(dim=1)), dim=1)\n",
    "    confusion_matrix_c = torch.zeros((number_of_groups,number_of_groups), dtype=torch.int32)      # horizontal axis - predicted, vertical - true\n",
    "    for row in stacked_c:\n",
    "        confusion_matrix_c[row[0].item()][row[1].item()] += 1     # row is target, column - predicted\n",
    "    \n",
    "    # print(confusion_matrix)\n",
    "    # print(400 - torch.count_nonzero(test_labels_tensor).item())\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(confusion_matrix_c, cmap='winter')\n",
    "    \n",
    "    ax.set_xticks(np.arange(confusion_matrix_c.shape[0]))\n",
    "    ax.set_yticks(np.arange(confusion_matrix_c.shape[1]))\n",
    "    x_labels = []\n",
    "    y_labels = []\n",
    "    for i in range(confusion_matrix_c.shape[0]):\n",
    "        x_labels.append('Predicted: '+ str(i + 1))\n",
    "        y_labels.append('Real: ' + str(i + 1))\n",
    "    ax.set_xticklabels(x_labels)\n",
    "    ax.set_yticklabels(y_labels)\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "    \n",
    "    for i in range(confusion_matrix_c.shape[0]):\n",
    "        for j in range(confusion_matrix_c.shape[1]):\n",
    "            text = ax.text(j, i, str(round(confusion_matrix_c[i][j].item()*100/test_features_c.shape[0],2)) + '%', ha=\"center\", va=\"center\", size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60, 180])\n",
      "tensor([5.8509e+00, 4.7722e+00, 4.2107e+00, 2.8279e+00, 2.7520e+00, 2.5039e+00,\n",
      "        2.3486e+00, 2.1076e+00, 2.0159e+00, 1.8725e+00, 1.6458e+00, 1.5499e+00,\n",
      "        1.5084e+00, 1.3011e+00, 1.1872e+00, 1.1770e+00, 1.0972e+00, 1.0228e+00,\n",
      "        8.4517e-01, 7.9016e-01, 7.0318e-01, 5.7660e-01, 5.4587e-01, 4.4370e-01,\n",
      "        4.3103e-01, 3.8869e-01, 3.7050e-01, 3.3818e-01, 3.0510e-01, 2.8451e-01,\n",
      "        2.4735e-01, 2.1046e-01, 1.9155e-01, 1.8147e-01, 1.6024e-01, 1.5215e-01,\n",
      "        1.3297e-01, 1.2349e-01, 1.1691e-01, 1.0813e-01, 9.6738e-02, 8.9554e-02,\n",
      "        8.7246e-02, 7.5562e-02, 7.4372e-02, 7.1657e-02, 6.3605e-02, 6.0752e-02,\n",
      "        5.1835e-02, 4.8697e-02, 4.5742e-02, 4.3315e-02, 3.8393e-02, 3.6951e-02,\n",
      "        1.8220e-02, 1.1108e-02, 6.5835e-03, 2.3745e-03, 7.0252e-05, 1.4691e-05])\n",
      "torch.Size([16, 60])\n",
      "tensor([4.4479, 3.9111, 2.8382, 1.7617, 1.3033, 0.8572, 0.6947, 0.3375, 0.2980,\n",
      "        0.2068, 0.1491, 0.1151, 0.0824, 0.0227, 0.0130, 0.0068])\n"
     ]
    }
   ],
   "source": [
    "p1 = net_c.lin1.weight.clone().detach()\n",
    "print(p1.shape)\n",
    "u, s1, v = torch.svd(p1)\n",
    "print(s1)\n",
    "p2 = net_c.lin2.weight.clone().detach()\n",
    "print(p2.shape)\n",
    "u, s2, v = torch.svd(p2)\n",
    "print(s2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
