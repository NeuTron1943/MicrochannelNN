{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b(4x8) angles and r \n",
      "\n",
      "(22000, 192)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_detectors = 6\n",
    "number_of_features = n_detectors*4*8\n",
    "input_data = []\n",
    "with open('data/PD_three_rings_with_particle_mass_detector_2cm.dat', 'r') as inpf: \n",
    "    l = inpf.readline()\n",
    "    print(l)\n",
    "    for line in inpf:\n",
    "        features = []\n",
    "        s = line.strip().split()\n",
    "        b = float(s[0])\n",
    "        # for i in range(6):\n",
    "            # for digit in s[i + 1]:\n",
    "                # features.append(float(digit))\n",
    "        for digit in s[1:]:\n",
    "            features.append(float(digit))\n",
    "        input_data.append([b, features])\n",
    "    # print(len(input_data))\n",
    "    \n",
    "    np.random.shuffle(input_data)\n",
    "    input_sorted = sorted(input_data, key=lambda x: (x[0]))\n",
    "    # print(input_data)\n",
    "    \n",
    "    features = np.zeros((len(input_data), number_of_features))\n",
    "    labels = np.zeros((len(input_data), 1))\n",
    "    incr = 0\n",
    "    for elem in input_data:\n",
    "        labels[incr] = np.array(elem[0])\n",
    "        features[incr] = np.array(elem[1])\n",
    "        incr += 1\n",
    "    \n",
    "    # print(input_sorted[:5])\n",
    "    # print(input_data[:5])\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12.101]\n",
      " [ 9.87 ]\n",
      " [ 9.957]\n",
      " [12.355]\n",
      " [ 8.361]\n",
      " [ 7.321]\n",
      " [ 6.46 ]\n",
      " [ 7.758]\n",
      " [ 5.054]\n",
      " [12.326]]\n",
      "Length of segment: 5500\n",
      "Encoded into intervals: [(0, 6.974), (6.974, 9.814), (9.814, 12.043), (12.043, 16.347)]\n",
      "[[3]\n",
      " [2]\n",
      " [2]\n",
      " [3]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [3]]\n",
      "Set shape: (22000, 192)\n",
      "Train features shape: torch.Size([17600, 192])\n",
      "Train labels shape: torch.Size([17600])\n",
      "Test features shape: torch.Size([4400, 192])\n",
      "Test labels shape: torch.Size([4400])\n"
     ]
    }
   ],
   "source": [
    "# Encode labels into segments with equal length\n",
    "def encode_equi_segment(b: float, maximum: float, groups: int) -> int:\n",
    "    if b == maximum:\n",
    "        return groups - 1\n",
    "    else:\n",
    "        length_of_segment = maximum / groups\n",
    "        return int( b // length_of_segment )\n",
    "\n",
    "    \n",
    "# Encode labels into segments with equal size\n",
    "def encode_equi_size(labels_arr: np.ndarray, groups: int ) -> np.ndarray:\n",
    "    lb_sorted = np.sort(labels_arr, axis=0)\n",
    "    segment = lb_sorted.shape[0]//groups\n",
    "    print(\"Length of segment: {}\".format(segment))\n",
    "    borders = []\n",
    "    for i in range(groups):   # define borders of segments\n",
    "        if i != (groups - 1) and i != 0:\n",
    "            borders.append((lb_sorted[(i)*segment].item(), lb_sorted[(i+1)*segment].item()))\n",
    "        elif i == 0:\n",
    "            borders.append((0, lb_sorted[(i+1)*segment].item()))\n",
    "        else: \n",
    "            borders.append((lb_sorted[(i)*segment].item(), lb_sorted[labels.shape[0] - 1].item()))\n",
    "    print(\"Encoded into intervals: {}\" .format(borders))\n",
    "    lb_enc = np.zeros_like(labels, dtype=np.int)\n",
    "    incr = 0\n",
    "    for elem in labels:   # iterate over all (not sorted) labels and encode them\n",
    "        gr = 0\n",
    "        for seg in borders:\n",
    "            if seg[0] < elem <= seg[1]:\n",
    "                lb_enc[incr] = gr\n",
    "                break\n",
    "            gr += 1\n",
    "        incr += 1\n",
    "    return lb_enc\n",
    "\n",
    "\n",
    "number_of_groups = 4\n",
    "\n",
    "\n",
    "# labels_encoded_list = []\n",
    "# maximum_b = np.max(labels)\n",
    "# for label in labels:\n",
    "#     labels_encoded_list.append(encode_equi_segment(label[0], maximum_b, number_of_groups))\n",
    "# labels_encoded = np.array(labels_encoded_list)\n",
    "# train_labels = torch.flatten(torch.tensor(labels_encoded[:size_of_training_set]))\n",
    "# test_labels = torch.flatten(torch.tensor(labels_encoded[size_of_training_set:]))\n",
    "\n",
    "\n",
    "# Divide into test and training sets\n",
    "size_of_training_set = int(features.shape[0] * 0.8)\n",
    "size_of_test_set = features.shape[0] - size_of_training_set\n",
    "\n",
    "train_features = torch.tensor(features[:size_of_training_set], dtype=torch.float32)\n",
    "test_features = torch.tensor(features[size_of_training_set:], dtype=torch.float32)\n",
    "\n",
    "print(labels[:10])\n",
    "labels_encoded_equisized = encode_equi_size(labels, number_of_groups)\n",
    "print(labels_encoded_equisized[:10])\n",
    "train_labels = torch.flatten(torch.tensor(labels_encoded_equisized[:size_of_training_set]))\n",
    "test_labels = torch.flatten(torch.tensor(labels_encoded_equisized[size_of_training_set:]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Set shape: ' + str(features.shape))\n",
    "print('Train features shape: ' + str(train_features.shape))\n",
    "print('Train labels shape: ' + str(train_labels.shape))\n",
    "print('Test features shape: ' + str(test_features.shape))\n",
    "print('Test labels shape: ' + str(test_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Fully connected network. \n",
    "# Convolutional - three blocks below\n",
    "\n",
    "def get_correct_predictions(preds: torch.Tensor, values: torch.Tensor) -> int:\n",
    "    return preds.argmax(dim=1).eq(values).sum().item()\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.lin1 = nn.Linear(in_features = n_detectors*32, out_features = 64)\n",
    "        nn.init.normal_(self.lin1.weight, mean=0.0, std=0.02)\n",
    "        \n",
    "        self.lin2 = nn.Linear(in_features = 64, out_features = 16)\n",
    "        nn.init.normal_(self.lin2.weight, mean=0.0, std=0.02)\n",
    "        \n",
    "        # self.lin3 = nn.Linear(in_features = 16, out_features = 30)\n",
    "        # nn.init.normal_(self.lin3.weight, mean=0.0, std=0.02)\n",
    "        \n",
    "        # self.lin4 = nn.Linear(in_features = 30, out_features = 20)\n",
    "        # nn.init.normal_(self.lin4.weight, mean=0.0, std=0.02)\n",
    "        \n",
    "        # self.lin5 = nn.Linear(in_features = 20, out_features = 12)\n",
    "        # nn.init.normal_(self.lin5.weight, mean=0.0, std=0.02)\n",
    "        \n",
    "        # self.lin6 = nn.Linear(in_features = 12, out_features = 8)\n",
    "        # nn.init.normal_(self.lin6.weight, mean=0.0, std=0.02)\n",
    "        \n",
    "        self.out = nn.Linear(in_features = 16, out_features = number_of_groups)\n",
    "        nn.init.normal_(self.out.weight, mean=0.0, std=0.02)\n",
    "        # print(self.lin1.weight[:4, :8])\n",
    "        # print(self.lin2.weight[:4, :8])\n",
    "        # print(self.lin3.weight[:4, :8])\n",
    "        # print(self.out.weight)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        t = t\n",
    "        t = F.relu(self.lin1(t))\n",
    "        t = F.relu(self.lin2(t))\n",
    "        # t = F.relu(self.lin3(t))\n",
    "        # t = F.relu(self.lin4(t))\n",
    "        # t = F.relu(self.lin5(t))\n",
    "        # t = F.relu(self.lin6(t))\n",
    "        t = F.softmax(self.out(t), dim=1)\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0061,  0.0178,  0.0244, -0.0124,  0.0189,  0.0093, -0.0215,  0.0068,\n",
      "         -0.0327,  0.0060, -0.0031,  0.0134,  0.0250,  0.0132,  0.0232,  0.0180],\n",
      "        [-0.0047,  0.0056,  0.0083, -0.0247, -0.0237,  0.0072, -0.0068,  0.0113,\n",
      "         -0.0075,  0.0163,  0.0054, -0.0095,  0.0060, -0.0026,  0.0048,  0.0237],\n",
      "        [ 0.0191,  0.0070,  0.0022,  0.0104,  0.0017, -0.0257,  0.0098, -0.0158,\n",
      "          0.0141, -0.0427, -0.0061, -0.0162,  0.0208, -0.0252,  0.0172,  0.0078],\n",
      "        [-0.0185, -0.0062,  0.0188, -0.0209, -0.0023,  0.0256, -0.0094, -0.0112,\n",
      "          0.0240, -0.0291, -0.0169,  0.0012, -0.0060, -0.0154,  0.0261,  0.0337]],\n",
      "       requires_grad=True)\n",
      "Epoch:    0 |---> loss is 1.3869059086, total correct predictions:  4369, its 24.824%\n",
      "Epoch:    1 |---> loss is 1.3841309547, total correct predictions:  6774, its 38.489%\n",
      "Epoch:    2 |---> loss is 1.3737404346, total correct predictions:  6460, its 36.705%\n",
      "Epoch:    3 |---> loss is 1.3537939787, total correct predictions:  5908, its 33.568%\n",
      "Epoch:    4 |---> loss is 1.3350672722, total correct predictions:  5883, its 33.426%\n",
      "Epoch:    5 |---> loss is 1.3316118717, total correct predictions:  5891, its 33.472%\n",
      "Epoch:    6 |---> loss is 1.3278501034, total correct predictions:  5841, its 33.188%\n",
      "Epoch:    7 |---> loss is 1.3320207596, total correct predictions:  5953, its 33.824%\n",
      "Epoch:    8 |---> loss is 1.3321925402, total correct predictions:  6075, its 34.517%\n",
      "Epoch:    9 |---> loss is 1.3250707388, total correct predictions:  6173, its 35.074%\n",
      "Epoch:   10 |---> loss is 1.3189083338, total correct predictions:  6291, its 35.744%\n",
      "Epoch:   11 |---> loss is 1.3185983896, total correct predictions:  6523, its 37.062%\n",
      "Epoch:   12 |---> loss is 1.3173885345, total correct predictions:  6690, its 38.011%\n",
      "Epoch:   13 |---> loss is 1.3155953884, total correct predictions:  6878, its 39.080%\n",
      "Epoch:   14 |---> loss is 1.3126646280, total correct predictions:  7010, its 39.830%\n",
      "Epoch:   15 |---> loss is 1.3092130423, total correct predictions:  7421, its 42.165%\n",
      "Epoch:   16 |---> loss is 1.3059582710, total correct predictions:  7278, its 41.352%\n",
      "Epoch:   17 |---> loss is 1.3026051521, total correct predictions:  7299, its 41.472%\n",
      "Epoch:   18 |---> loss is 1.2998232841, total correct predictions:  7303, its 41.494%\n",
      "Epoch:   19 |---> loss is 1.2974915504, total correct predictions:  7267, its 41.290%\n",
      "Epoch:   20 |---> loss is 1.2932649851, total correct predictions:  7621, its 43.301%\n",
      "Epoch:   21 |---> loss is 1.2875823975, total correct predictions:  7573, its 43.028%\n",
      "Epoch:   22 |---> loss is 1.2821110487, total correct predictions:  7810, its 44.375%\n",
      "Epoch:   23 |---> loss is 1.2777469158, total correct predictions:  8057, its 45.778%\n",
      "Epoch:   24 |---> loss is 1.2728631496, total correct predictions:  8169, its 46.415%\n",
      "Epoch:   25 |---> loss is 1.2660353184, total correct predictions:  8298, its 47.148%\n",
      "Epoch:   26 |---> loss is 1.2597432137, total correct predictions:  8411, its 47.790%\n",
      "Epoch:   27 |---> loss is 1.2531094551, total correct predictions:  8529, its 48.460%\n",
      "Epoch:   28 |---> loss is 1.2450610399, total correct predictions:  8759, its 49.767%\n",
      "Epoch:   29 |---> loss is 1.2369669676, total correct predictions:  8952, its 50.864%\n",
      "Epoch:   30 |---> loss is 1.2297714949, total correct predictions:  9057, its 51.460%\n",
      "Epoch:   31 |---> loss is 1.2218631506, total correct predictions:  9109, its 51.756%\n",
      "Epoch:   32 |---> loss is 1.2145398855, total correct predictions:  9169, its 52.097%\n",
      "Epoch:   33 |---> loss is 1.2074091434, total correct predictions:  9240, its 52.500%\n",
      "Epoch:   34 |---> loss is 1.2003151178, total correct predictions:  9282, its 52.739%\n",
      "Epoch:   35 |---> loss is 1.1945005655, total correct predictions:  9367, its 53.222%\n",
      "Epoch:   36 |---> loss is 1.1883547306, total correct predictions:  9416, its 53.500%\n",
      "Epoch:   37 |---> loss is 1.1830500364, total correct predictions:  9466, its 53.784%\n",
      "Epoch:   38 |---> loss is 1.1776044369, total correct predictions:  9585, its 54.460%\n",
      "Epoch:   39 |---> loss is 1.1720647812, total correct predictions:  9678, its 54.989%\n",
      "Epoch:   40 |---> loss is 1.1666131020, total correct predictions:  9808, its 55.727%\n",
      "Epoch:   41 |---> loss is 1.1613633633, total correct predictions:  9914, its 56.330%\n",
      "Epoch:   42 |---> loss is 1.1563605070, total correct predictions: 10033, its 57.006%\n",
      "Epoch:   43 |---> loss is 1.1516414881, total correct predictions: 10121, its 57.506%\n",
      "Epoch:   44 |---> loss is 1.1472176313, total correct predictions: 10232, its 58.136%\n",
      "Epoch:   45 |---> loss is 1.1426773071, total correct predictions: 10344, its 58.773%\n",
      "Epoch:   46 |---> loss is 1.1380960941, total correct predictions: 10470, its 59.489%\n",
      "Epoch:   47 |---> loss is 1.1328663826, total correct predictions: 10611, its 60.290%\n",
      "Epoch:   48 |---> loss is 1.1279793978, total correct predictions: 10723, its 60.926%\n",
      "Epoch:   49 |---> loss is 1.1225841045, total correct predictions: 10894, its 61.898%\n",
      "Epoch:   50 |---> loss is 1.1172342300, total correct predictions: 11064, its 62.864%\n",
      "Epoch:   51 |---> loss is 1.1122089624, total correct predictions: 11186, its 63.557%\n",
      "Epoch:   52 |---> loss is 1.1075249910, total correct predictions: 11298, its 64.193%\n",
      "Epoch:   53 |---> loss is 1.1025726795, total correct predictions: 11411, its 64.835%\n",
      "Epoch:   54 |---> loss is 1.0967572927, total correct predictions: 11550, its 65.625%\n",
      "Epoch:   55 |---> loss is 1.0896008015, total correct predictions: 11719, its 66.585%\n",
      "Epoch:   56 |---> loss is 1.0839321613, total correct predictions: 11853, its 67.347%\n",
      "Epoch:   57 |---> loss is 1.0803121328, total correct predictions: 11964, its 67.977%\n",
      "Epoch:   58 |---> loss is 1.0760954618, total correct predictions: 12013, its 68.256%\n",
      "Epoch:   59 |---> loss is 1.0698041916, total correct predictions: 12171, its 69.153%\n",
      "Epoch:   60 |---> loss is 1.0632715225, total correct predictions: 12276, its 69.750%\n",
      "Epoch:   61 |---> loss is 1.0582940578, total correct predictions: 12395, its 70.426%\n",
      "Epoch:   62 |---> loss is 1.0546275377, total correct predictions: 12420, its 70.568%\n",
      "Epoch:   63 |---> loss is 1.0518069267, total correct predictions: 12430, its 70.625%\n",
      "Epoch:   64 |---> loss is 1.0491496325, total correct predictions: 12462, its 70.807%\n",
      "Epoch:   65 |---> loss is 1.0420173407, total correct predictions: 12577, its 71.460%\n",
      "Epoch:   66 |---> loss is 1.0359883308, total correct predictions: 12663, its 71.949%\n",
      "Epoch:   67 |---> loss is 1.0329974890, total correct predictions: 12703, its 72.176%\n",
      "Epoch:   68 |---> loss is 1.0310389996, total correct predictions: 12725, its 72.301%\n",
      "Epoch:   69 |---> loss is 1.0280166864, total correct predictions: 12786, its 72.648%\n",
      "Epoch:   70 |---> loss is 1.0235892534, total correct predictions: 12863, its 73.085%\n",
      "Epoch:   71 |---> loss is 1.0185068846, total correct predictions: 12954, its 73.602%\n",
      "Epoch:   72 |---> loss is 1.0152796507, total correct predictions: 12993, its 73.824%\n",
      "Epoch:   73 |---> loss is 1.0142757893, total correct predictions: 12982, its 73.761%\n",
      "Epoch:   74 |---> loss is 1.0144945383, total correct predictions: 12977, its 73.733%\n",
      "Epoch:   75 |---> loss is 1.0125731230, total correct predictions: 12984, its 73.773%\n",
      "Epoch:   76 |---> loss is 1.0072926283, total correct predictions: 13116, its 74.523%\n",
      "Epoch:   77 |---> loss is 1.0029364824, total correct predictions: 13188, its 74.932%\n",
      "Epoch:   78 |---> loss is 1.0029914379, total correct predictions: 13167, its 74.812%\n",
      "Epoch:   79 |---> loss is 1.0026363134, total correct predictions: 13181, its 74.892%\n",
      "Epoch:   80 |---> loss is 0.9982944727, total correct predictions: 13259, its 75.335%\n",
      "Epoch:   81 |---> loss is 0.9951063991, total correct predictions: 13306, its 75.602%\n",
      "Epoch:   82 |---> loss is 0.9949601889, total correct predictions: 13311, its 75.631%\n",
      "Epoch:   83 |---> loss is 0.9962970614, total correct predictions: 13283, its 75.472%\n",
      "Epoch:   84 |---> loss is 0.9967491627, total correct predictions: 13255, its 75.312%\n",
      "Epoch:   85 |---> loss is 0.9911391139, total correct predictions: 13395, its 76.108%\n",
      "Epoch:   86 |---> loss is 0.9871757627, total correct predictions: 13496, its 76.682%\n",
      "Epoch:   87 |---> loss is 0.9875240922, total correct predictions: 13457, its 76.460%\n",
      "Epoch:   88 |---> loss is 0.9876242876, total correct predictions: 13461, its 76.483%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   89 |---> loss is 0.9865375161, total correct predictions: 13474, its 76.557%\n",
      "Epoch:   90 |---> loss is 0.9832586050, total correct predictions: 13549, its 76.983%\n",
      "Epoch:   91 |---> loss is 0.9806222320, total correct predictions: 13607, its 77.312%\n",
      "Epoch:   92 |---> loss is 0.9811814427, total correct predictions: 13574, its 77.125%\n",
      "Epoch:   93 |---> loss is 0.9815229774, total correct predictions: 13578, its 77.148%\n",
      "Epoch:   94 |---> loss is 0.9808742404, total correct predictions: 13556, its 77.023%\n",
      "Epoch:   95 |---> loss is 0.9779558778, total correct predictions: 13654, its 77.580%\n",
      "Epoch:   96 |---> loss is 0.9749325514, total correct predictions: 13710, its 77.898%\n",
      "Epoch:   97 |---> loss is 0.9750358462, total correct predictions: 13687, its 77.767%\n",
      "Epoch:   98 |---> loss is 0.9753980637, total correct predictions: 13701, its 77.847%\n",
      "Epoch:   99 |---> loss is 0.9745661020, total correct predictions: 13709, its 77.892%\n",
      "Epoch:  100 |---> loss is 0.9727473855, total correct predictions: 13750, its 78.125%\n",
      "Epoch:  101 |---> loss is 0.9699672461, total correct predictions: 13821, its 78.528%\n",
      "Epoch:  102 |---> loss is 0.9689624906, total correct predictions: 13833, its 78.597%\n",
      "Epoch:  103 |---> loss is 0.9689278603, total correct predictions: 13843, its 78.653%\n",
      "Epoch:  104 |---> loss is 0.9691692591, total correct predictions: 13828, its 78.568%\n",
      "Epoch:  105 |---> loss is 0.9690805674, total correct predictions: 13813, its 78.483%\n",
      "Epoch:  106 |---> loss is 0.9686350226, total correct predictions: 13839, its 78.631%\n",
      "Epoch:  107 |---> loss is 0.9664896131, total correct predictions: 13890, its 78.920%\n",
      "Epoch:  108 |---> loss is 0.9641033411, total correct predictions: 13925, its 79.119%\n",
      "Epoch:  109 |---> loss is 0.9626120925, total correct predictions: 13963, its 79.335%\n",
      "Epoch:  110 |---> loss is 0.9631270170, total correct predictions: 13939, its 79.199%\n",
      "Epoch:  111 |---> loss is 0.9633237720, total correct predictions: 13939, its 79.199%\n",
      "Epoch:  112 |---> loss is 0.9623727202, total correct predictions: 13942, its 79.216%\n",
      "Epoch:  113 |---> loss is 0.9608761072, total correct predictions: 13988, its 79.477%\n",
      "Epoch:  114 |---> loss is 0.9586846232, total correct predictions: 14027, its 79.699%\n",
      "Epoch:  115 |---> loss is 0.9577828646, total correct predictions: 14039, its 79.767%\n",
      "Epoch:  116 |---> loss is 0.9581909180, total correct predictions: 14029, its 79.710%\n",
      "Epoch:  117 |---> loss is 0.9584186077, total correct predictions: 14040, its 79.773%\n",
      "Epoch:  118 |---> loss is 0.9590668082, total correct predictions: 13997, its 79.528%\n",
      "Epoch:  119 |---> loss is 0.9595685601, total correct predictions: 13990, its 79.489%\n",
      "Epoch:  120 |---> loss is 0.9597678185, total correct predictions: 13962, its 79.330%\n",
      "Epoch:  121 |---> loss is 0.9573015571, total correct predictions: 14031, its 79.722%\n",
      "Epoch:  122 |---> loss is 0.9540192485, total correct predictions: 14097, its 80.097%\n",
      "Epoch:  123 |---> loss is 0.9524331093, total correct predictions: 14130, its 80.284%\n",
      "Epoch:  124 |---> loss is 0.9536958337, total correct predictions: 14101, its 80.119%\n",
      "Epoch:  125 |---> loss is 0.9526928663, total correct predictions: 14136, its 80.318%\n",
      "Epoch:  126 |---> loss is 0.9504071474, total correct predictions: 14162, its 80.466%\n",
      "Epoch:  127 |---> loss is 0.9500912428, total correct predictions: 14177, its 80.551%\n",
      "Epoch:  128 |---> loss is 0.9504874945, total correct predictions: 14165, its 80.483%\n",
      "Epoch:  129 |---> loss is 0.9496175647, total correct predictions: 14180, its 80.568%\n",
      "Epoch:  130 |---> loss is 0.9482764602, total correct predictions: 14211, its 80.744%\n",
      "Epoch:  131 |---> loss is 0.9472505450, total correct predictions: 14231, its 80.858%\n",
      "Epoch:  132 |---> loss is 0.9470435977, total correct predictions: 14227, its 80.835%\n",
      "Epoch:  133 |---> loss is 0.9472285509, total correct predictions: 14233, its 80.869%\n",
      "Epoch:  134 |---> loss is 0.9468477964, total correct predictions: 14239, its 80.903%\n",
      "Epoch:  135 |---> loss is 0.9461449981, total correct predictions: 14256, its 81.000%\n",
      "Epoch:  136 |---> loss is 0.9450418353, total correct predictions: 14270, its 81.080%\n",
      "Epoch:  137 |---> loss is 0.9440986514, total correct predictions: 14274, its 81.102%\n",
      "Epoch:  138 |---> loss is 0.9434682131, total correct predictions: 14292, its 81.205%\n",
      "Epoch:  139 |---> loss is 0.9430923462, total correct predictions: 14299, its 81.244%\n",
      "Epoch:  140 |---> loss is 0.9430386424, total correct predictions: 14301, its 81.256%\n",
      "Epoch:  141 |---> loss is 0.9434358478, total correct predictions: 14295, its 81.222%\n",
      "Epoch:  142 |---> loss is 0.9454327822, total correct predictions: 14241, its 80.915%\n",
      "Epoch:  143 |---> loss is 0.9507364035, total correct predictions: 14117, its 80.210%\n",
      "Epoch:  144 |---> loss is 0.9640618563, total correct predictions: 13791, its 78.358%\n",
      "Epoch:  145 |---> loss is 0.9409056306, total correct predictions: 14325, its 81.392%\n",
      "Epoch:  146 |---> loss is 0.9565845728, total correct predictions: 13954, its 79.284%\n",
      "Epoch:  147 |---> loss is 0.9650161862, total correct predictions: 13778, its 78.284%\n",
      "Epoch:  148 |---> loss is 0.9481775165, total correct predictions: 14142, its 80.352%\n",
      "Epoch:  149 |---> loss is 0.9774523973, total correct predictions: 13513, its 76.778%\n",
      "Epoch:  150 |---> loss is 0.9496577382, total correct predictions: 14105, its 80.142%\n",
      "Epoch:  151 |---> loss is 0.9774996638, total correct predictions: 13526, its 76.852%\n",
      "Epoch:  152 |---> loss is 0.9684122205, total correct predictions: 13729, its 78.006%\n",
      "Epoch:  153 |---> loss is 0.9508663416, total correct predictions: 14073, its 79.960%\n",
      "Epoch:  154 |---> loss is 0.9651544690, total correct predictions: 13763, its 78.199%\n",
      "Epoch:  155 |---> loss is 0.9440637231, total correct predictions: 14217, its 80.778%\n",
      "Epoch:  156 |---> loss is 0.9593195319, total correct predictions: 13908, its 79.023%\n",
      "Epoch:  157 |---> loss is 0.9433043599, total correct predictions: 14234, its 80.875%\n",
      "Epoch:  158 |---> loss is 0.9539739490, total correct predictions: 14016, its 79.636%\n",
      "Epoch:  159 |---> loss is 0.9453687668, total correct predictions: 14174, its 80.534%\n",
      "Epoch:  160 |---> loss is 0.9450928569, total correct predictions: 14178, its 80.557%\n",
      "Epoch:  161 |---> loss is 0.9471499920, total correct predictions: 14154, its 80.420%\n",
      "Epoch:  162 |---> loss is 0.9403569102, total correct predictions: 14273, its 81.097%\n",
      "Epoch:  163 |---> loss is 0.9471632838, total correct predictions: 14145, its 80.369%\n",
      "Epoch:  164 |---> loss is 0.9382858872, total correct predictions: 14309, its 81.301%\n",
      "Epoch:  165 |---> loss is 0.9446285963, total correct predictions: 14205, its 80.710%\n",
      "Epoch:  166 |---> loss is 0.9388314486, total correct predictions: 14314, its 81.330%\n",
      "Epoch:  167 |---> loss is 0.9411962032, total correct predictions: 14268, its 81.068%\n",
      "Epoch:  168 |---> loss is 0.9383444786, total correct predictions: 14306, its 81.284%\n",
      "Epoch:  169 |---> loss is 0.9376977682, total correct predictions: 14322, its 81.375%\n",
      "Epoch:  170 |---> loss is 0.9381286502, total correct predictions: 14320, its 81.364%\n",
      "Epoch:  171 |---> loss is 0.9358339906, total correct predictions: 14355, its 81.562%\n",
      "Epoch:  172 |---> loss is 0.9371444583, total correct predictions: 14338, its 81.466%\n",
      "Epoch:  173 |---> loss is 0.9342952967, total correct predictions: 14390, its 81.761%\n",
      "Epoch:  174 |---> loss is 0.9360557795, total correct predictions: 14359, its 81.585%\n",
      "Epoch:  175 |---> loss is 0.9333027601, total correct predictions: 14421, its 81.938%\n",
      "Epoch:  176 |---> loss is 0.9350059628, total correct predictions: 14389, its 81.756%\n",
      "Epoch:  177 |---> loss is 0.9323225617, total correct predictions: 14439, its 82.040%\n",
      "Epoch:  178 |---> loss is 0.9333708286, total correct predictions: 14409, its 81.869%\n",
      "Epoch:  179 |---> loss is 0.9314387441, total correct predictions: 14449, its 82.097%\n",
      "Epoch:  180 |---> loss is 0.9320479035, total correct predictions: 14454, its 82.125%\n",
      "Epoch:  181 |---> loss is 0.9308296442, total correct predictions: 14457, its 82.142%\n",
      "Epoch:  182 |---> loss is 0.9310873151, total correct predictions: 14457, its 82.142%\n",
      "Epoch:  183 |---> loss is 0.9300661087, total correct predictions: 14476, its 82.250%\n",
      "Epoch:  184 |---> loss is 0.9300417900, total correct predictions: 14477, its 82.256%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  185 |---> loss is 0.9293582439, total correct predictions: 14485, its 82.301%\n",
      "Epoch:  186 |---> loss is 0.9290587902, total correct predictions: 14500, its 82.386%\n",
      "Epoch:  187 |---> loss is 0.9284980893, total correct predictions: 14511, its 82.449%\n",
      "Epoch:  188 |---> loss is 0.9280976653, total correct predictions: 14516, its 82.477%\n",
      "Epoch:  189 |---> loss is 0.9278910756, total correct predictions: 14524, its 82.523%\n",
      "Epoch:  190 |---> loss is 0.9272648096, total correct predictions: 14543, its 82.631%\n",
      "Epoch:  191 |---> loss is 0.9272542596, total correct predictions: 14534, its 82.580%\n",
      "Epoch:  192 |---> loss is 0.9264402986, total correct predictions: 14555, its 82.699%\n",
      "Epoch:  193 |---> loss is 0.9264782071, total correct predictions: 14554, its 82.693%\n",
      "Epoch:  194 |---> loss is 0.9258595109, total correct predictions: 14564, its 82.750%\n",
      "Epoch:  195 |---> loss is 0.9257482290, total correct predictions: 14563, its 82.744%\n",
      "Epoch:  196 |---> loss is 0.9252864122, total correct predictions: 14572, its 82.795%\n",
      "Epoch:  197 |---> loss is 0.9250652790, total correct predictions: 14574, its 82.807%\n",
      "Epoch:  198 |---> loss is 0.9247555137, total correct predictions: 14580, its 82.841%\n",
      "Epoch:  199 |---> loss is 0.9244047999, total correct predictions: 14581, its 82.847%\n",
      "Epoch:  200 |---> loss is 0.9242207408, total correct predictions: 14589, its 82.892%\n",
      "Epoch:  201 |---> loss is 0.9238102436, total correct predictions: 14587, its 82.881%\n",
      "Epoch:  202 |---> loss is 0.9236304760, total correct predictions: 14595, its 82.926%\n",
      "Epoch:  203 |---> loss is 0.9232643247, total correct predictions: 14606, its 82.989%\n",
      "Epoch:  204 |---> loss is 0.9229571223, total correct predictions: 14611, its 83.017%\n",
      "Epoch:  205 |---> loss is 0.9227018952, total correct predictions: 14616, its 83.045%\n",
      "Epoch:  206 |---> loss is 0.9223347902, total correct predictions: 14618, its 83.057%\n",
      "Epoch:  207 |---> loss is 0.9221002460, total correct predictions: 14625, its 83.097%\n",
      "Epoch:  208 |---> loss is 0.9217966199, total correct predictions: 14629, its 83.119%\n",
      "Epoch:  209 |---> loss is 0.9216064811, total correct predictions: 14628, its 83.114%\n",
      "Epoch:  210 |---> loss is 0.9212991595, total correct predictions: 14634, its 83.148%\n",
      "Epoch:  211 |---> loss is 0.9210268855, total correct predictions: 14635, its 83.153%\n",
      "Epoch:  212 |---> loss is 0.9207985997, total correct predictions: 14637, its 83.165%\n",
      "Epoch:  213 |---> loss is 0.9205113053, total correct predictions: 14644, its 83.205%\n",
      "Epoch:  214 |---> loss is 0.9202803373, total correct predictions: 14647, its 83.222%\n",
      "Epoch:  215 |---> loss is 0.9199817181, total correct predictions: 14649, its 83.233%\n",
      "Epoch:  216 |---> loss is 0.9196890593, total correct predictions: 14653, its 83.256%\n",
      "Epoch:  217 |---> loss is 0.9194356203, total correct predictions: 14661, its 83.301%\n",
      "Epoch:  218 |---> loss is 0.9191192389, total correct predictions: 14665, its 83.324%\n",
      "Epoch:  219 |---> loss is 0.9188520312, total correct predictions: 14672, its 83.364%\n",
      "Epoch:  220 |---> loss is 0.9185774326, total correct predictions: 14679, its 83.403%\n",
      "Epoch:  221 |---> loss is 0.9183564186, total correct predictions: 14684, its 83.432%\n",
      "Epoch:  222 |---> loss is 0.9181511402, total correct predictions: 14687, its 83.449%\n",
      "Epoch:  223 |---> loss is 0.9178546667, total correct predictions: 14690, its 83.466%\n",
      "Epoch:  224 |---> loss is 0.9176349640, total correct predictions: 14696, its 83.500%\n",
      "Epoch:  225 |---> loss is 0.9174098372, total correct predictions: 14696, its 83.500%\n",
      "Epoch:  226 |---> loss is 0.9172104001, total correct predictions: 14697, its 83.506%\n",
      "Epoch:  227 |---> loss is 0.9169908762, total correct predictions: 14700, its 83.523%\n",
      "Epoch:  228 |---> loss is 0.9167645574, total correct predictions: 14703, its 83.540%\n",
      "Epoch:  229 |---> loss is 0.9165428281, total correct predictions: 14703, its 83.540%\n",
      "Epoch:  230 |---> loss is 0.9163377285, total correct predictions: 14704, its 83.545%\n",
      "Epoch:  231 |---> loss is 0.9161339402, total correct predictions: 14708, its 83.568%\n",
      "Epoch:  232 |---> loss is 0.9159384370, total correct predictions: 14712, its 83.591%\n",
      "Epoch:  233 |---> loss is 0.9157325625, total correct predictions: 14714, its 83.602%\n",
      "Epoch:  234 |---> loss is 0.9155215025, total correct predictions: 14715, its 83.608%\n",
      "Epoch:  235 |---> loss is 0.9153303504, total correct predictions: 14717, its 83.619%\n",
      "Epoch:  236 |---> loss is 0.9151446819, total correct predictions: 14716, its 83.614%\n",
      "Epoch:  237 |---> loss is 0.9149453044, total correct predictions: 14719, its 83.631%\n",
      "Epoch:  238 |---> loss is 0.9147326946, total correct predictions: 14724, its 83.659%\n",
      "Epoch:  239 |---> loss is 0.9145411253, total correct predictions: 14728, its 83.682%\n",
      "Epoch:  240 |---> loss is 0.9143485427, total correct predictions: 14731, its 83.699%\n",
      "Epoch:  241 |---> loss is 0.9141732454, total correct predictions: 14731, its 83.699%\n",
      "Epoch:  242 |---> loss is 0.9139810801, total correct predictions: 14733, its 83.710%\n",
      "Epoch:  243 |---> loss is 0.9137893915, total correct predictions: 14737, its 83.733%\n",
      "Epoch:  244 |---> loss is 0.9135692716, total correct predictions: 14740, its 83.750%\n",
      "Epoch:  245 |---> loss is 0.9133738875, total correct predictions: 14746, its 83.784%\n",
      "Epoch:  246 |---> loss is 0.9131852984, total correct predictions: 14749, its 83.801%\n",
      "Epoch:  247 |---> loss is 0.9130045176, total correct predictions: 14752, its 83.818%\n",
      "Epoch:  248 |---> loss is 0.9128169417, total correct predictions: 14755, its 83.835%\n",
      "Epoch:  249 |---> loss is 0.9126396775, total correct predictions: 14759, its 83.858%\n",
      "Epoch:  250 |---> loss is 0.9124611616, total correct predictions: 14764, its 83.886%\n",
      "Epoch:  251 |---> loss is 0.9122706652, total correct predictions: 14766, its 83.898%\n",
      "Epoch:  252 |---> loss is 0.9120814800, total correct predictions: 14769, its 83.915%\n",
      "Epoch:  253 |---> loss is 0.9119103551, total correct predictions: 14772, its 83.932%\n",
      "Epoch:  254 |---> loss is 0.9117482305, total correct predictions: 14775, its 83.949%\n",
      "Epoch:  255 |---> loss is 0.9115877748, total correct predictions: 14778, its 83.966%\n",
      "Epoch:  256 |---> loss is 0.9114223123, total correct predictions: 14780, its 83.977%\n",
      "Epoch:  257 |---> loss is 0.9112625122, total correct predictions: 14782, its 83.989%\n",
      "Epoch:  258 |---> loss is 0.9111090899, total correct predictions: 14782, its 83.989%\n",
      "Epoch:  259 |---> loss is 0.9109498262, total correct predictions: 14784, its 84.000%\n",
      "Epoch:  260 |---> loss is 0.9107966423, total correct predictions: 14785, its 84.006%\n",
      "Epoch:  261 |---> loss is 0.9106428027, total correct predictions: 14785, its 84.006%\n",
      "Epoch:  262 |---> loss is 0.9104942679, total correct predictions: 14788, its 84.023%\n",
      "Epoch:  263 |---> loss is 0.9103477001, total correct predictions: 14789, its 84.028%\n",
      "Epoch:  264 |---> loss is 0.9102075100, total correct predictions: 14789, its 84.028%\n",
      "Epoch:  265 |---> loss is 0.9100588560, total correct predictions: 14792, its 84.045%\n",
      "Epoch:  266 |---> loss is 0.9099118710, total correct predictions: 14790, its 84.034%\n",
      "Epoch:  267 |---> loss is 0.9097656012, total correct predictions: 14793, its 84.051%\n",
      "Epoch:  268 |---> loss is 0.9096204042, total correct predictions: 14795, its 84.062%\n",
      "Epoch:  269 |---> loss is 0.9094757438, total correct predictions: 14797, its 84.074%\n",
      "Epoch:  270 |---> loss is 0.9093317986, total correct predictions: 14799, its 84.085%\n",
      "Epoch:  271 |---> loss is 0.9091894031, total correct predictions: 14803, its 84.108%\n",
      "Epoch:  272 |---> loss is 0.9090532660, total correct predictions: 14803, its 84.108%\n",
      "Epoch:  273 |---> loss is 0.9089211226, total correct predictions: 14805, its 84.119%\n",
      "Epoch:  274 |---> loss is 0.9087894559, total correct predictions: 14805, its 84.119%\n",
      "Epoch:  275 |---> loss is 0.9086582065, total correct predictions: 14807, its 84.131%\n",
      "Epoch:  276 |---> loss is 0.9085260034, total correct predictions: 14806, its 84.125%\n",
      "Epoch:  277 |---> loss is 0.9083963037, total correct predictions: 14809, its 84.142%\n",
      "Epoch:  278 |---> loss is 0.9082652330, total correct predictions: 14808, its 84.136%\n",
      "Epoch:  279 |---> loss is 0.9081317782, total correct predictions: 14810, its 84.148%\n",
      "Epoch:  280 |---> loss is 0.9079955816, total correct predictions: 14815, its 84.176%\n",
      "Epoch:  281 |---> loss is 0.9078667164, total correct predictions: 14816, its 84.182%\n",
      "Epoch:  282 |---> loss is 0.9077382684, total correct predictions: 14817, its 84.188%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  283 |---> loss is 0.9076095819, total correct predictions: 14818, its 84.193%\n",
      "Epoch:  284 |---> loss is 0.9074850082, total correct predictions: 14819, its 84.199%\n",
      "Epoch:  285 |---> loss is 0.9073621035, total correct predictions: 14817, its 84.188%\n",
      "Epoch:  286 |---> loss is 0.9072377086, total correct predictions: 14820, its 84.205%\n",
      "Epoch:  287 |---> loss is 0.9071139097, total correct predictions: 14820, its 84.205%\n",
      "Epoch:  288 |---> loss is 0.9069908857, total correct predictions: 14823, its 84.222%\n",
      "Epoch:  289 |---> loss is 0.9068674445, total correct predictions: 14825, its 84.233%\n",
      "Epoch:  290 |---> loss is 0.9067466259, total correct predictions: 14826, its 84.239%\n",
      "Epoch:  291 |---> loss is 0.9066262841, total correct predictions: 14828, its 84.250%\n",
      "Epoch:  292 |---> loss is 0.9065156579, total correct predictions: 14828, its 84.250%\n",
      "Epoch:  293 |---> loss is 0.9064016342, total correct predictions: 14829, its 84.256%\n",
      "Epoch:  294 |---> loss is 0.9062873125, total correct predictions: 14831, its 84.267%\n",
      "Epoch:  295 |---> loss is 0.9061767459, total correct predictions: 14832, its 84.273%\n",
      "Epoch:  296 |---> loss is 0.9060650468, total correct predictions: 14833, its 84.278%\n",
      "Epoch:  297 |---> loss is 0.9059532881, total correct predictions: 14834, its 84.284%\n",
      "Epoch:  298 |---> loss is 0.9058425426, total correct predictions: 14834, its 84.284%\n",
      "Epoch:  299 |---> loss is 0.9057350159, total correct predictions: 14834, its 84.284%\n",
      "Epoch:  300 |---> loss is 0.9056221247, total correct predictions: 14836, its 84.295%\n",
      "Epoch:  301 |---> loss is 0.9055185318, total correct predictions: 14840, its 84.318%\n",
      "Epoch:  302 |---> loss is 0.9054237008, total correct predictions: 14839, its 84.312%\n",
      "Epoch:  303 |---> loss is 0.9053045511, total correct predictions: 14843, its 84.335%\n",
      "Epoch:  304 |---> loss is 0.9052695632, total correct predictions: 14846, its 84.352%\n",
      "Epoch:  305 |---> loss is 0.9053180218, total correct predictions: 14846, its 84.352%\n",
      "Epoch:  306 |---> loss is 0.9054167867, total correct predictions: 14846, its 84.352%\n",
      "Epoch:  307 |---> loss is 0.9056976438, total correct predictions: 14849, its 84.369%\n",
      "Epoch:  308 |---> loss is 0.9067450762, total correct predictions: 14843, its 84.335%\n",
      "Epoch:  309 |---> loss is 0.9126676321, total correct predictions: 14753, its 83.824%\n",
      "Epoch:  310 |---> loss is 0.9522185922, total correct predictions: 13972, its 79.386%\n",
      "Epoch:  311 |---> loss is 0.9379928112, total correct predictions: 14186, its 80.602%\n",
      "Epoch:  312 |---> loss is 0.9688279033, total correct predictions: 13606, its 77.307%\n",
      "Epoch:  313 |---> loss is 0.9513476491, total correct predictions: 13904, its 79.000%\n",
      "Epoch:  314 |---> loss is 0.9465172291, total correct predictions: 14079, its 79.994%\n",
      "Epoch:  315 |---> loss is 0.9623175859, total correct predictions: 13756, its 78.159%\n",
      "Epoch:  316 |---> loss is 0.9431042671, total correct predictions: 14112, its 80.182%\n",
      "Epoch:  317 |---> loss is 0.9340324402, total correct predictions: 14289, its 81.188%\n",
      "Epoch:  318 |---> loss is 0.9465965629, total correct predictions: 14050, its 79.830%\n",
      "Epoch:  319 |---> loss is 0.9331169128, total correct predictions: 14284, its 81.159%\n",
      "Epoch:  320 |---> loss is 0.9288823605, total correct predictions: 14406, its 81.852%\n",
      "Epoch:  321 |---> loss is 0.9397543073, total correct predictions: 14188, its 80.614%\n",
      "Epoch:  322 |---> loss is 0.9319679737, total correct predictions: 14323, its 81.381%\n",
      "Epoch:  323 |---> loss is 0.9174692631, total correct predictions: 14619, its 83.062%\n",
      "Epoch:  324 |---> loss is 0.9353087544, total correct predictions: 14280, its 81.136%\n",
      "Epoch:  325 |---> loss is 0.9268851280, total correct predictions: 14453, its 82.119%\n",
      "Epoch:  326 |---> loss is 0.9176826477, total correct predictions: 14640, its 83.182%\n",
      "Epoch:  327 |---> loss is 0.9256144166, total correct predictions: 14482, its 82.284%\n",
      "Epoch:  328 |---> loss is 0.9255399108, total correct predictions: 14473, its 82.233%\n",
      "Epoch:  329 |---> loss is 0.9157048464, total correct predictions: 14649, its 83.233%\n",
      "Epoch:  330 |---> loss is 0.9158696532, total correct predictions: 14636, its 83.159%\n",
      "Epoch:  331 |---> loss is 0.9233336449, total correct predictions: 14494, its 82.352%\n",
      "Epoch:  332 |---> loss is 0.9129204154, total correct predictions: 14703, its 83.540%\n",
      "Epoch:  333 |---> loss is 0.9130520821, total correct predictions: 14706, its 83.557%\n",
      "Epoch:  334 |---> loss is 0.9167531133, total correct predictions: 14654, its 83.261%\n",
      "Epoch:  335 |---> loss is 0.9123502970, total correct predictions: 14724, its 83.659%\n",
      "Epoch:  336 |---> loss is 0.9089567065, total correct predictions: 14792, its 84.045%\n",
      "Epoch:  337 |---> loss is 0.9131509066, total correct predictions: 14707, its 83.562%\n",
      "Epoch:  338 |---> loss is 0.9091605544, total correct predictions: 14789, its 84.028%\n",
      "Epoch:  339 |---> loss is 0.9079162478, total correct predictions: 14814, its 84.170%\n",
      "Epoch:  340 |---> loss is 0.9097483158, total correct predictions: 14776, its 83.955%\n",
      "Epoch:  341 |---> loss is 0.9078907967, total correct predictions: 14810, its 84.148%\n",
      "Epoch:  342 |---> loss is 0.9062023759, total correct predictions: 14825, its 84.233%\n",
      "Epoch:  343 |---> loss is 0.9075828195, total correct predictions: 14804, its 84.114%\n",
      "Epoch:  344 |---> loss is 0.9057729244, total correct predictions: 14844, its 84.341%\n",
      "Epoch:  345 |---> loss is 0.9048945904, total correct predictions: 14853, its 84.392%\n",
      "Epoch:  346 |---> loss is 0.9053408504, total correct predictions: 14847, its 84.358%\n",
      "Epoch:  347 |---> loss is 0.9044264555, total correct predictions: 14868, its 84.477%\n",
      "Epoch:  348 |---> loss is 0.9037073255, total correct predictions: 14875, its 84.517%\n",
      "Epoch:  349 |---> loss is 0.9041052461, total correct predictions: 14866, its 84.466%\n",
      "Epoch:  350 |---> loss is 0.9033976197, total correct predictions: 14884, its 84.568%\n",
      "Epoch:  351 |---> loss is 0.9029644132, total correct predictions: 14893, its 84.619%\n",
      "Epoch:  352 |---> loss is 0.9032117128, total correct predictions: 14896, its 84.636%\n",
      "Epoch:  353 |---> loss is 0.9026399851, total correct predictions: 14903, its 84.676%\n",
      "Epoch:  354 |---> loss is 0.9025177956, total correct predictions: 14902, its 84.670%\n",
      "Epoch:  355 |---> loss is 0.9022810459, total correct predictions: 14905, its 84.688%\n",
      "Epoch:  356 |---> loss is 0.9017483592, total correct predictions: 14912, its 84.727%\n",
      "Epoch:  357 |---> loss is 0.9015353322, total correct predictions: 14915, its 84.744%\n",
      "Epoch:  358 |---> loss is 0.9015493393, total correct predictions: 14914, its 84.739%\n",
      "Epoch:  359 |---> loss is 0.9011608362, total correct predictions: 14919, its 84.767%\n",
      "Epoch:  360 |---> loss is 0.9010691047, total correct predictions: 14918, its 84.761%\n",
      "Epoch:  361 |---> loss is 0.9009866118, total correct predictions: 14922, its 84.784%\n",
      "Epoch:  362 |---> loss is 0.9006043077, total correct predictions: 14925, its 84.801%\n",
      "Epoch:  363 |---> loss is 0.9004768729, total correct predictions: 14929, its 84.824%\n",
      "Epoch:  364 |---> loss is 0.9003853202, total correct predictions: 14931, its 84.835%\n",
      "Epoch:  365 |---> loss is 0.9001771808, total correct predictions: 14935, its 84.858%\n",
      "Epoch:  366 |---> loss is 0.9000097513, total correct predictions: 14938, its 84.875%\n",
      "Epoch:  367 |---> loss is 0.9000135660, total correct predictions: 14939, its 84.881%\n",
      "Epoch:  368 |---> loss is 0.8998188376, total correct predictions: 14939, its 84.881%\n",
      "Epoch:  369 |---> loss is 0.8996095061, total correct predictions: 14940, its 84.886%\n",
      "Epoch:  370 |---> loss is 0.8993958235, total correct predictions: 14943, its 84.903%\n",
      "Epoch:  371 |---> loss is 0.8992300034, total correct predictions: 14945, its 84.915%\n",
      "Epoch:  372 |---> loss is 0.8991042972, total correct predictions: 14946, its 84.920%\n",
      "Epoch:  373 |---> loss is 0.8989920020, total correct predictions: 14944, its 84.909%\n",
      "Epoch:  374 |---> loss is 0.8988258839, total correct predictions: 14946, its 84.920%\n",
      "Epoch:  375 |---> loss is 0.8987486959, total correct predictions: 14946, its 84.920%\n",
      "Epoch:  376 |---> loss is 0.8986129761, total correct predictions: 14948, its 84.932%\n",
      "Epoch:  377 |---> loss is 0.8985674381, total correct predictions: 14948, its 84.932%\n",
      "Epoch:  378 |---> loss is 0.8984612823, total correct predictions: 14949, its 84.938%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  379 |---> loss is 0.8984012008, total correct predictions: 14952, its 84.955%\n",
      "Epoch:  380 |---> loss is 0.8983232975, total correct predictions: 14952, its 84.955%\n",
      "Epoch:  381 |---> loss is 0.8981825113, total correct predictions: 14953, its 84.960%\n",
      "Epoch:  382 |---> loss is 0.8980758786, total correct predictions: 14953, its 84.960%\n",
      "Epoch:  383 |---> loss is 0.8980128765, total correct predictions: 14955, its 84.972%\n",
      "Epoch:  384 |---> loss is 0.8978877664, total correct predictions: 14957, its 84.983%\n",
      "Epoch:  385 |---> loss is 0.8978272080, total correct predictions: 14958, its 84.989%\n",
      "Epoch:  386 |---> loss is 0.8976743817, total correct predictions: 14960, its 85.000%\n",
      "Epoch:  387 |---> loss is 0.8976380229, total correct predictions: 14959, its 84.994%\n",
      "Epoch:  388 |---> loss is 0.8975114822, total correct predictions: 14961, its 85.006%\n",
      "Epoch:  389 |---> loss is 0.8974500299, total correct predictions: 14960, its 85.000%\n",
      "Epoch:  390 |---> loss is 0.8973874450, total correct predictions: 14962, its 85.011%\n",
      "Epoch:  391 |---> loss is 0.8972793818, total correct predictions: 14964, its 85.023%\n",
      "Epoch:  392 |---> loss is 0.8971058130, total correct predictions: 14965, its 85.028%\n",
      "Epoch:  393 |---> loss is 0.8970002532, total correct predictions: 14966, its 85.034%\n",
      "Epoch:  394 |---> loss is 0.8969337940, total correct predictions: 14970, its 85.057%\n",
      "Epoch:  395 |---> loss is 0.8968495131, total correct predictions: 14973, its 85.074%\n",
      "Epoch:  396 |---> loss is 0.8969017267, total correct predictions: 14969, its 85.051%\n",
      "Epoch:  397 |---> loss is 0.8967075348, total correct predictions: 14972, its 85.068%\n",
      "Epoch:  398 |---> loss is 0.8967587948, total correct predictions: 14971, its 85.062%\n",
      "Epoch:  399 |---> loss is 0.8967223763, total correct predictions: 14970, its 85.057%\n",
      "Epoch:  400 |---> loss is 0.8965325952, total correct predictions: 14973, its 85.074%\n",
      "Epoch:  401 |---> loss is 0.8965296745, total correct predictions: 14972, its 85.068%\n",
      "Epoch:  402 |---> loss is 0.8964697123, total correct predictions: 14972, its 85.068%\n",
      "Epoch:  403 |---> loss is 0.8964858651, total correct predictions: 14974, its 85.080%\n",
      "Epoch:  404 |---> loss is 0.8964293599, total correct predictions: 14974, its 85.080%\n",
      "Epoch:  405 |---> loss is 0.8963901997, total correct predictions: 14974, its 85.080%\n",
      "Epoch:  406 |---> loss is 0.8963345289, total correct predictions: 14977, its 85.097%\n",
      "Epoch:  407 |---> loss is 0.8962073922, total correct predictions: 14977, its 85.097%\n",
      "Epoch:  408 |---> loss is 0.8961929083, total correct predictions: 14978, its 85.102%\n",
      "Epoch:  409 |---> loss is 0.8961115479, total correct predictions: 14979, its 85.108%\n",
      "Epoch:  410 |---> loss is 0.8960018158, total correct predictions: 14980, its 85.114%\n",
      "Epoch:  411 |---> loss is 0.8960009217, total correct predictions: 14979, its 85.108%\n",
      "Epoch:  412 |---> loss is 0.8959226012, total correct predictions: 14980, its 85.114%\n",
      "Epoch:  413 |---> loss is 0.8958620429, total correct predictions: 14980, its 85.114%\n",
      "Epoch:  414 |---> loss is 0.8958417773, total correct predictions: 14981, its 85.119%\n",
      "Epoch:  415 |---> loss is 0.8957651258, total correct predictions: 14980, its 85.114%\n",
      "Epoch:  416 |---> loss is 0.8957446218, total correct predictions: 14980, its 85.114%\n",
      "Epoch:  417 |---> loss is 0.8956933022, total correct predictions: 14980, its 85.114%\n",
      "Epoch:  418 |---> loss is 0.8956411481, total correct predictions: 14980, its 85.114%\n",
      "Epoch:  419 |---> loss is 0.8956099749, total correct predictions: 14982, its 85.125%\n",
      "Epoch:  420 |---> loss is 0.8955495954, total correct predictions: 14982, its 85.125%\n",
      "Epoch:  421 |---> loss is 0.8955133557, total correct predictions: 14983, its 85.131%\n",
      "Epoch:  422 |---> loss is 0.8954675198, total correct predictions: 14984, its 85.136%\n",
      "Epoch:  423 |---> loss is 0.8954198956, total correct predictions: 14986, its 85.148%\n",
      "Epoch:  424 |---> loss is 0.8953880668, total correct predictions: 14986, its 85.148%\n",
      "Epoch:  425 |---> loss is 0.8953399658, total correct predictions: 14986, its 85.148%\n",
      "Epoch:  426 |---> loss is 0.8952990770, total correct predictions: 14986, its 85.148%\n",
      "Epoch:  427 |---> loss is 0.8952599168, total correct predictions: 14986, its 85.148%\n",
      "Epoch:  428 |---> loss is 0.8952088356, total correct predictions: 14986, its 85.148%\n",
      "Epoch:  429 |---> loss is 0.8951660395, total correct predictions: 14987, its 85.153%\n",
      "Epoch:  430 |---> loss is 0.8951227069, total correct predictions: 14987, its 85.153%\n",
      "Epoch:  431 |---> loss is 0.8950741291, total correct predictions: 14987, its 85.153%\n",
      "Epoch:  432 |---> loss is 0.8950350285, total correct predictions: 14987, its 85.153%\n",
      "Epoch:  433 |---> loss is 0.8949849606, total correct predictions: 14986, its 85.148%\n",
      "Epoch:  434 |---> loss is 0.8949377537, total correct predictions: 14988, its 85.159%\n",
      "Epoch:  435 |---> loss is 0.8948919773, total correct predictions: 14989, its 85.165%\n",
      "Epoch:  436 |---> loss is 0.8948444128, total correct predictions: 14991, its 85.176%\n",
      "Epoch:  437 |---> loss is 0.8948023915, total correct predictions: 14991, its 85.176%\n",
      "Epoch:  438 |---> loss is 0.8947620392, total correct predictions: 14991, its 85.176%\n",
      "Epoch:  439 |---> loss is 0.8947203755, total correct predictions: 14991, its 85.176%\n",
      "Epoch:  440 |---> loss is 0.8946807981, total correct predictions: 14991, its 85.176%\n",
      "Epoch:  441 |---> loss is 0.8946390748, total correct predictions: 14993, its 85.188%\n",
      "Epoch:  442 |---> loss is 0.8945953250, total correct predictions: 14993, its 85.188%\n",
      "Epoch:  443 |---> loss is 0.8945484757, total correct predictions: 14993, its 85.188%\n",
      "Epoch:  444 |---> loss is 0.8944965601, total correct predictions: 14994, its 85.193%\n",
      "Epoch:  445 |---> loss is 0.8944464326, total correct predictions: 14995, its 85.199%\n",
      "Epoch:  446 |---> loss is 0.8944008350, total correct predictions: 14995, its 85.199%\n",
      "Epoch:  447 |---> loss is 0.8943613768, total correct predictions: 14995, its 85.199%\n",
      "Epoch:  448 |---> loss is 0.8943229318, total correct predictions: 14995, its 85.199%\n",
      "Epoch:  449 |---> loss is 0.8942790031, total correct predictions: 14995, its 85.199%\n",
      "Epoch:  450 |---> loss is 0.8942311406, total correct predictions: 14995, its 85.199%\n",
      "Epoch:  451 |---> loss is 0.8941553831, total correct predictions: 14995, its 85.199%\n",
      "Epoch:  452 |---> loss is 0.8940785527, total correct predictions: 14999, its 85.222%\n",
      "Epoch:  453 |---> loss is 0.8940418959, total correct predictions: 14999, its 85.222%\n",
      "Epoch:  454 |---> loss is 0.8939915895, total correct predictions: 14999, its 85.222%\n",
      "Epoch:  455 |---> loss is 0.8939384818, total correct predictions: 14999, its 85.222%\n",
      "Epoch:  456 |---> loss is 0.8938899636, total correct predictions: 15001, its 85.233%\n",
      "Epoch:  457 |---> loss is 0.8938476443, total correct predictions: 15002, its 85.239%\n",
      "Epoch:  458 |---> loss is 0.8938019276, total correct predictions: 15002, its 85.239%\n",
      "Epoch:  459 |---> loss is 0.8937621713, total correct predictions: 15002, its 85.239%\n",
      "Epoch:  460 |---> loss is 0.8936724663, total correct predictions: 15003, its 85.244%\n",
      "Epoch:  461 |---> loss is 0.8936398029, total correct predictions: 15002, its 85.239%\n",
      "Epoch:  462 |---> loss is 0.8935997486, total correct predictions: 15002, its 85.239%\n",
      "Epoch:  463 |---> loss is 0.8935647607, total correct predictions: 15003, its 85.244%\n",
      "Epoch:  464 |---> loss is 0.8935303688, total correct predictions: 15004, its 85.250%\n",
      "Epoch:  465 |---> loss is 0.8934950829, total correct predictions: 15004, its 85.250%\n",
      "Epoch:  466 |---> loss is 0.8934403062, total correct predictions: 15004, its 85.250%\n",
      "Epoch:  467 |---> loss is 0.8935337663, total correct predictions: 15003, its 85.244%\n",
      "Epoch:  468 |---> loss is 0.8935365081, total correct predictions: 15003, its 85.244%\n",
      "Epoch:  469 |---> loss is 0.8936131001, total correct predictions: 15002, its 85.239%\n",
      "Epoch:  470 |---> loss is 0.8935454488, total correct predictions: 15003, its 85.244%\n",
      "Epoch:  471 |---> loss is 0.8935227394, total correct predictions: 15004, its 85.250%\n",
      "Epoch:  472 |---> loss is 0.8934628367, total correct predictions: 15006, its 85.261%\n",
      "Epoch:  473 |---> loss is 0.8933936357, total correct predictions: 15007, its 85.267%\n",
      "Epoch:  474 |---> loss is 0.8933421373, total correct predictions: 15009, its 85.278%\n",
      "Epoch:  475 |---> loss is 0.8932720423, total correct predictions: 15009, its 85.278%\n",
      "Epoch:  476 |---> loss is 0.8932405114, total correct predictions: 15009, its 85.278%\n",
      "Epoch:  477 |---> loss is 0.8932276964, total correct predictions: 15010, its 85.284%\n",
      "Epoch:  478 |---> loss is 0.8932030201, total correct predictions: 15011, its 85.290%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  479 |---> loss is 0.8931688070, total correct predictions: 15011, its 85.290%\n",
      "Epoch:  480 |---> loss is 0.8931193352, total correct predictions: 15011, its 85.290%\n",
      "Epoch:  481 |---> loss is 0.8930873275, total correct predictions: 15011, its 85.290%\n",
      "Epoch:  482 |---> loss is 0.8930432796, total correct predictions: 15011, its 85.290%\n",
      "Epoch:  483 |---> loss is 0.8929858804, total correct predictions: 15013, its 85.301%\n",
      "Epoch:  484 |---> loss is 0.8929477334, total correct predictions: 15012, its 85.295%\n",
      "Epoch:  485 |---> loss is 0.8929102421, total correct predictions: 15011, its 85.290%\n",
      "Epoch:  486 |---> loss is 0.8928772211, total correct predictions: 15012, its 85.295%\n",
      "Epoch:  487 |---> loss is 0.8928490877, total correct predictions: 15012, its 85.295%\n",
      "Epoch:  488 |---> loss is 0.8928067088, total correct predictions: 15013, its 85.301%\n",
      "Epoch:  489 |---> loss is 0.8927409649, total correct predictions: 15013, its 85.301%\n",
      "Epoch:  490 |---> loss is 0.8927107453, total correct predictions: 15013, its 85.301%\n",
      "Epoch:  491 |---> loss is 0.8926590085, total correct predictions: 15014, its 85.307%\n",
      "Epoch:  492 |---> loss is 0.8926056623, total correct predictions: 15015, its 85.312%\n",
      "Epoch:  493 |---> loss is 0.8926065564, total correct predictions: 15015, its 85.312%\n",
      "Epoch:  494 |---> loss is 0.8925288320, total correct predictions: 15016, its 85.318%\n",
      "Epoch:  495 |---> loss is 0.8924993873, total correct predictions: 15017, its 85.324%\n",
      "Epoch:  496 |---> loss is 0.8924661875, total correct predictions: 15017, its 85.324%\n",
      "Epoch:  497 |---> loss is 0.8924402595, total correct predictions: 15018, its 85.330%\n",
      "Epoch:  498 |---> loss is 0.8924225569, total correct predictions: 15018, its 85.330%\n",
      "Epoch:  499 |---> loss is 0.8923718929, total correct predictions: 15019, its 85.335%\n"
     ]
    }
   ],
   "source": [
    "net = Network()\n",
    "print(net.out.weight)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "number_of_epoches = 500\n",
    "loss_weights = torch.tensor([1.,1.,1.,1.])\n",
    "\n",
    "\n",
    "total_loss = []\n",
    "total_accuracy = []\n",
    "total_val_loss = []\n",
    "total_val_accuracy = []\n",
    "for epoch in range(number_of_epoches):\n",
    "    predicted = net(train_features)\n",
    "    loss = F.cross_entropy(predicted, train_labels, loss_weights)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    total_correct = get_correct_predictions(predicted, train_labels)\n",
    "    print(\"Epoch: {:4d} |---> loss is {:4.10f}, total correct predictions: {:5d}, its {:.3f}%\"\n",
    "      .format(epoch, loss.item(), total_correct, total_correct*100/train_features.shape[0]))\n",
    "    \n",
    "    with torch.no_grad():  # record loss and accuracy info for plots\n",
    "        total_loss.append(loss.item())\n",
    "        total_accuracy.append(total_correct*100/train_features.shape[0])\n",
    "        \n",
    "        test_preds = net(test_features)\n",
    "        total_val_loss.append(F.cross_entropy(test_preds, test_labels, loss_weights).item())\n",
    "        total_val_accuracy.append(get_correct_predictions(test_preds, test_labels)*100/test_features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 70.05%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graphs and evaluation\n",
    "with torch.no_grad():\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(total_accuracy, label='accuracy')\n",
    "    plt.plot(total_val_accuracy, label = 'val_accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([0, 100])\n",
    "    plt.legend(loc='upper left')\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(total_loss, label='loss')\n",
    "    plt.plot(total_val_loss, label = 'val_loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    \n",
    "    \n",
    "    test_predictions = net(test_features)\n",
    "    test_correct_predictions = get_correct_predictions(test_predictions, test_labels)\n",
    "    print(\"Test accuracy is {:2.2f}%\" .format(test_correct_predictions * 100 /test_features.shape[0]))\n",
    "    \n",
    "    stacked = torch.stack((test_labels, test_predictions.argmax(dim=1)), dim=1)\n",
    "    confusion_matrix = torch.zeros((number_of_groups,number_of_groups), dtype=torch.int32)      # horizontal axis - predicted, vertical - true\n",
    "    for row in stacked:\n",
    "       confusion_matrix[row[0].item()][row[1].item()] += 1     # row is target, column - predicted\n",
    "    # print(confusion_matrix)\n",
    "    # print(400 - torch.count_nonzero(test_labels_tensor).item())\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(confusion_matrix, cmap='winter')\n",
    "    \n",
    "    ax.set_xticks(np.arange(confusion_matrix.shape[0]))\n",
    "    ax.set_yticks(np.arange(confusion_matrix.shape[1]))\n",
    "    x_labels = []\n",
    "    y_labels = []\n",
    "    for i in range(confusion_matrix.shape[0]):\n",
    "        x_labels.append('Predicted: '+ str(i + 1))\n",
    "        y_labels.append('Real: ' + str(i + 1))\n",
    "    ax.set_xticklabels(x_labels)\n",
    "    ax.set_yticklabels(y_labels)\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "    \n",
    "    for i in range(confusion_matrix.shape[0]):\n",
    "        for j in range(confusion_matrix.shape[1]):\n",
    "            text = ax.text(j, i, str(round(confusion_matrix[i][j].item()*100/test_features.shape[0], 2)) + '%', ha=\"center\", va=\"center\", size=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12.101]\n",
      " [ 9.87 ]\n",
      " [ 9.957]]\n",
      "[[3]\n",
      " [2]\n",
      " [2]]\n",
      "tensor([[0.0000, 0.9383, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convolutional NN\n",
    "features_reshaped = np.reshape(features, (features.shape[0], n_detectors, 8, 4))\n",
    "\n",
    "train_features_c = torch.tensor(features_reshaped[:size_of_training_set], dtype=torch.float32)\n",
    "test_features_c = torch.tensor(features_reshaped[size_of_training_set:], dtype=torch.float32)\n",
    "\n",
    "\n",
    "print(labels[:3])\n",
    "print(labels_encoded_equisized[:3])\n",
    "\n",
    "# Equisized\n",
    "train_labels_c = torch.flatten(torch.tensor(labels_encoded_equisized[:size_of_training_set]))\n",
    "test_labels_c = torch.flatten(torch.tensor(labels_encoded_equisized[size_of_training_set:]))\n",
    "\n",
    "# print(train_features_conv.shape)\n",
    "print(train_features_c[0][0])\n",
    "plt.imshow(train_features_c[0][0])\n",
    "plt.show()\n",
    "# print(train_features_c[0][1])\n",
    "# plt.imshow(train_features_c[0][1])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional NN\n",
    "class NetworkConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetworkConv, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=n_detectors, out_channels=n_detectors*2, kernel_size=(4, 2))\n",
    "        nn.init.normal_(self.conv1.weight, mean=0.0, std=0.02)\n",
    "        # print(self.conv1.weight)\n",
    "        # self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=2)\n",
    "        \n",
    "        self.lin1 = nn.Linear(in_features=n_detectors*2*5*3, out_features=60)\n",
    "        nn.init.normal_(self.lin1.weight, mean=0.0, std=0.02)\n",
    "        \n",
    "        self.lin2 = nn.Linear(in_features=60, out_features=16)\n",
    "        nn.init.normal_(self.lin2.weight, mean=0.0, std=0.02)\n",
    "\n",
    "        # self.lin3 = nn.Linear(in_features=30, out_features=12)\n",
    "        # nn.init.normal_(self.lin3.weight, mean=0.0, std=0.02)\n",
    "        \n",
    "        # self.lin4 = nn.Linear(in_features=30, out_features=16)\n",
    "        # nn.init.normal_(self.lin4.weight, mean=0.0, std=0.02) \n",
    "        \n",
    "        self.out = nn.Linear(in_features=16, out_features=number_of_groups)\n",
    "        nn.init.normal_(self.out.weight, mean=0.0, std=0.02)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        t = t\n",
    "        t = F.relu(self.conv1(t))\n",
    "        # t = F.relu(self.conv2(t))\n",
    "        # t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        t = F.relu(self.lin1(t.reshape(-1, n_detectors*2*5*3)))\n",
    "        t = F.relu(self.lin2(t))\n",
    "        # t = F.relu(self.lin3(t))\n",
    "        # t = F.relu(self.lin4(t))\n",
    "        \n",
    "        t = F.softmax(self.out(t), dim=1)\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 7.8461e-03,  3.8986e-03],\n",
      "          [-4.6233e-02,  6.0765e-03],\n",
      "          [ 2.8536e-02,  1.4415e-02],\n",
      "          [-7.9404e-03, -2.6155e-02]],\n",
      "\n",
      "         [[-1.8617e-03,  2.0640e-02],\n",
      "          [ 2.1612e-02, -1.4703e-02],\n",
      "          [ 1.8040e-02, -2.7844e-03],\n",
      "          [-6.3668e-03, -2.4219e-02]],\n",
      "\n",
      "         [[ 3.6082e-02,  2.6352e-03],\n",
      "          [ 8.5889e-05,  2.2664e-02],\n",
      "          [-4.5465e-02,  1.8752e-02],\n",
      "          [-3.3384e-02,  1.3816e-03]],\n",
      "\n",
      "         [[-4.8029e-03, -3.2852e-03],\n",
      "          [ 2.6501e-02, -8.4624e-03],\n",
      "          [ 3.7916e-02, -1.8340e-02],\n",
      "          [ 3.6310e-03,  2.0921e-04]],\n",
      "\n",
      "         [[-2.5808e-02, -3.9339e-03],\n",
      "          [-1.3734e-02,  9.1683e-03],\n",
      "          [-4.2627e-03,  1.1962e-02],\n",
      "          [-6.5031e-03, -6.9175e-03]],\n",
      "\n",
      "         [[-3.6908e-02, -1.3742e-03],\n",
      "          [-1.1168e-02,  2.4347e-02],\n",
      "          [ 5.5220e-03, -2.1128e-02],\n",
      "          [ 8.9454e-03,  9.0229e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4731e-02,  8.9084e-03],\n",
      "          [ 3.6780e-03, -5.9194e-03],\n",
      "          [ 3.5451e-02,  2.3347e-02],\n",
      "          [-1.1686e-02,  2.4994e-02]],\n",
      "\n",
      "         [[-6.2067e-03, -6.4350e-03],\n",
      "          [-4.4554e-03, -3.2247e-02],\n",
      "          [ 1.7810e-02,  1.2278e-02],\n",
      "          [-7.2310e-03, -1.5568e-02]],\n",
      "\n",
      "         [[ 2.3276e-02,  2.2451e-02],\n",
      "          [-1.0183e-02, -1.3751e-02],\n",
      "          [-1.9845e-02,  1.6831e-02],\n",
      "          [-2.1314e-02, -2.1891e-02]],\n",
      "\n",
      "         [[-2.2221e-02,  1.5206e-02],\n",
      "          [ 1.8094e-02,  2.8373e-02],\n",
      "          [-1.5842e-03,  5.6775e-03],\n",
      "          [-1.4290e-02,  8.2689e-03]],\n",
      "\n",
      "         [[ 3.9945e-02,  3.8472e-02],\n",
      "          [ 3.2726e-02,  1.3503e-02],\n",
      "          [-9.4818e-03, -2.1971e-02],\n",
      "          [-1.0923e-02, -1.5766e-02]],\n",
      "\n",
      "         [[-1.4779e-02,  2.1899e-02],\n",
      "          [-2.9230e-02, -1.6989e-02],\n",
      "          [-1.1993e-02, -1.0844e-02],\n",
      "          [ 1.7498e-03, -1.8799e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.5278e-02, -7.2840e-03],\n",
      "          [ 1.7977e-02, -2.7091e-03],\n",
      "          [ 1.1182e-02, -2.2654e-02],\n",
      "          [-1.5216e-02,  1.0753e-02]],\n",
      "\n",
      "         [[-4.7907e-03,  1.1601e-02],\n",
      "          [ 7.4000e-03, -2.7650e-02],\n",
      "          [-4.4782e-02, -9.9432e-03],\n",
      "          [ 1.2482e-02, -4.6741e-03]],\n",
      "\n",
      "         [[ 1.9684e-02,  1.5459e-02],\n",
      "          [-5.0422e-03,  2.1444e-02],\n",
      "          [-2.2243e-03, -5.5423e-03],\n",
      "          [-7.5156e-03, -2.1775e-02]],\n",
      "\n",
      "         [[ 5.7661e-03,  2.2992e-02],\n",
      "          [ 2.1932e-02, -2.2839e-02],\n",
      "          [ 3.2617e-02,  2.0740e-02],\n",
      "          [ 7.8585e-03, -3.9363e-03]],\n",
      "\n",
      "         [[ 5.5150e-03, -3.5196e-02],\n",
      "          [ 7.1472e-03,  1.6134e-02],\n",
      "          [ 2.7644e-02,  8.0542e-03],\n",
      "          [ 3.2933e-02, -5.1197e-03]],\n",
      "\n",
      "         [[ 5.6546e-03,  2.8118e-03],\n",
      "          [-3.5814e-02,  1.3749e-02],\n",
      "          [-1.6515e-03,  2.8095e-02],\n",
      "          [-3.4084e-03,  8.9134e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7294e-02,  3.3256e-02],\n",
      "          [-6.9480e-03, -2.4133e-03],\n",
      "          [-3.4321e-02,  1.2900e-02],\n",
      "          [ 2.1886e-02, -2.5193e-02]],\n",
      "\n",
      "         [[-1.0241e-02, -9.1412e-03],\n",
      "          [ 2.8651e-02,  1.3497e-02],\n",
      "          [-2.0832e-02,  6.3956e-02],\n",
      "          [ 1.0737e-02,  2.4493e-02]],\n",
      "\n",
      "         [[-2.2641e-02, -2.2927e-02],\n",
      "          [-2.9518e-02,  2.3233e-02],\n",
      "          [-4.1836e-02, -1.8829e-02],\n",
      "          [-2.7368e-02, -1.6913e-03]],\n",
      "\n",
      "         [[ 2.4025e-03,  4.8752e-05],\n",
      "          [-6.2059e-03,  3.4032e-02],\n",
      "          [ 4.7557e-02, -3.4040e-03],\n",
      "          [ 2.4535e-02, -1.1584e-02]],\n",
      "\n",
      "         [[ 1.5774e-02,  1.2705e-02],\n",
      "          [-6.3292e-03, -4.4065e-02],\n",
      "          [ 2.0632e-02, -1.6523e-02],\n",
      "          [-1.5397e-02, -2.8761e-02]],\n",
      "\n",
      "         [[-2.2140e-02,  1.9802e-02],\n",
      "          [ 2.0727e-03, -7.5555e-03],\n",
      "          [ 2.3956e-02, -1.0556e-02],\n",
      "          [ 7.0046e-03,  1.5504e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.4685e-02,  2.0147e-02],\n",
      "          [-1.7226e-02, -2.8664e-04],\n",
      "          [ 2.5936e-02, -2.8736e-02],\n",
      "          [-4.2759e-02,  1.9369e-02]],\n",
      "\n",
      "         [[-4.1280e-03,  5.0849e-03],\n",
      "          [ 2.8256e-03,  1.4320e-03],\n",
      "          [ 2.6212e-02,  2.3644e-02],\n",
      "          [ 9.2081e-03, -2.1741e-03]],\n",
      "\n",
      "         [[ 2.5839e-02,  4.2251e-03],\n",
      "          [ 1.2237e-02,  1.1273e-02],\n",
      "          [ 2.4281e-02,  3.5089e-02],\n",
      "          [ 1.3599e-02, -4.3668e-02]],\n",
      "\n",
      "         [[-7.4480e-03, -7.7113e-03],\n",
      "          [ 6.1899e-03, -1.1063e-02],\n",
      "          [ 6.8039e-03,  9.4547e-03],\n",
      "          [-6.0080e-03, -3.1674e-02]],\n",
      "\n",
      "         [[-1.6199e-02,  4.8979e-02],\n",
      "          [-6.7951e-03, -9.0336e-04],\n",
      "          [ 1.1621e-02, -1.9578e-02],\n",
      "          [ 7.9889e-03,  1.4117e-02]],\n",
      "\n",
      "         [[-6.4566e-03, -1.5841e-02],\n",
      "          [ 3.1845e-02,  1.9172e-02],\n",
      "          [-8.6937e-03, -3.1942e-02],\n",
      "          [-1.3343e-02,  2.0363e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.7640e-03,  3.5121e-03],\n",
      "          [ 8.5674e-03, -8.8200e-03],\n",
      "          [-5.3249e-03,  3.2844e-02],\n",
      "          [-1.7046e-02, -1.6473e-02]],\n",
      "\n",
      "         [[ 2.0582e-02, -8.9703e-03],\n",
      "          [-2.3665e-02,  2.4059e-02],\n",
      "          [-3.5541e-02,  3.0735e-02],\n",
      "          [-5.0308e-03,  6.6989e-03]],\n",
      "\n",
      "         [[-1.8070e-02,  2.0452e-02],\n",
      "          [-2.4242e-02, -4.8496e-02],\n",
      "          [ 2.4809e-02,  2.9275e-04],\n",
      "          [-2.0672e-02,  5.0007e-03]],\n",
      "\n",
      "         [[-2.3355e-02, -1.3147e-03],\n",
      "          [ 1.1197e-02,  1.0928e-02],\n",
      "          [ 2.3783e-02, -1.6981e-02],\n",
      "          [ 2.2275e-02, -1.3558e-03]],\n",
      "\n",
      "         [[-2.2228e-02,  2.9472e-02],\n",
      "          [-3.3986e-02,  1.3566e-02],\n",
      "          [-1.9500e-02, -1.8218e-02],\n",
      "          [-1.6807e-02,  1.5736e-02]],\n",
      "\n",
      "         [[-5.3688e-03, -6.5862e-03],\n",
      "          [-2.0085e-02, -1.5396e-02],\n",
      "          [-3.7212e-02, -5.0280e-03],\n",
      "          [-4.1407e-02, -1.9795e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.4624e-03,  2.1078e-02],\n",
      "          [ 5.2340e-04, -2.4128e-02],\n",
      "          [ 7.8497e-03,  2.0019e-02],\n",
      "          [-4.1514e-02,  1.1385e-04]],\n",
      "\n",
      "         [[-3.2411e-02,  1.0859e-02],\n",
      "          [-1.8075e-02, -1.5947e-02],\n",
      "          [ 5.9067e-03,  2.1394e-02],\n",
      "          [ 3.7898e-03, -5.0237e-03]],\n",
      "\n",
      "         [[ 4.6770e-03, -1.3583e-02],\n",
      "          [ 1.1826e-02, -3.9703e-03],\n",
      "          [-1.1694e-02, -2.1675e-02],\n",
      "          [ 1.8983e-03, -1.3892e-02]],\n",
      "\n",
      "         [[-5.0638e-03, -1.1598e-02],\n",
      "          [-2.0082e-02,  3.1542e-02],\n",
      "          [ 1.1401e-02, -2.5244e-03],\n",
      "          [ 6.6485e-03, -1.5227e-02]],\n",
      "\n",
      "         [[-5.5797e-03, -1.6923e-02],\n",
      "          [ 2.5215e-02,  3.0522e-03],\n",
      "          [-4.0981e-02,  3.8121e-02],\n",
      "          [ 4.6001e-02, -5.0259e-02]],\n",
      "\n",
      "         [[-2.0097e-02, -3.1145e-02],\n",
      "          [-4.8068e-03,  3.2476e-02],\n",
      "          [ 7.2230e-03,  1.4230e-02],\n",
      "          [-1.8077e-02, -1.0638e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.9406e-04, -7.4581e-03],\n",
      "          [-2.2717e-02, -2.8619e-02],\n",
      "          [ 5.2509e-03,  7.0392e-03],\n",
      "          [-6.7022e-03,  1.3730e-02]],\n",
      "\n",
      "         [[-1.4091e-03,  2.1724e-02],\n",
      "          [ 8.6470e-03,  1.2697e-02],\n",
      "          [ 2.0266e-02, -8.8910e-03],\n",
      "          [-1.2287e-03,  3.5073e-02]],\n",
      "\n",
      "         [[ 5.5516e-04, -1.6966e-02],\n",
      "          [-1.0089e-02,  4.7544e-03],\n",
      "          [ 6.3602e-02,  1.8642e-02],\n",
      "          [-2.8663e-02, -2.0114e-03]],\n",
      "\n",
      "         [[-1.4349e-02,  1.4230e-02],\n",
      "          [ 1.4632e-02,  5.1662e-02],\n",
      "          [ 5.2077e-02, -1.7529e-02],\n",
      "          [-4.3147e-02, -1.8155e-02]],\n",
      "\n",
      "         [[-5.8246e-03,  6.4393e-03],\n",
      "          [-6.6726e-03,  1.8982e-02],\n",
      "          [-3.2794e-02,  4.4593e-04],\n",
      "          [ 2.2670e-02,  4.0783e-03]],\n",
      "\n",
      "         [[-1.5017e-02, -1.0629e-02],\n",
      "          [-1.4236e-02,  1.2201e-02],\n",
      "          [ 9.9748e-04,  2.0128e-02],\n",
      "          [ 3.6018e-02,  2.1324e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.6654e-03, -1.4152e-02],\n",
      "          [-2.5625e-02,  1.2816e-02],\n",
      "          [ 7.9473e-03,  2.4783e-02],\n",
      "          [ 1.3650e-02, -4.8051e-03]],\n",
      "\n",
      "         [[-2.4900e-02,  1.3080e-02],\n",
      "          [ 6.2492e-03, -3.8687e-03],\n",
      "          [ 3.0166e-04,  1.2607e-02],\n",
      "          [ 2.0726e-02,  1.0794e-02]],\n",
      "\n",
      "         [[ 3.9712e-02, -4.2947e-02],\n",
      "          [-2.6356e-02, -2.2065e-02],\n",
      "          [-2.7781e-02, -2.2686e-02],\n",
      "          [ 1.8456e-03,  1.1014e-02]],\n",
      "\n",
      "         [[-3.2156e-02,  1.6633e-03],\n",
      "          [-7.0701e-03,  1.6227e-02],\n",
      "          [ 3.0411e-02,  1.4842e-02],\n",
      "          [ 1.7087e-02,  1.2976e-02]],\n",
      "\n",
      "         [[-3.0006e-02, -1.4486e-02],\n",
      "          [ 1.6841e-02, -1.6374e-02],\n",
      "          [-1.1519e-02,  1.9834e-03],\n",
      "          [ 3.0736e-02,  2.8257e-02]],\n",
      "\n",
      "         [[-1.1987e-02, -1.5791e-02],\n",
      "          [-2.0456e-02,  2.6376e-02],\n",
      "          [ 7.6383e-03,  7.1335e-03],\n",
      "          [-1.4484e-02,  3.1504e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.9777e-03,  1.0564e-02],\n",
      "          [ 2.9972e-02,  5.1700e-03],\n",
      "          [-1.8656e-02,  4.6787e-02],\n",
      "          [-7.9749e-03, -2.9661e-02]],\n",
      "\n",
      "         [[-6.3520e-03, -3.8871e-03],\n",
      "          [ 4.3996e-02,  2.6995e-03],\n",
      "          [-4.4618e-02,  2.0171e-02],\n",
      "          [ 2.0082e-02,  3.5491e-02]],\n",
      "\n",
      "         [[ 2.1037e-03, -1.2235e-02],\n",
      "          [-4.3982e-03, -1.5544e-02],\n",
      "          [ 1.7075e-02, -2.0879e-02],\n",
      "          [ 5.2470e-03, -1.5906e-02]],\n",
      "\n",
      "         [[-1.4674e-02,  2.7264e-04],\n",
      "          [ 1.1241e-02,  6.5740e-03],\n",
      "          [-9.4565e-03, -2.3222e-02],\n",
      "          [-2.1416e-03,  4.4134e-03]],\n",
      "\n",
      "         [[ 1.6494e-02,  1.9290e-03],\n",
      "          [-1.3786e-02,  2.6363e-02],\n",
      "          [-3.6036e-02,  7.3794e-03],\n",
      "          [-1.4938e-03, -2.9437e-04]],\n",
      "\n",
      "         [[-3.8022e-02, -3.1728e-03],\n",
      "          [ 1.2630e-02,  1.7444e-02],\n",
      "          [ 4.4183e-02, -2.8440e-02],\n",
      "          [-4.5246e-04,  2.5579e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6590e-02,  2.1176e-02],\n",
      "          [-2.3467e-02,  1.2801e-02],\n",
      "          [-1.8024e-02, -1.6345e-02],\n",
      "          [ 3.2207e-02, -1.9571e-02]],\n",
      "\n",
      "         [[-3.9561e-02,  1.2562e-02],\n",
      "          [-1.0533e-02,  3.5107e-02],\n",
      "          [ 4.0341e-02, -1.0573e-02],\n",
      "          [-5.1519e-03,  1.0685e-02]],\n",
      "\n",
      "         [[ 2.8059e-02,  2.3745e-02],\n",
      "          [-7.5923e-04,  1.4323e-02],\n",
      "          [ 1.3364e-02, -2.2365e-02],\n",
      "          [ 2.4237e-03, -3.8821e-02]],\n",
      "\n",
      "         [[-5.3756e-03, -1.1969e-02],\n",
      "          [ 3.6799e-02, -1.5145e-02],\n",
      "          [ 1.2157e-02, -1.3460e-02],\n",
      "          [-1.5097e-02, -1.4811e-02]],\n",
      "\n",
      "         [[-3.2739e-02, -1.2982e-02],\n",
      "          [-1.9927e-02,  3.3420e-02],\n",
      "          [ 4.5200e-02,  2.7422e-02],\n",
      "          [-8.1349e-03, -1.3303e-02]],\n",
      "\n",
      "         [[-1.0770e-02,  1.7161e-03],\n",
      "          [ 1.5266e-02,  9.3010e-03],\n",
      "          [ 2.1545e-02,  1.0051e-02],\n",
      "          [ 2.2901e-02, -3.7112e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5375e-02, -1.6381e-02],\n",
      "          [ 9.5639e-03,  1.1133e-02],\n",
      "          [-1.7435e-03,  5.6082e-02],\n",
      "          [ 1.4657e-02,  1.0171e-02]],\n",
      "\n",
      "         [[-2.2360e-02, -3.6556e-02],\n",
      "          [ 1.6313e-02, -1.6736e-02],\n",
      "          [ 2.3954e-03, -9.9844e-03],\n",
      "          [-1.0769e-02, -3.0927e-02]],\n",
      "\n",
      "         [[ 1.1491e-02, -2.8342e-02],\n",
      "          [-8.0930e-03, -2.0792e-02],\n",
      "          [-4.0523e-03, -4.6544e-03],\n",
      "          [ 2.8743e-02,  5.3051e-04]],\n",
      "\n",
      "         [[ 7.9791e-03,  4.6814e-03],\n",
      "          [-5.4879e-03,  2.0017e-02],\n",
      "          [ 1.1364e-02, -2.5536e-02],\n",
      "          [-1.0498e-02,  1.7228e-02]],\n",
      "\n",
      "         [[-2.9021e-03,  3.8449e-04],\n",
      "          [ 4.6893e-03,  2.2541e-02],\n",
      "          [ 2.4799e-02,  2.5152e-02],\n",
      "          [-3.8724e-02,  6.6280e-03]],\n",
      "\n",
      "         [[ 1.9880e-02, -7.4633e-03],\n",
      "          [ 5.8835e-03, -2.1192e-02],\n",
      "          [-9.0846e-03,  8.9506e-03],\n",
      "          [-2.8529e-04,  2.1456e-02]]]], requires_grad=True)\n",
      "Epoch:    0 |---> loss is 1.3870573044, total correct predictions:  4412, its 25.068%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    1 |---> loss is 1.3868596554, total correct predictions:  4412, its 25.068%\n",
      "Epoch:    2 |---> loss is 1.3862117529, total correct predictions:  4680, its 26.591%\n",
      "Epoch:    3 |---> loss is 1.3832058907, total correct predictions:  4332, its 24.614%\n",
      "Epoch:    4 |---> loss is 1.3741908073, total correct predictions:  4407, its 25.040%\n",
      "Epoch:    5 |---> loss is 1.3564027548, total correct predictions:  4425, its 25.142%\n",
      "Epoch:    6 |---> loss is 1.3432631493, total correct predictions:  4425, its 25.142%\n",
      "Epoch:    7 |---> loss is 1.3412853479, total correct predictions:  4592, its 26.091%\n",
      "Epoch:    8 |---> loss is 1.3268882036, total correct predictions:  5018, its 28.511%\n",
      "Epoch:    9 |---> loss is 1.3273115158, total correct predictions:  5735, its 32.585%\n",
      "Epoch:   10 |---> loss is 1.3243882656, total correct predictions:  6685, its 37.983%\n",
      "Epoch:   11 |---> loss is 1.3219969273, total correct predictions:  7638, its 43.398%\n",
      "Epoch:   12 |---> loss is 1.3200868368, total correct predictions:  8006, its 45.489%\n",
      "Epoch:   13 |---> loss is 1.3110201359, total correct predictions:  7900, its 44.886%\n",
      "Epoch:   14 |---> loss is 1.3050227165, total correct predictions:  7726, its 43.898%\n",
      "Epoch:   15 |---> loss is 1.3028204441, total correct predictions:  7534, its 42.807%\n",
      "Epoch:   16 |---> loss is 1.3029369116, total correct predictions:  7573, its 43.028%\n",
      "Epoch:   17 |---> loss is 1.2978516817, total correct predictions:  7759, its 44.085%\n",
      "Epoch:   18 |---> loss is 1.2909795046, total correct predictions:  7978, its 45.330%\n",
      "Epoch:   19 |---> loss is 1.2872176170, total correct predictions:  8263, its 46.949%\n",
      "Epoch:   20 |---> loss is 1.2845418453, total correct predictions:  8126, its 46.170%\n",
      "Epoch:   21 |---> loss is 1.2780684233, total correct predictions:  8154, its 46.330%\n",
      "Epoch:   22 |---> loss is 1.2706160545, total correct predictions:  8168, its 46.409%\n",
      "Epoch:   23 |---> loss is 1.2620055676, total correct predictions:  8371, its 47.562%\n",
      "Epoch:   24 |---> loss is 1.2555735111, total correct predictions:  8096, its 46.000%\n",
      "Epoch:   25 |---> loss is 1.2460289001, total correct predictions:  8167, its 46.403%\n",
      "Epoch:   26 |---> loss is 1.2369284630, total correct predictions:  8535, its 48.494%\n",
      "Epoch:   27 |---> loss is 1.2297035456, total correct predictions:  8462, its 48.080%\n",
      "Epoch:   28 |---> loss is 1.2231886387, total correct predictions:  8472, its 48.136%\n",
      "Epoch:   29 |---> loss is 1.2179328203, total correct predictions:  8659, its 49.199%\n",
      "Epoch:   30 |---> loss is 1.2136377096, total correct predictions:  8621, its 48.983%\n",
      "Epoch:   31 |---> loss is 1.2089073658, total correct predictions:  8726, its 49.580%\n",
      "Epoch:   32 |---> loss is 1.2055548429, total correct predictions:  8653, its 49.165%\n",
      "Epoch:   33 |---> loss is 1.2111458778, total correct predictions:  8631, its 49.040%\n",
      "Epoch:   34 |---> loss is 1.2245016098, total correct predictions:  8198, its 46.580%\n",
      "Epoch:   35 |---> loss is 1.2043689489, total correct predictions:  8829, its 50.165%\n",
      "Epoch:   36 |---> loss is 1.2025238276, total correct predictions:  8897, its 50.551%\n",
      "Epoch:   37 |---> loss is 1.2047454119, total correct predictions:  8660, its 49.205%\n",
      "Epoch:   38 |---> loss is 1.1984584332, total correct predictions:  8819, its 50.108%\n",
      "Epoch:   39 |---> loss is 1.1993280649, total correct predictions:  8921, its 50.688%\n",
      "Epoch:   40 |---> loss is 1.1940946579, total correct predictions:  9034, its 51.330%\n",
      "Epoch:   41 |---> loss is 1.1962418556, total correct predictions:  8973, its 50.983%\n",
      "Epoch:   42 |---> loss is 1.1853755713, total correct predictions:  9216, its 52.364%\n",
      "Epoch:   43 |---> loss is 1.1873264313, total correct predictions:  9288, its 52.773%\n",
      "Epoch:   44 |---> loss is 1.1790287495, total correct predictions:  9383, its 53.312%\n",
      "Epoch:   45 |---> loss is 1.1817715168, total correct predictions:  9310, its 52.898%\n",
      "Epoch:   46 |---> loss is 1.1728879213, total correct predictions:  9495, its 53.949%\n",
      "Epoch:   47 |---> loss is 1.1734505892, total correct predictions:  9549, its 54.256%\n",
      "Epoch:   48 |---> loss is 1.1647561789, total correct predictions:  9782, its 55.580%\n",
      "Epoch:   49 |---> loss is 1.1647311449, total correct predictions:  9737, its 55.324%\n",
      "Epoch:   50 |---> loss is 1.1577235460, total correct predictions:  9775, its 55.540%\n",
      "Epoch:   51 |---> loss is 1.1556619406, total correct predictions:  9838, its 55.898%\n",
      "Epoch:   52 |---> loss is 1.1487145424, total correct predictions:  9936, its 56.455%\n",
      "Epoch:   53 |---> loss is 1.1454282999, total correct predictions:  9937, its 56.460%\n",
      "Epoch:   54 |---> loss is 1.1397150755, total correct predictions:  9963, its 56.608%\n",
      "Epoch:   55 |---> loss is 1.1355654001, total correct predictions: 10036, its 57.023%\n",
      "Epoch:   56 |---> loss is 1.1286162138, total correct predictions: 11379, its 64.653%\n",
      "Epoch:   57 |---> loss is 1.1239868402, total correct predictions: 11277, its 64.074%\n",
      "Epoch:   58 |---> loss is 1.1164522171, total correct predictions: 11255, its 63.949%\n",
      "Epoch:   59 |---> loss is 1.1129039526, total correct predictions: 11237, its 63.847%\n",
      "Epoch:   60 |---> loss is 1.1057276726, total correct predictions: 11225, its 63.778%\n",
      "Epoch:   61 |---> loss is 1.1023275852, total correct predictions: 11274, its 64.057%\n",
      "Epoch:   62 |---> loss is 1.0966691971, total correct predictions: 11336, its 64.409%\n",
      "Epoch:   63 |---> loss is 1.0942983627, total correct predictions: 11358, its 64.534%\n",
      "Epoch:   64 |---> loss is 1.0899453163, total correct predictions: 11428, its 64.932%\n",
      "Epoch:   65 |---> loss is 1.0868730545, total correct predictions: 11459, its 65.108%\n",
      "Epoch:   66 |---> loss is 1.0845212936, total correct predictions: 11495, its 65.312%\n",
      "Epoch:   67 |---> loss is 1.0804560184, total correct predictions: 11552, its 65.636%\n",
      "Epoch:   68 |---> loss is 1.0796374083, total correct predictions: 11561, its 65.688%\n",
      "Epoch:   69 |---> loss is 1.0806168318, total correct predictions: 11502, its 65.352%\n",
      "Epoch:   70 |---> loss is 1.0758618116, total correct predictions: 11662, its 66.261%\n",
      "Epoch:   71 |---> loss is 1.0728651285, total correct predictions: 11646, its 66.170%\n",
      "Epoch:   72 |---> loss is 1.0729947090, total correct predictions: 11627, its 66.062%\n",
      "Epoch:   73 |---> loss is 1.0701404810, total correct predictions: 11703, its 66.494%\n",
      "Epoch:   74 |---> loss is 1.0669640303, total correct predictions: 11756, its 66.795%\n",
      "Epoch:   75 |---> loss is 1.0677812099, total correct predictions: 11742, its 66.716%\n",
      "Epoch:   76 |---> loss is 1.0682265759, total correct predictions: 11772, its 66.886%\n",
      "Epoch:   77 |---> loss is 1.0660241842, total correct predictions: 11760, its 66.818%\n",
      "Epoch:   78 |---> loss is 1.0605884790, total correct predictions: 11894, its 67.580%\n",
      "Epoch:   79 |---> loss is 1.0606213808, total correct predictions: 11900, its 67.614%\n",
      "Epoch:   80 |---> loss is 1.0661379099, total correct predictions: 11787, its 66.972%\n",
      "Epoch:   81 |---> loss is 1.0594561100, total correct predictions: 11956, its 67.932%\n",
      "Epoch:   82 |---> loss is 1.0552681684, total correct predictions: 11983, its 68.085%\n",
      "Epoch:   83 |---> loss is 1.0541137457, total correct predictions: 12048, its 68.455%\n",
      "Epoch:   84 |---> loss is 1.0562267303, total correct predictions: 12004, its 68.205%\n",
      "Epoch:   85 |---> loss is 1.0593037605, total correct predictions: 11921, its 67.733%\n",
      "Epoch:   86 |---> loss is 1.0531705618, total correct predictions: 12060, its 68.523%\n",
      "Epoch:   87 |---> loss is 1.0496885777, total correct predictions: 12110, its 68.807%\n",
      "Epoch:   88 |---> loss is 1.0521864891, total correct predictions: 12064, its 68.545%\n",
      "Epoch:   89 |---> loss is 1.0531699657, total correct predictions: 12038, its 68.398%\n",
      "Epoch:   90 |---> loss is 1.0492049456, total correct predictions: 12118, its 68.852%\n",
      "Epoch:   91 |---> loss is 1.0466237068, total correct predictions: 12188, its 69.250%\n",
      "Epoch:   92 |---> loss is 1.0476526022, total correct predictions: 12143, its 68.994%\n",
      "Epoch:   93 |---> loss is 1.0492768288, total correct predictions: 12110, its 68.807%\n",
      "Epoch:   94 |---> loss is 1.0450948477, total correct predictions: 12217, its 69.415%\n",
      "Epoch:   95 |---> loss is 1.0417755842, total correct predictions: 12291, its 69.835%\n",
      "Epoch:   96 |---> loss is 1.0430001020, total correct predictions: 12238, its 69.534%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   97 |---> loss is 1.0436390638, total correct predictions: 12250, its 69.602%\n",
      "Epoch:   98 |---> loss is 1.0448920727, total correct predictions: 12209, its 69.369%\n",
      "Epoch:   99 |---> loss is 1.0427079201, total correct predictions: 12222, its 69.443%\n",
      "Epoch:  100 |---> loss is 1.0377060175, total correct predictions: 12376, its 70.318%\n",
      "Epoch:  101 |---> loss is 1.0393861532, total correct predictions: 12320, its 70.000%\n",
      "Epoch:  102 |---> loss is 1.0412526131, total correct predictions: 12228, its 69.477%\n",
      "Epoch:  103 |---> loss is 1.0385439396, total correct predictions: 12335, its 70.085%\n",
      "Epoch:  104 |---> loss is 1.0373439789, total correct predictions: 12391, its 70.403%\n",
      "Epoch:  105 |---> loss is 1.0334835052, total correct predictions: 12464, its 70.818%\n",
      "Epoch:  106 |---> loss is 1.0324604511, total correct predictions: 12492, its 70.977%\n",
      "Epoch:  107 |---> loss is 1.0338239670, total correct predictions: 12459, its 70.790%\n",
      "Epoch:  108 |---> loss is 1.0324863195, total correct predictions: 12458, its 70.784%\n",
      "Epoch:  109 |---> loss is 1.0319360495, total correct predictions: 12475, its 70.881%\n",
      "Epoch:  110 |---> loss is 1.0358475447, total correct predictions: 12387, its 70.381%\n",
      "Epoch:  111 |---> loss is 1.0393666029, total correct predictions: 12301, its 69.892%\n",
      "Epoch:  112 |---> loss is 1.0349189043, total correct predictions: 12397, its 70.438%\n",
      "Epoch:  113 |---> loss is 1.0309772491, total correct predictions: 12492, its 70.977%\n",
      "Epoch:  114 |---> loss is 1.0262776613, total correct predictions: 12602, its 71.602%\n",
      "Epoch:  115 |---> loss is 1.0266828537, total correct predictions: 12567, its 71.403%\n",
      "Epoch:  116 |---> loss is 1.0317245722, total correct predictions: 12448, its 70.727%\n",
      "Epoch:  117 |---> loss is 1.0366481543, total correct predictions: 12342, its 70.125%\n",
      "Epoch:  118 |---> loss is 1.0300778151, total correct predictions: 12482, its 70.920%\n",
      "Epoch:  119 |---> loss is 1.0243200064, total correct predictions: 12614, its 71.670%\n",
      "Epoch:  120 |---> loss is 1.0244226456, total correct predictions: 12623, its 71.722%\n",
      "Epoch:  121 |---> loss is 1.0277060270, total correct predictions: 12527, its 71.176%\n",
      "Epoch:  122 |---> loss is 1.0268102884, total correct predictions: 12579, its 71.472%\n",
      "Epoch:  123 |---> loss is 1.0216348171, total correct predictions: 12665, its 71.960%\n",
      "Epoch:  124 |---> loss is 1.0211020708, total correct predictions: 12680, its 72.045%\n",
      "Epoch:  125 |---> loss is 1.0241723061, total correct predictions: 12628, its 71.750%\n",
      "Epoch:  126 |---> loss is 1.0270144939, total correct predictions: 12558, its 71.352%\n",
      "Epoch:  127 |---> loss is 1.0269672871, total correct predictions: 12545, its 71.278%\n",
      "Epoch:  128 |---> loss is 1.0209807158, total correct predictions: 12719, its 72.267%\n",
      "Epoch:  129 |---> loss is 1.0182954073, total correct predictions: 12747, its 72.426%\n",
      "Epoch:  130 |---> loss is 1.0244151354, total correct predictions: 12597, its 71.574%\n",
      "Epoch:  131 |---> loss is 1.0243058205, total correct predictions: 12600, its 71.591%\n",
      "Epoch:  132 |---> loss is 1.0171306133, total correct predictions: 12756, its 72.477%\n",
      "Epoch:  133 |---> loss is 1.0175530910, total correct predictions: 12751, its 72.449%\n",
      "Epoch:  134 |---> loss is 1.0225450993, total correct predictions: 12667, its 71.972%\n",
      "Epoch:  135 |---> loss is 1.0158040524, total correct predictions: 12801, its 72.733%\n",
      "Epoch:  136 |---> loss is 1.0278937817, total correct predictions: 12515, its 71.108%\n",
      "Epoch:  137 |---> loss is 1.0226275921, total correct predictions: 12664, its 71.955%\n",
      "Epoch:  138 |---> loss is 1.0194258690, total correct predictions: 12732, its 72.341%\n",
      "Epoch:  139 |---> loss is 1.0256820917, total correct predictions: 12554, its 71.330%\n",
      "Epoch:  140 |---> loss is 1.0127936602, total correct predictions: 12838, its 72.943%\n",
      "Epoch:  141 |---> loss is 1.0169624090, total correct predictions: 12772, its 72.568%\n",
      "Epoch:  142 |---> loss is 1.0131891966, total correct predictions: 12834, its 72.920%\n",
      "Epoch:  143 |---> loss is 1.0174149275, total correct predictions: 12728, its 72.318%\n",
      "Epoch:  144 |---> loss is 1.0169698000, total correct predictions: 12755, its 72.472%\n",
      "Epoch:  145 |---> loss is 1.0134538412, total correct predictions: 12828, its 72.886%\n",
      "Epoch:  146 |---> loss is 1.0150293112, total correct predictions: 12795, its 72.699%\n",
      "Epoch:  147 |---> loss is 1.0089662075, total correct predictions: 12921, its 73.415%\n",
      "Epoch:  148 |---> loss is 1.0119535923, total correct predictions: 12860, its 73.068%\n",
      "Epoch:  149 |---> loss is 1.0110727549, total correct predictions: 12876, its 73.159%\n",
      "Epoch:  150 |---> loss is 1.0128456354, total correct predictions: 12833, its 72.915%\n",
      "Epoch:  151 |---> loss is 1.0146234035, total correct predictions: 12783, its 72.631%\n",
      "Epoch:  152 |---> loss is 1.0110464096, total correct predictions: 12866, its 73.102%\n",
      "Epoch:  153 |---> loss is 1.0109926462, total correct predictions: 12847, its 72.994%\n",
      "Epoch:  154 |---> loss is 1.0072364807, total correct predictions: 12970, its 73.693%\n",
      "Epoch:  155 |---> loss is 1.0064208508, total correct predictions: 12996, its 73.841%\n",
      "Epoch:  156 |---> loss is 1.0128251314, total correct predictions: 12818, its 72.830%\n",
      "Epoch:  157 |---> loss is 1.0085650682, total correct predictions: 12915, its 73.381%\n",
      "Epoch:  158 |---> loss is 1.0070346594, total correct predictions: 12966, its 73.670%\n",
      "Epoch:  159 |---> loss is 1.0094002485, total correct predictions: 12913, its 73.369%\n",
      "Epoch:  160 |---> loss is 1.0094381571, total correct predictions: 12895, its 73.267%\n",
      "Epoch:  161 |---> loss is 1.0063632727, total correct predictions: 12995, its 73.835%\n",
      "Epoch:  162 |---> loss is 1.0120611191, total correct predictions: 12835, its 72.926%\n",
      "Epoch:  163 |---> loss is 1.0073232651, total correct predictions: 12931, its 73.472%\n",
      "Epoch:  164 |---> loss is 1.0132184029, total correct predictions: 12810, its 72.784%\n",
      "Epoch:  165 |---> loss is 1.0112971067, total correct predictions: 12839, its 72.949%\n",
      "Epoch:  166 |---> loss is 1.0022894144, total correct predictions: 13033, its 74.051%\n",
      "Epoch:  167 |---> loss is 1.0123130083, total correct predictions: 12848, its 73.000%\n",
      "Epoch:  168 |---> loss is 1.0036535263, total correct predictions: 13010, its 73.920%\n",
      "Epoch:  169 |---> loss is 1.0131744146, total correct predictions: 12795, its 72.699%\n",
      "Epoch:  170 |---> loss is 1.0091311932, total correct predictions: 12920, its 73.409%\n",
      "Epoch:  171 |---> loss is 1.0064622164, total correct predictions: 12969, its 73.688%\n",
      "Epoch:  172 |---> loss is 1.0087428093, total correct predictions: 12896, its 73.273%\n",
      "Epoch:  173 |---> loss is 1.0004526377, total correct predictions: 13081, its 74.324%\n",
      "Epoch:  174 |---> loss is 1.0074275732, total correct predictions: 12917, its 73.392%\n",
      "Epoch:  175 |---> loss is 0.9995100498, total correct predictions: 13079, its 74.312%\n",
      "Epoch:  176 |---> loss is 1.0042055845, total correct predictions: 12993, its 73.824%\n",
      "Epoch:  177 |---> loss is 1.0005766153, total correct predictions: 13104, its 74.455%\n",
      "Epoch:  178 |---> loss is 1.0013780594, total correct predictions: 13066, its 74.239%\n",
      "Epoch:  179 |---> loss is 1.0020376444, total correct predictions: 13061, its 74.210%\n",
      "Epoch:  180 |---> loss is 1.0012987852, total correct predictions: 13047, its 74.131%\n",
      "Epoch:  181 |---> loss is 1.0049533844, total correct predictions: 12978, its 73.739%\n",
      "Epoch:  182 |---> loss is 0.9980344176, total correct predictions: 13119, its 74.540%\n",
      "Epoch:  183 |---> loss is 0.9983789921, total correct predictions: 13134, its 74.625%\n",
      "Epoch:  184 |---> loss is 0.9970114827, total correct predictions: 13171, its 74.835%\n",
      "Epoch:  185 |---> loss is 0.9961085916, total correct predictions: 13181, its 74.892%\n",
      "Epoch:  186 |---> loss is 0.9980632067, total correct predictions: 13153, its 74.733%\n",
      "Epoch:  187 |---> loss is 0.9974197745, total correct predictions: 13146, its 74.693%\n",
      "Epoch:  188 |---> loss is 1.0008476973, total correct predictions: 13051, its 74.153%\n",
      "Epoch:  189 |---> loss is 0.9997864962, total correct predictions: 13085, its 74.347%\n",
      "Epoch:  190 |---> loss is 0.9986811876, total correct predictions: 13100, its 74.432%\n",
      "Epoch:  191 |---> loss is 0.9978439212, total correct predictions: 13126, its 74.580%\n",
      "Epoch:  192 |---> loss is 0.9984067678, total correct predictions: 13111, its 74.494%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  193 |---> loss is 0.9987514615, total correct predictions: 13113, its 74.506%\n",
      "Epoch:  194 |---> loss is 0.9995818734, total correct predictions: 13069, its 74.256%\n",
      "Epoch:  195 |---> loss is 0.9951430559, total correct predictions: 13175, its 74.858%\n",
      "Epoch:  196 |---> loss is 0.9923304319, total correct predictions: 13253, its 75.301%\n",
      "Epoch:  197 |---> loss is 0.9923948050, total correct predictions: 13255, its 75.312%\n",
      "Epoch:  198 |---> loss is 0.9947875142, total correct predictions: 13179, its 74.881%\n",
      "Epoch:  199 |---> loss is 0.9966391921, total correct predictions: 13152, its 74.727%\n",
      "Epoch:  200 |---> loss is 0.9935548902, total correct predictions: 13205, its 75.028%\n",
      "Epoch:  201 |---> loss is 0.9915444255, total correct predictions: 13285, its 75.483%\n",
      "Epoch:  202 |---> loss is 0.9917535782, total correct predictions: 13282, its 75.466%\n",
      "Epoch:  203 |---> loss is 0.9910877347, total correct predictions: 13283, its 75.472%\n",
      "Epoch:  204 |---> loss is 0.9910619855, total correct predictions: 13302, its 75.580%\n",
      "Epoch:  205 |---> loss is 0.9900734425, total correct predictions: 13309, its 75.619%\n",
      "Epoch:  206 |---> loss is 0.9894822836, total correct predictions: 13326, its 75.716%\n",
      "Epoch:  207 |---> loss is 0.9891971946, total correct predictions: 13330, its 75.739%\n",
      "Epoch:  208 |---> loss is 0.9909474850, total correct predictions: 13276, its 75.432%\n",
      "Epoch:  209 |---> loss is 0.9984865785, total correct predictions: 13085, its 74.347%\n",
      "Epoch:  210 |---> loss is 1.0124701262, total correct predictions: 12787, its 72.653%\n",
      "Epoch:  211 |---> loss is 0.9981506467, total correct predictions: 13120, its 74.545%\n",
      "Epoch:  212 |---> loss is 0.9959825277, total correct predictions: 13148, its 74.705%\n",
      "Epoch:  213 |---> loss is 1.0183261633, total correct predictions: 12669, its 71.983%\n",
      "Epoch:  214 |---> loss is 1.0140273571, total correct predictions: 12748, its 72.432%\n",
      "Epoch:  215 |---> loss is 1.0039877892, total correct predictions: 12961, its 73.642%\n",
      "Epoch:  216 |---> loss is 1.0237977505, total correct predictions: 12530, its 71.193%\n",
      "Epoch:  217 |---> loss is 0.9977359176, total correct predictions: 13090, its 74.375%\n",
      "Epoch:  218 |---> loss is 1.0317353010, total correct predictions: 12382, its 70.352%\n",
      "Epoch:  219 |---> loss is 1.0240242481, total correct predictions: 12535, its 71.222%\n",
      "Epoch:  220 |---> loss is 1.0023167133, total correct predictions: 13011, its 73.926%\n",
      "Epoch:  221 |---> loss is 1.0111027956, total correct predictions: 12817, its 72.824%\n",
      "Epoch:  222 |---> loss is 0.9936282635, total correct predictions: 13188, its 74.932%\n",
      "Epoch:  223 |---> loss is 1.0024734735, total correct predictions: 13002, its 73.875%\n",
      "Epoch:  224 |---> loss is 0.9906255603, total correct predictions: 13257, its 75.324%\n",
      "Epoch:  225 |---> loss is 0.9987946153, total correct predictions: 13061, its 74.210%\n",
      "Epoch:  226 |---> loss is 0.9947889447, total correct predictions: 13169, its 74.824%\n",
      "Epoch:  227 |---> loss is 0.9911203980, total correct predictions: 13270, its 75.398%\n",
      "Epoch:  228 |---> loss is 0.9939576387, total correct predictions: 13187, its 74.926%\n",
      "Epoch:  229 |---> loss is 0.9963572025, total correct predictions: 13133, its 74.619%\n",
      "Epoch:  230 |---> loss is 0.9933511615, total correct predictions: 13157, its 74.756%\n",
      "Epoch:  231 |---> loss is 0.9991450906, total correct predictions: 13061, its 74.210%\n",
      "Epoch:  232 |---> loss is 1.0029280186, total correct predictions: 12975, its 73.722%\n",
      "Epoch:  233 |---> loss is 0.9896928072, total correct predictions: 13260, its 75.341%\n",
      "Epoch:  234 |---> loss is 1.0063092709, total correct predictions: 12912, its 73.364%\n",
      "Epoch:  235 |---> loss is 0.9904227257, total correct predictions: 13260, its 75.341%\n",
      "Epoch:  236 |---> loss is 0.9944518805, total correct predictions: 13182, its 74.898%\n",
      "Epoch:  237 |---> loss is 0.9898952246, total correct predictions: 13248, its 75.273%\n",
      "Epoch:  238 |---> loss is 0.9888515472, total correct predictions: 13284, its 75.477%\n",
      "Epoch:  239 |---> loss is 0.9956658483, total correct predictions: 13150, its 74.716%\n",
      "Epoch:  240 |---> loss is 0.9877848625, total correct predictions: 13312, its 75.636%\n",
      "Epoch:  241 |---> loss is 0.9961791039, total correct predictions: 13138, its 74.648%\n",
      "Epoch:  242 |---> loss is 0.9887401462, total correct predictions: 13292, its 75.523%\n",
      "Epoch:  243 |---> loss is 0.9903350472, total correct predictions: 13242, its 75.239%\n",
      "Epoch:  244 |---> loss is 0.9866855741, total correct predictions: 13340, its 75.795%\n",
      "Epoch:  245 |---> loss is 0.9858897924, total correct predictions: 13340, its 75.795%\n",
      "Epoch:  246 |---> loss is 0.9873458743, total correct predictions: 13324, its 75.705%\n",
      "Epoch:  247 |---> loss is 0.9835300446, total correct predictions: 13386, its 76.057%\n",
      "Epoch:  248 |---> loss is 0.9873219728, total correct predictions: 13317, its 75.665%\n",
      "Epoch:  249 |---> loss is 0.9829126000, total correct predictions: 13406, its 76.170%\n",
      "Epoch:  250 |---> loss is 0.9842867851, total correct predictions: 13384, its 76.045%\n",
      "Epoch:  251 |---> loss is 0.9832121134, total correct predictions: 13405, its 76.165%\n",
      "Epoch:  252 |---> loss is 0.9826431274, total correct predictions: 13427, its 76.290%\n",
      "Epoch:  253 |---> loss is 0.9831202030, total correct predictions: 13411, its 76.199%\n",
      "Epoch:  254 |---> loss is 0.9803912640, total correct predictions: 13474, its 76.557%\n",
      "Epoch:  255 |---> loss is 0.9826795459, total correct predictions: 13446, its 76.398%\n",
      "Epoch:  256 |---> loss is 0.9856595397, total correct predictions: 13391, its 76.085%\n",
      "Epoch:  257 |---> loss is 0.9809430242, total correct predictions: 13483, its 76.608%\n",
      "Epoch:  258 |---> loss is 0.9852965474, total correct predictions: 13374, its 75.989%\n",
      "Epoch:  259 |---> loss is 0.9912338853, total correct predictions: 13247, its 75.267%\n",
      "Epoch:  260 |---> loss is 0.9828728437, total correct predictions: 13424, its 76.273%\n",
      "Epoch:  261 |---> loss is 1.0022577047, total correct predictions: 12995, its 73.835%\n",
      "Epoch:  262 |---> loss is 0.9883354306, total correct predictions: 13312, its 75.636%\n",
      "Epoch:  263 |---> loss is 0.9946184754, total correct predictions: 13158, its 74.761%\n",
      "Epoch:  264 |---> loss is 0.9867293835, total correct predictions: 13328, its 75.727%\n",
      "Epoch:  265 |---> loss is 0.9835751057, total correct predictions: 13375, its 75.994%\n",
      "Epoch:  266 |---> loss is 0.9935110807, total correct predictions: 13155, its 74.744%\n",
      "Epoch:  267 |---> loss is 0.9829013944, total correct predictions: 13386, its 76.057%\n",
      "Epoch:  268 |---> loss is 0.9987875223, total correct predictions: 13031, its 74.040%\n",
      "Epoch:  269 |---> loss is 0.9789094925, total correct predictions: 13492, its 76.659%\n",
      "Epoch:  270 |---> loss is 0.9981238842, total correct predictions: 13071, its 74.267%\n",
      "Epoch:  271 |---> loss is 0.9812216163, total correct predictions: 13434, its 76.330%\n",
      "Epoch:  272 |---> loss is 0.9978866577, total correct predictions: 13057, its 74.188%\n",
      "Epoch:  273 |---> loss is 0.9830447435, total correct predictions: 13412, its 76.205%\n",
      "Epoch:  274 |---> loss is 0.9992310405, total correct predictions: 13043, its 74.108%\n",
      "Epoch:  275 |---> loss is 0.9939709306, total correct predictions: 13168, its 74.818%\n",
      "Epoch:  276 |---> loss is 0.9899479747, total correct predictions: 13253, its 75.301%\n",
      "Epoch:  277 |---> loss is 0.9961049557, total correct predictions: 13123, its 74.562%\n",
      "Epoch:  278 |---> loss is 1.0009106398, total correct predictions: 12990, its 73.807%\n",
      "Epoch:  279 |---> loss is 1.0056347847, total correct predictions: 12923, its 73.426%\n",
      "Epoch:  280 |---> loss is 0.9855664968, total correct predictions: 13350, its 75.852%\n",
      "Epoch:  281 |---> loss is 1.0049186945, total correct predictions: 12924, its 73.432%\n",
      "Epoch:  282 |---> loss is 0.9959584475, total correct predictions: 13070, its 74.261%\n",
      "Epoch:  283 |---> loss is 0.9930655360, total correct predictions: 13148, its 74.705%\n",
      "Epoch:  284 |---> loss is 0.9959999919, total correct predictions: 13108, its 74.477%\n",
      "Epoch:  285 |---> loss is 0.9799429774, total correct predictions: 13431, its 76.312%\n",
      "Epoch:  286 |---> loss is 0.9898468852, total correct predictions: 13240, its 75.227%\n",
      "Epoch:  287 |---> loss is 0.9792974591, total correct predictions: 13487, its 76.631%\n",
      "Epoch:  288 |---> loss is 0.9858779311, total correct predictions: 13314, its 75.648%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  289 |---> loss is 0.9786581397, total correct predictions: 13479, its 76.585%\n",
      "Epoch:  290 |---> loss is 0.9860547781, total correct predictions: 13326, its 75.716%\n",
      "Epoch:  291 |---> loss is 0.9861564636, total correct predictions: 13319, its 75.676%\n",
      "Epoch:  292 |---> loss is 0.9898091555, total correct predictions: 13253, its 75.301%\n",
      "Epoch:  293 |---> loss is 0.9810467958, total correct predictions: 13415, its 76.222%\n",
      "Epoch:  294 |---> loss is 0.9910113811, total correct predictions: 13189, its 74.938%\n",
      "Epoch:  295 |---> loss is 0.9844812155, total correct predictions: 13339, its 75.790%\n",
      "Epoch:  296 |---> loss is 0.9869250655, total correct predictions: 13302, its 75.580%\n",
      "Epoch:  297 |---> loss is 0.9851841331, total correct predictions: 13342, its 75.807%\n",
      "Epoch:  298 |---> loss is 0.9826573730, total correct predictions: 13409, its 76.188%\n",
      "Epoch:  299 |---> loss is 0.9853157997, total correct predictions: 13351, its 75.858%\n",
      "Epoch:  300 |---> loss is 0.9816029072, total correct predictions: 13403, its 76.153%\n",
      "Epoch:  301 |---> loss is 0.9844796658, total correct predictions: 13362, its 75.920%\n",
      "Epoch:  302 |---> loss is 0.9798957705, total correct predictions: 13436, its 76.341%\n",
      "Epoch:  303 |---> loss is 0.9948748350, total correct predictions: 13125, its 74.574%\n",
      "Epoch:  304 |---> loss is 0.9776421785, total correct predictions: 13514, its 76.784%\n",
      "Epoch:  305 |---> loss is 0.9847999215, total correct predictions: 13347, its 75.835%\n",
      "Epoch:  306 |---> loss is 0.9814131260, total correct predictions: 13408, its 76.182%\n",
      "Epoch:  307 |---> loss is 0.9794646502, total correct predictions: 13427, its 76.290%\n",
      "Epoch:  308 |---> loss is 0.9780002832, total correct predictions: 13469, its 76.528%\n",
      "Epoch:  309 |---> loss is 0.9828648567, total correct predictions: 13382, its 76.034%\n",
      "Epoch:  310 |---> loss is 0.9798864722, total correct predictions: 13464, its 76.500%\n",
      "Epoch:  311 |---> loss is 0.9823157787, total correct predictions: 13392, its 76.091%\n",
      "Epoch:  312 |---> loss is 0.9823657274, total correct predictions: 13376, its 76.000%\n",
      "Epoch:  313 |---> loss is 0.9802168608, total correct predictions: 13426, its 76.284%\n",
      "Epoch:  314 |---> loss is 0.9784832001, total correct predictions: 13463, its 76.494%\n",
      "Epoch:  315 |---> loss is 0.9853712916, total correct predictions: 13308, its 75.614%\n",
      "Epoch:  316 |---> loss is 0.9759589434, total correct predictions: 13534, its 76.898%\n",
      "Epoch:  317 |---> loss is 0.9792250991, total correct predictions: 13474, its 76.557%\n",
      "Epoch:  318 |---> loss is 0.9790668488, total correct predictions: 13465, its 76.506%\n",
      "Epoch:  319 |---> loss is 0.9757991433, total correct predictions: 13527, its 76.858%\n",
      "Epoch:  320 |---> loss is 0.9734776616, total correct predictions: 13570, its 77.102%\n",
      "Epoch:  321 |---> loss is 0.9753628969, total correct predictions: 13553, its 77.006%\n",
      "Epoch:  322 |---> loss is 0.9738143682, total correct predictions: 13606, its 77.307%\n",
      "Epoch:  323 |---> loss is 0.9720754027, total correct predictions: 13632, its 77.455%\n",
      "Epoch:  324 |---> loss is 0.9746379852, total correct predictions: 13541, its 76.938%\n",
      "Epoch:  325 |---> loss is 0.9720711708, total correct predictions: 13604, its 77.295%\n",
      "Epoch:  326 |---> loss is 0.9703803062, total correct predictions: 13663, its 77.631%\n",
      "Epoch:  327 |---> loss is 0.9710233808, total correct predictions: 13635, its 77.472%\n",
      "Epoch:  328 |---> loss is 0.9705659747, total correct predictions: 13639, its 77.494%\n",
      "Epoch:  329 |---> loss is 0.9695641994, total correct predictions: 13667, its 77.653%\n",
      "Epoch:  330 |---> loss is 0.9702064991, total correct predictions: 13669, its 77.665%\n",
      "Epoch:  331 |---> loss is 0.9704315662, total correct predictions: 13659, its 77.608%\n",
      "Epoch:  332 |---> loss is 0.9703794122, total correct predictions: 13680, its 77.727%\n",
      "Epoch:  333 |---> loss is 0.9733473063, total correct predictions: 13618, its 77.375%\n",
      "Epoch:  334 |---> loss is 0.9753227234, total correct predictions: 13542, its 76.943%\n",
      "Epoch:  335 |---> loss is 0.9824218750, total correct predictions: 13373, its 75.983%\n",
      "Epoch:  336 |---> loss is 0.9717305303, total correct predictions: 13618, its 77.375%\n",
      "Epoch:  337 |---> loss is 0.9690576196, total correct predictions: 13687, its 77.767%\n",
      "Epoch:  338 |---> loss is 0.9678462148, total correct predictions: 13704, its 77.864%\n",
      "Epoch:  339 |---> loss is 0.9683670402, total correct predictions: 13713, its 77.915%\n",
      "Epoch:  340 |---> loss is 0.9715529680, total correct predictions: 13628, its 77.432%\n",
      "Epoch:  341 |---> loss is 0.9761512280, total correct predictions: 13521, its 76.824%\n",
      "Epoch:  342 |---> loss is 0.9880144596, total correct predictions: 13281, its 75.460%\n",
      "Epoch:  343 |---> loss is 0.9713547826, total correct predictions: 13651, its 77.562%\n",
      "Epoch:  344 |---> loss is 0.9945905209, total correct predictions: 13138, its 74.648%\n",
      "Epoch:  345 |---> loss is 0.9845165014, total correct predictions: 13324, its 75.705%\n",
      "Epoch:  346 |---> loss is 0.9834409356, total correct predictions: 13330, its 75.739%\n",
      "Epoch:  347 |---> loss is 0.9849612713, total correct predictions: 13353, its 75.869%\n",
      "Epoch:  348 |---> loss is 0.9920543432, total correct predictions: 13154, its 74.739%\n",
      "Epoch:  349 |---> loss is 0.9800029993, total correct predictions: 13459, its 76.472%\n",
      "Epoch:  350 |---> loss is 0.9831752777, total correct predictions: 13373, its 75.983%\n",
      "Epoch:  351 |---> loss is 0.9813433290, total correct predictions: 13353, its 75.869%\n",
      "Epoch:  352 |---> loss is 0.9708796740, total correct predictions: 13620, its 77.386%\n",
      "Epoch:  353 |---> loss is 0.9810233712, total correct predictions: 13385, its 76.051%\n",
      "Epoch:  354 |---> loss is 0.9695155025, total correct predictions: 13660, its 77.614%\n",
      "Epoch:  355 |---> loss is 0.9736700058, total correct predictions: 13567, its 77.085%\n",
      "Epoch:  356 |---> loss is 0.9767440557, total correct predictions: 13514, its 76.784%\n",
      "Epoch:  357 |---> loss is 0.9681606293, total correct predictions: 13675, its 77.699%\n",
      "Epoch:  358 |---> loss is 0.9751484990, total correct predictions: 13494, its 76.670%\n",
      "Epoch:  359 |---> loss is 0.9711915255, total correct predictions: 13610, its 77.330%\n",
      "Epoch:  360 |---> loss is 0.9703469872, total correct predictions: 13638, its 77.489%\n",
      "Epoch:  361 |---> loss is 0.9731296897, total correct predictions: 13544, its 76.955%\n",
      "Epoch:  362 |---> loss is 0.9661329389, total correct predictions: 13717, its 77.938%\n",
      "Epoch:  363 |---> loss is 0.9698989987, total correct predictions: 13634, its 77.466%\n",
      "Epoch:  364 |---> loss is 0.9689435363, total correct predictions: 13681, its 77.733%\n",
      "Epoch:  365 |---> loss is 0.9653872848, total correct predictions: 13741, its 78.074%\n",
      "Epoch:  366 |---> loss is 0.9682322145, total correct predictions: 13675, its 77.699%\n",
      "Epoch:  367 |---> loss is 0.9674712420, total correct predictions: 13738, its 78.057%\n",
      "Epoch:  368 |---> loss is 0.9657003284, total correct predictions: 13746, its 78.102%\n",
      "Epoch:  369 |---> loss is 0.9700569510, total correct predictions: 13668, its 77.659%\n",
      "Epoch:  370 |---> loss is 0.9691690207, total correct predictions: 13672, its 77.682%\n",
      "Epoch:  371 |---> loss is 0.9722296596, total correct predictions: 13591, its 77.222%\n",
      "Epoch:  372 |---> loss is 0.9693150520, total correct predictions: 13649, its 77.551%\n",
      "Epoch:  373 |---> loss is 0.9643383622, total correct predictions: 13781, its 78.301%\n",
      "Epoch:  374 |---> loss is 0.9643009901, total correct predictions: 13777, its 78.278%\n",
      "Epoch:  375 |---> loss is 0.9691793323, total correct predictions: 13654, its 77.580%\n",
      "Epoch:  376 |---> loss is 0.9790966511, total correct predictions: 13449, its 76.415%\n",
      "Epoch:  377 |---> loss is 0.9667801261, total correct predictions: 13732, its 78.023%\n",
      "Epoch:  378 |---> loss is 0.9654347897, total correct predictions: 13746, its 78.102%\n",
      "Epoch:  379 |---> loss is 0.9753371477, total correct predictions: 13520, its 76.818%\n",
      "Epoch:  380 |---> loss is 0.9733500481, total correct predictions: 13545, its 76.960%\n",
      "Epoch:  381 |---> loss is 0.9684207439, total correct predictions: 13684, its 77.750%\n",
      "Epoch:  382 |---> loss is 0.9647442102, total correct predictions: 13750, its 78.125%\n",
      "Epoch:  383 |---> loss is 0.9643658996, total correct predictions: 13769, its 78.233%\n",
      "Epoch:  384 |---> loss is 0.9648306370, total correct predictions: 13754, its 78.148%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  385 |---> loss is 0.9691021442, total correct predictions: 13669, its 77.665%\n",
      "Epoch:  386 |---> loss is 0.9750463963, total correct predictions: 13494, its 76.670%\n",
      "Epoch:  387 |---> loss is 0.9631558657, total correct predictions: 13800, its 78.409%\n",
      "Epoch:  388 |---> loss is 0.9644255042, total correct predictions: 13782, its 78.307%\n",
      "Epoch:  389 |---> loss is 0.9716594815, total correct predictions: 13608, its 77.318%\n",
      "Epoch:  390 |---> loss is 0.9638397694, total correct predictions: 13787, its 78.335%\n",
      "Epoch:  391 |---> loss is 0.9609876871, total correct predictions: 13845, its 78.665%\n",
      "Epoch:  392 |---> loss is 0.9622197747, total correct predictions: 13820, its 78.523%\n",
      "Epoch:  393 |---> loss is 0.9668288231, total correct predictions: 13727, its 77.994%\n",
      "Epoch:  394 |---> loss is 0.9739421010, total correct predictions: 13560, its 77.045%\n",
      "Epoch:  395 |---> loss is 0.9612005353, total correct predictions: 13855, its 78.722%\n",
      "Epoch:  396 |---> loss is 0.9629253745, total correct predictions: 13806, its 78.443%\n",
      "Epoch:  397 |---> loss is 0.9761776328, total correct predictions: 13498, its 76.693%\n",
      "Epoch:  398 |---> loss is 0.9598194361, total correct predictions: 13879, its 78.858%\n",
      "Epoch:  399 |---> loss is 0.9763639569, total correct predictions: 13506, its 76.739%\n",
      "Epoch:  400 |---> loss is 0.9929902554, total correct predictions: 13143, its 74.676%\n",
      "Epoch:  401 |---> loss is 0.9872316718, total correct predictions: 13266, its 75.375%\n",
      "Epoch:  402 |---> loss is 0.9793059826, total correct predictions: 13438, its 76.352%\n",
      "Epoch:  403 |---> loss is 0.9618601203, total correct predictions: 13839, its 78.631%\n",
      "Epoch:  404 |---> loss is 0.9668017626, total correct predictions: 13696, its 77.818%\n",
      "Epoch:  405 |---> loss is 0.9694271684, total correct predictions: 13633, its 77.460%\n",
      "Epoch:  406 |---> loss is 0.9670533538, total correct predictions: 13677, its 77.710%\n",
      "Epoch:  407 |---> loss is 0.9624664783, total correct predictions: 13795, its 78.381%\n",
      "Epoch:  408 |---> loss is 0.9692124128, total correct predictions: 13665, its 77.642%\n",
      "Epoch:  409 |---> loss is 0.9711546898, total correct predictions: 13604, its 77.295%\n",
      "Epoch:  410 |---> loss is 0.9632317424, total correct predictions: 13790, its 78.352%\n",
      "Epoch:  411 |---> loss is 0.9878242612, total correct predictions: 13262, its 75.352%\n",
      "Epoch:  412 |---> loss is 0.9646041393, total correct predictions: 13751, its 78.131%\n",
      "Epoch:  413 |---> loss is 0.9669882059, total correct predictions: 13694, its 77.807%\n",
      "Epoch:  414 |---> loss is 0.9704696536, total correct predictions: 13644, its 77.523%\n",
      "Epoch:  415 |---> loss is 0.9625289440, total correct predictions: 13807, its 78.449%\n",
      "Epoch:  416 |---> loss is 0.9615687132, total correct predictions: 13820, its 78.523%\n",
      "Epoch:  417 |---> loss is 0.9663571119, total correct predictions: 13697, its 77.824%\n",
      "Epoch:  418 |---> loss is 0.9607923627, total correct predictions: 13838, its 78.625%\n",
      "Epoch:  419 |---> loss is 0.9610427022, total correct predictions: 13849, its 78.688%\n",
      "Epoch:  420 |---> loss is 0.9660840034, total correct predictions: 13749, its 78.119%\n",
      "Epoch:  421 |---> loss is 0.9612264633, total correct predictions: 13833, its 78.597%\n",
      "Epoch:  422 |---> loss is 0.9637321234, total correct predictions: 13763, its 78.199%\n",
      "Epoch:  423 |---> loss is 0.9672649503, total correct predictions: 13685, its 77.756%\n",
      "Epoch:  424 |---> loss is 0.9629412293, total correct predictions: 13784, its 78.318%\n",
      "Epoch:  425 |---> loss is 0.9634025693, total correct predictions: 13785, its 78.324%\n",
      "Epoch:  426 |---> loss is 0.9646663070, total correct predictions: 13765, its 78.210%\n",
      "Epoch:  427 |---> loss is 0.9608601332, total correct predictions: 13857, its 78.733%\n",
      "Epoch:  428 |---> loss is 0.9577513337, total correct predictions: 13894, its 78.943%\n",
      "Epoch:  429 |---> loss is 0.9583488107, total correct predictions: 13882, its 78.875%\n",
      "Epoch:  430 |---> loss is 0.9578311443, total correct predictions: 13895, its 78.949%\n",
      "Epoch:  431 |---> loss is 0.9572736025, total correct predictions: 13920, its 79.091%\n",
      "Epoch:  432 |---> loss is 0.9571963549, total correct predictions: 13919, its 79.085%\n",
      "Epoch:  433 |---> loss is 0.9584180713, total correct predictions: 13883, its 78.881%\n",
      "Epoch:  434 |---> loss is 0.9615637064, total correct predictions: 13815, its 78.494%\n",
      "Epoch:  435 |---> loss is 0.9645098448, total correct predictions: 13724, its 77.977%\n",
      "Epoch:  436 |---> loss is 0.9645944834, total correct predictions: 13739, its 78.062%\n",
      "Epoch:  437 |---> loss is 0.9622188807, total correct predictions: 13780, its 78.295%\n",
      "Epoch:  438 |---> loss is 0.9618011117, total correct predictions: 13799, its 78.403%\n",
      "Epoch:  439 |---> loss is 0.9603070617, total correct predictions: 13847, its 78.676%\n",
      "Epoch:  440 |---> loss is 0.9618751407, total correct predictions: 13806, its 78.443%\n",
      "Epoch:  441 |---> loss is 0.9609725475, total correct predictions: 13843, its 78.653%\n",
      "Epoch:  442 |---> loss is 0.9675897956, total correct predictions: 13691, its 77.790%\n",
      "Epoch:  443 |---> loss is 0.9601809978, total correct predictions: 13865, its 78.778%\n",
      "Epoch:  444 |---> loss is 0.9568049908, total correct predictions: 13900, its 78.977%\n",
      "Epoch:  445 |---> loss is 0.9601185322, total correct predictions: 13837, its 78.619%\n",
      "Epoch:  446 |---> loss is 0.9667716622, total correct predictions: 13689, its 77.778%\n",
      "Epoch:  447 |---> loss is 0.9752901793, total correct predictions: 13501, its 76.710%\n",
      "Epoch:  448 |---> loss is 0.9615502954, total correct predictions: 13828, its 78.568%\n",
      "Epoch:  449 |---> loss is 1.0001813173, total correct predictions: 13000, its 73.864%\n",
      "Epoch:  450 |---> loss is 0.9643104076, total correct predictions: 13698, its 77.830%\n",
      "Epoch:  451 |---> loss is 1.0112555027, total correct predictions: 12800, its 72.727%\n",
      "Epoch:  452 |---> loss is 1.0071169138, total correct predictions: 12892, its 73.250%\n",
      "Epoch:  453 |---> loss is 0.9673060179, total correct predictions: 13698, its 77.830%\n",
      "Epoch:  454 |---> loss is 1.0215581656, total correct predictions: 12599, its 71.585%\n",
      "Epoch:  455 |---> loss is 1.0100110769, total correct predictions: 12855, its 73.040%\n",
      "Epoch:  456 |---> loss is 0.9720454812, total correct predictions: 13567, its 77.085%\n",
      "Epoch:  457 |---> loss is 1.0155307055, total correct predictions: 12743, its 72.403%\n",
      "Epoch:  458 |---> loss is 1.0338213444, total correct predictions: 12391, its 70.403%\n",
      "Epoch:  459 |---> loss is 1.0038619041, total correct predictions: 12936, its 73.500%\n",
      "Epoch:  460 |---> loss is 0.9944478869, total correct predictions: 13110, its 74.489%\n",
      "Epoch:  461 |---> loss is 1.0127695799, total correct predictions: 12796, its 72.705%\n",
      "Epoch:  462 |---> loss is 1.0117787123, total correct predictions: 12861, its 73.074%\n",
      "Epoch:  463 |---> loss is 0.9899352789, total correct predictions: 13251, its 75.290%\n",
      "Epoch:  464 |---> loss is 0.9827287197, total correct predictions: 13354, its 75.875%\n",
      "Epoch:  465 |---> loss is 0.9971649647, total correct predictions: 13080, its 74.318%\n",
      "Epoch:  466 |---> loss is 0.9836698771, total correct predictions: 13334, its 75.761%\n",
      "Epoch:  467 |---> loss is 0.9750715494, total correct predictions: 13536, its 76.909%\n",
      "Epoch:  468 |---> loss is 0.9850311875, total correct predictions: 13320, its 75.682%\n",
      "Epoch:  469 |---> loss is 0.9703483582, total correct predictions: 13606, its 77.307%\n",
      "Epoch:  470 |---> loss is 0.9770966172, total correct predictions: 13466, its 76.511%\n",
      "Epoch:  471 |---> loss is 0.9798898101, total correct predictions: 13381, its 76.028%\n",
      "Epoch:  472 |---> loss is 0.9686974883, total correct predictions: 13617, its 77.369%\n",
      "Epoch:  473 |---> loss is 0.9747646451, total correct predictions: 13511, its 76.767%\n",
      "Epoch:  474 |---> loss is 0.9671074748, total correct predictions: 13671, its 77.676%\n",
      "Epoch:  475 |---> loss is 0.9713079333, total correct predictions: 13606, its 77.307%\n",
      "Epoch:  476 |---> loss is 0.9704542160, total correct predictions: 13609, its 77.324%\n",
      "Epoch:  477 |---> loss is 0.9633393884, total correct predictions: 13730, its 78.011%\n",
      "Epoch:  478 |---> loss is 0.9687028527, total correct predictions: 13628, its 77.432%\n",
      "Epoch:  479 |---> loss is 0.9623593688, total correct predictions: 13767, its 78.222%\n",
      "Epoch:  480 |---> loss is 0.9668754339, total correct predictions: 13671, its 77.676%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  481 |---> loss is 0.9599428773, total correct predictions: 13827, its 78.562%\n",
      "Epoch:  482 |---> loss is 0.9633864760, total correct predictions: 13731, its 78.017%\n",
      "Epoch:  483 |---> loss is 0.9605883956, total correct predictions: 13786, its 78.330%\n",
      "Epoch:  484 |---> loss is 0.9624562860, total correct predictions: 13768, its 78.227%\n",
      "Epoch:  485 |---> loss is 0.9575111866, total correct predictions: 13872, its 78.818%\n",
      "Epoch:  486 |---> loss is 0.9610455036, total correct predictions: 13814, its 78.489%\n",
      "Epoch:  487 |---> loss is 0.9572727084, total correct predictions: 13887, its 78.903%\n",
      "Epoch:  488 |---> loss is 0.9590737224, total correct predictions: 13854, its 78.716%\n",
      "Epoch:  489 |---> loss is 0.9559683800, total correct predictions: 13917, its 79.074%\n",
      "Epoch:  490 |---> loss is 0.9581326842, total correct predictions: 13874, its 78.830%\n",
      "Epoch:  491 |---> loss is 0.9568926692, total correct predictions: 13904, its 79.000%\n",
      "Epoch:  492 |---> loss is 0.9594296813, total correct predictions: 13838, its 78.625%\n",
      "Epoch:  493 |---> loss is 0.9617965221, total correct predictions: 13766, its 78.216%\n",
      "Epoch:  494 |---> loss is 0.9658742547, total correct predictions: 13689, its 77.778%\n",
      "Epoch:  495 |---> loss is 0.9599516392, total correct predictions: 13837, its 78.619%\n",
      "Epoch:  496 |---> loss is 0.9561859965, total correct predictions: 13922, its 79.102%\n",
      "Epoch:  497 |---> loss is 0.9582203031, total correct predictions: 13862, its 78.761%\n",
      "Epoch:  498 |---> loss is 0.9687198997, total correct predictions: 13619, its 77.381%\n",
      "Epoch:  499 |---> loss is 0.9714996815, total correct predictions: 13587, its 77.199%\n"
     ]
    }
   ],
   "source": [
    "net_c = NetworkConv()\n",
    "print(net_c.conv1.weight)\n",
    "optimizer_c = optim.Adam(net_c.parameters(), lr=0.01, weight_decay=0.0001)\n",
    "number_of_epoches_c = 500\n",
    "# Here define weights for loss contribution of segments\n",
    "loss_weights_c = torch.tensor([1.,1.,1.,1.])\n",
    "\n",
    "total_loss_c = []\n",
    "total_accuracy_c = []\n",
    "total_val_loss_c = []\n",
    "total_val_accuracy_c = []\n",
    "for epoch in range(number_of_epoches_c):\n",
    "    predicted_c = net_c(train_features_c)\n",
    "    loss_c = F.cross_entropy(predicted_c, train_labels_c, loss_weights_c)\n",
    "    optimizer_c.zero_grad()\n",
    "    loss_c.backward()\n",
    "    optimizer_c.step()\n",
    "    \n",
    "    total_correct_c = get_correct_predictions(predicted_c, train_labels_c)\n",
    "    print(\"Epoch: {:4d} |---> loss is {:4.10f}, total correct predictions: {:5d}, its {:.3f}%\"\n",
    "      .format(epoch, loss_c.item(), total_correct_c, total_correct_c*100/train_features_c.shape[0]))\n",
    "    \n",
    "    with torch.no_grad():  # record loss and accuracy info for plots\n",
    "        total_loss_c.append(loss_c.item())\n",
    "        total_accuracy_c.append(total_correct_c*100/train_features_c.shape[0])\n",
    "        \n",
    "        test_preds_c = net_c(test_features_c)\n",
    "        total_val_loss_c.append(F.cross_entropy(test_preds_c, test_labels_c, loss_weights_c).item())\n",
    "        total_val_accuracy_c.append(get_correct_predictions(test_preds_c, test_labels_c)*100/test_features_c.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 72.11%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graphs and evaluation\n",
    "with torch.no_grad():\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(total_accuracy_c, label='accuracy')\n",
    "    plt.plot(total_val_accuracy_c, label = 'val_accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([0, 100])\n",
    "    plt.legend(loc='upper left')\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(total_loss_c, label='loss')\n",
    "    plt.plot(total_val_loss_c, label = 'val_loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    \n",
    "    \n",
    "    test_predictions_c = net_c(test_features_c)\n",
    "    test_correct_predictions_c = get_correct_predictions(test_predictions_c, test_labels_c)\n",
    "    print(\"Test accuracy is {:2.2f}%\" .format(test_correct_predictions_c * 100 /test_features_c.shape[0]))\n",
    "    \n",
    "    stacked_c = torch.stack((test_labels_c, test_predictions_c.argmax(dim=1)), dim=1)\n",
    "    confusion_matrix_c = torch.zeros((number_of_groups,number_of_groups), dtype=torch.int32)      # horizontal axis - predicted, vertical - true\n",
    "    for row in stacked_c:\n",
    "        confusion_matrix_c[row[0].item()][row[1].item()] += 1     # row is target, column - predicted\n",
    "    \n",
    "    # print(confusion_matrix)\n",
    "    # print(400 - torch.count_nonzero(test_labels_tensor).item())\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(confusion_matrix_c, cmap='winter')\n",
    "    \n",
    "    ax.set_xticks(np.arange(confusion_matrix_c.shape[0]))\n",
    "    ax.set_yticks(np.arange(confusion_matrix_c.shape[1]))\n",
    "    x_labels = []\n",
    "    y_labels = []\n",
    "    for i in range(confusion_matrix_c.shape[0]):\n",
    "        x_labels.append('Predicted: '+ str(i + 1))\n",
    "        y_labels.append('Real: ' + str(i + 1))\n",
    "    ax.set_xticklabels(x_labels)\n",
    "    ax.set_yticklabels(y_labels)\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "    \n",
    "    for i in range(confusion_matrix_c.shape[0]):\n",
    "        for j in range(confusion_matrix_c.shape[1]):\n",
    "            text = ax.text(j, i, str(round(confusion_matrix_c[i][j].item()*100/test_features_c.shape[0],2)) + '%', ha=\"center\", va=\"center\", size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60, 180])\n",
      "tensor([7.4342e+00, 6.2331e+00, 4.0876e+00, 3.1343e+00, 2.7192e+00, 2.4516e+00,\n",
      "        2.1997e+00, 1.6089e+00, 1.3795e+00, 1.3157e+00, 1.0906e+00, 9.8127e-01,\n",
      "        9.5411e-01, 8.2721e-01, 7.9649e-01, 6.7818e-01, 5.8512e-01, 5.5070e-01,\n",
      "        5.1281e-01, 4.8694e-01, 4.6225e-01, 3.9101e-01, 3.6803e-01, 3.1798e-01,\n",
      "        2.8323e-01, 2.5914e-01, 2.5353e-01, 2.4454e-01, 2.1151e-01, 2.0595e-01,\n",
      "        1.9792e-01, 1.9540e-01, 1.7622e-01, 1.7037e-01, 1.4706e-01, 1.3741e-01,\n",
      "        1.3165e-01, 1.2399e-01, 1.1729e-01, 1.0967e-01, 9.9128e-02, 9.6511e-02,\n",
      "        8.5839e-02, 7.3576e-02, 7.1755e-02, 6.7199e-02, 6.0581e-02, 5.7307e-02,\n",
      "        5.1637e-02, 4.9035e-02, 4.6145e-02, 4.0681e-02, 3.8259e-02, 3.7442e-02,\n",
      "        3.5467e-02, 3.2039e-02, 2.5062e-02, 2.2122e-02, 3.7379e-03, 1.1044e-03])\n",
      "torch.Size([16, 60])\n",
      "tensor([5.0795e+00, 2.8059e+00, 1.5708e+00, 1.1679e+00, 9.5050e-01, 7.5370e-01,\n",
      "        3.5906e-01, 1.8720e-01, 1.7324e-01, 1.0562e-01, 7.7764e-02, 7.0391e-02,\n",
      "        2.6386e-02, 7.9654e-03, 7.3098e-04, 3.1777e-04])\n"
     ]
    }
   ],
   "source": [
    "p1 = net_c.lin1.weight.clone().detach()\n",
    "print(p1.shape)\n",
    "u, s1, v = torch.svd(p1)\n",
    "print(s1)\n",
    "p2 = net_c.lin2.weight.clone().detach()\n",
    "print(p2.shape)\n",
    "u, s2, v = torch.svd(p2)\n",
    "print(s2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
